{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a1951a",
   "metadata": {},
   "source": [
    "## 1. DNN 기본 개념과 비선형성\n",
    "\n",
    "- 딥러닝의 목적은 **데이터 예측을 잘하는 것**\n",
    "- Perceptron은 하나의 뉴런이고, 여러 개가 모여 신경망을 구성\n",
    "- 단순 선형 분류기로는 복잡한 데이터를 분류할 수 없음\n",
    "    \n",
    "    ⇒ 뉴런에 **비선형 활성화 함수**를 추가하여 해결\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a91f",
   "metadata": {},
   "source": [
    "## 2. Loss Function, Optimization\n",
    "\n",
    "- 예: 선형 회귀 모델\n",
    "    \n",
    "    `y = ax + b`\n",
    "    \n",
    "- 평균 제곱 오차 (MSE):\n",
    "    \n",
    "    $$\n",
    "    \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "    $$\n",
    "    \n",
    "- 손실 함수Loss(a)를 미분했을 때, **기울기(gradient)가 0이 되는 지점**을 찾는 것이 목적\n",
    "    \n",
    "    ⇒ 이 지점은 **손실 함수의 최소값을 의미**하며, 그곳에서 모델의 예측이 가장 정확해짐\n",
    "    \n",
    "- 따라서, 경사하강법(Gradient Descent)을 사용하여 파라미터 a를 반복적으로 다음과 같이 업데이트함:\n",
    "    \n",
    "    (여기서 η는 learning rate)\n",
    "    \n",
    "\n",
    "$$\n",
    "a \\leftarrow a - \\eta \\cdot \\frac{d}{da} \\text{Loss}(a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbf16a",
   "metadata": {},
   "source": [
    "## 3. Backpropagation\n",
    "\n",
    "- 입력 → 출력까지 계산: **Forward propagation**\n",
    "- 예측값과 실제값의 차이를 바탕으로 가중치를 조정: **Backpropagation**\n",
    "- 미분(chain rule)을 통해 gradient 계산\n",
    "    \n",
    "    $$\n",
    "    \\frac{\\partial \\text{Loss}}{\\partial w} = \\frac{\\partial \\text{Loss}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w}\n",
    "    $$\n",
    "    \n",
    "- 계산된 gradient로 가중치 업데이트 (경사하강법 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e6f9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# y : 실제값, x : 입력 값, a : 가중치\n",
    "x = torch.tensor(2, dtype=torch.float32, requires_grad=False)\n",
    "y = torch.tensor(3, dtype=torch.float32, requires_grad=False)\n",
    "a = torch.tensor(3, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244cfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 9.0\n",
      "x grad : None\n",
      "y grad : None\n",
      "a grad : 12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 손실 함수(MSE)\n",
    "loss = (a * x - y) ** 2\n",
    "print(f\"loss : {loss}\")\n",
    "\n",
    "# 역전파\n",
    "loss.backward()\n",
    "print(f\"x grad : {x.grad}\")\n",
    "print(f\"y grad : {y.grad}\")\n",
    "print(f\"a grad : {a.grad}\")\n",
    "\n",
    "# gradient는 계산시 계속 누적되기 때문에 0으로 초기화 필수\n",
    "a.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa579ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a value: 3.0, dl/da :  12.0\n",
      "a value: 2.880000114440918, dl/da :  11.040000915527344\n",
      "a value: 2.7696001529693604, dl/da :  10.156801223754883\n",
      "a value: 2.668032169342041, dl/da :  9.344257354736328\n",
      "a value: 2.574589490890503, dl/da :  8.596715927124023\n",
      "a value: 2.4886224269866943, dl/da :  7.908979415893555\n",
      "a value: 2.4095325469970703, dl/da :  7.2762603759765625\n",
      "a value: 2.3367700576782227, dl/da :  6.694160461425781\n",
      "a value: 2.2698285579681396, dl/da :  6.158628463745117\n",
      "a value: 2.208242177963257, dl/da :  5.665937423706055\n",
      "a value: 2.151582717895508, dl/da :  5.2126617431640625\n",
      "a value: 2.0994560718536377, dl/da :  4.795648574829102\n",
      "a value: 2.051499605178833, dl/da :  4.411996841430664\n",
      "a value: 2.0073795318603516, dl/da :  4.0590362548828125\n",
      "a value: 1.9667891263961792, dl/da :  3.7343130111694336\n",
      "a value: 1.9294459819793701, dl/da :  3.435567855834961\n",
      "a value: 1.8950903415679932, dl/da :  3.1607227325439453\n",
      "a value: 1.8634830713272095, dl/da :  2.907864570617676\n",
      "a value: 1.834404468536377, dl/da :  2.6752357482910156\n",
      "a value: 1.8076521158218384, dl/da :  2.461216926574707\n",
      "a value: 1.783039927482605, dl/da :  2.26431941986084\n",
      "a value: 1.7603967189788818, dl/da :  2.0831737518310547\n",
      "a value: 1.7395650148391724, dl/da :  1.916520118713379\n",
      "a value: 1.7203998565673828, dl/da :  1.7631988525390625\n",
      "a value: 1.7027678489685059, dl/da :  1.6221427917480469\n",
      "a value: 1.6865464448928833, dl/da :  1.4923715591430664\n",
      "a value: 1.6716227531433105, dl/da :  1.3729820251464844\n",
      "a value: 1.6578929424285889, dl/da :  1.263143539428711\n",
      "a value: 1.645261526107788, dl/da :  1.1620922088623047\n",
      "a value: 1.6336406469345093, dl/da :  1.0691251754760742\n",
      "a value: 1.6229493618011475, dl/da :  0.9835948944091797\n",
      "a value: 1.6131134033203125, dl/da :  0.9049072265625\n",
      "a value: 1.6040643453598022, dl/da :  0.832514762878418\n",
      "a value: 1.5957392454147339, dl/da :  0.7659139633178711\n",
      "a value: 1.5880800485610962, dl/da :  0.7046403884887695\n",
      "a value: 1.5810335874557495, dl/da :  0.6482686996459961\n",
      "a value: 1.5745508670806885, dl/da :  0.5964069366455078\n",
      "a value: 1.568586826324463, dl/da :  0.5486946105957031\n",
      "a value: 1.5630998611450195, dl/da :  0.5047988891601562\n",
      "a value: 1.5580518245697021, dl/da :  0.4644145965576172\n",
      "a value: 1.5534076690673828, dl/da :  0.4272613525390625\n",
      "a value: 1.5491350889205933, dl/da :  0.3930807113647461\n",
      "a value: 1.5452042818069458, dl/da :  0.3616342544555664\n",
      "a value: 1.5415879487991333, dl/da :  0.3327035903930664\n",
      "a value: 1.5382609367370605, dl/da :  0.3060874938964844\n",
      "a value: 1.5352001190185547, dl/da :  0.2816009521484375\n",
      "a value: 1.5323841571807861, dl/da :  0.25907325744628906\n",
      "a value: 1.529793381690979, dl/da :  0.23834705352783203\n",
      "a value: 1.5274099111557007, dl/da :  0.21927928924560547\n",
      "a value: 1.5252171754837036, dl/da :  0.2017374038696289\n",
      "a value: 1.5231997966766357, dl/da :  0.18559837341308594\n",
      "a value: 1.5213438272476196, dl/da :  0.17075061798095703\n",
      "a value: 1.5196362733840942, dl/da :  0.1570901870727539\n",
      "a value: 1.518065333366394, dl/da :  0.14452266693115234\n",
      "a value: 1.51662015914917, dl/da :  0.13296127319335938\n",
      "a value: 1.5152904987335205, dl/da :  0.12232398986816406\n",
      "a value: 1.51406729221344, dl/da :  0.11253833770751953\n",
      "a value: 1.5129419565200806, dl/da :  0.10353565216064453\n",
      "a value: 1.511906623840332, dl/da :  0.09525299072265625\n",
      "a value: 1.5109541416168213, dl/da :  0.08763313293457031\n",
      "a value: 1.5100778341293335, dl/da :  0.08062267303466797\n",
      "a value: 1.5092716217041016, dl/da :  0.0741729736328125\n",
      "a value: 1.5085299015045166, dl/da :  0.06823921203613281\n",
      "a value: 1.507847547531128, dl/da :  0.06278038024902344\n",
      "a value: 1.5072197914123535, dl/da :  0.057758331298828125\n",
      "a value: 1.50664222240448, dl/da :  0.053137779235839844\n",
      "a value: 1.5061107873916626, dl/da :  0.04888629913330078\n",
      "a value: 1.5056219100952148, dl/da :  0.04497528076171875\n",
      "a value: 1.5051721334457397, dl/da :  0.04137706756591797\n",
      "a value: 1.504758358001709, dl/da :  0.038066864013671875\n",
      "a value: 1.5043777227401733, dl/da :  0.03502178192138672\n",
      "a value: 1.5040274858474731, dl/da :  0.032219886779785156\n",
      "a value: 1.5037052631378174, dl/da :  0.029642105102539062\n",
      "a value: 1.5034087896347046, dl/da :  0.02727031707763672\n",
      "a value: 1.5031360387802124, dl/da :  0.02508831024169922\n",
      "a value: 1.502885103225708, dl/da :  0.023080825805664062\n",
      "a value: 1.5026543140411377, dl/da :  0.021234512329101562\n",
      "a value: 1.5024420022964478, dl/da :  0.01953601837158203\n",
      "a value: 1.502246618270874, dl/da :  0.017972946166992188\n",
      "a value: 1.5020668506622314, dl/da :  0.016534805297851562\n",
      "a value: 1.5019015073776245, dl/da :  0.015212059020996094\n",
      "a value: 1.5017493963241577, dl/da :  0.013995170593261719\n",
      "a value: 1.501609444618225, dl/da :  0.012875556945800781\n",
      "a value: 1.5014806985855103, dl/da :  0.011845588684082031\n",
      "a value: 1.5013622045516968, dl/da :  0.010897636413574219\n",
      "a value: 1.5012532472610474, dl/da :  0.010025978088378906\n",
      "a value: 1.5011529922485352, dl/da :  0.00922393798828125\n",
      "a value: 1.5010607242584229, dl/da :  0.008485794067382812\n",
      "a value: 1.5009758472442627, dl/da :  0.0078067779541015625\n",
      "a value: 1.500897765159607, dl/da :  0.007182121276855469\n",
      "a value: 1.5008260011672974, dl/da :  0.006608009338378906\n",
      "a value: 1.5007599592208862, dl/da :  0.006079673767089844\n",
      "a value: 1.5006991624832153, dl/da :  0.005593299865722656\n",
      "a value: 1.500643253326416, dl/da :  0.005146026611328125\n",
      "a value: 1.50059175491333, dl/da :  0.004734039306640625\n",
      "a value: 1.5005444288253784, dl/da :  0.004355430603027344\n",
      "a value: 1.5005009174346924, dl/da :  0.0040073394775390625\n",
      "a value: 1.5004608631134033, dl/da :  0.0036869049072265625\n",
      "a value: 1.5004240274429321, dl/da :  0.0033922195434570312\n",
      "a value: 1.5003900527954102, dl/da :  0.00312042236328125\n",
      "[9.0, 7.61760139465332, 6.447538375854492, 5.4571967124938965, 4.6189703941345215, 3.9094972610473633, 3.308997869491577, 2.800736427307129, 2.370543956756592, 2.0064280033111572, 1.6982401609420776, 1.4373903274536133, 1.2166072130203247, 1.0297359228134155, 0.8715683817863464, 0.7376953959465027, 0.6243855357170105, 0.5284797549247742, 0.4473053812980652, 0.37859928607940674, 0.3204464018344879, 0.27122581005096436, 0.2295655906200409, 0.19430439174175262, 0.1644591987133026, 0.13919830322265625, 0.1178174763917923, 0.09972072392702103, 0.0844036415219307, 0.07143928855657578, 0.060466181486845016, 0.05117856711149216, 0.04331755265593529, 0.03666401281952858, 0.03103237971663475, 0.026265768334269524, 0.02223132736980915, 0.018816610798239708, 0.01592637039721012, 0.013480057008564472, 0.0114095164462924, 0.009657028131186962, 0.00817370880395174, 0.006918230094015598, 0.005855597089976072, 0.00495619373396039, 0.004194934386759996, 0.003550582332536578, 0.0030052128713577986, 0.0025436237920075655, 0.0021529223304241896, 0.0018222358776256442, 0.0015423329314216971, 0.0013054250739514828, 0.0011049187742173672, 0.0009351974003948271, 0.0007915548630990088, 0.0006699769292026758, 0.000567070790566504, 0.0004799728631041944, 0.00040625096880830824, 0.0003438518615439534, 0.00029103687847964466, 0.0002463360142428428, 0.0002085015585180372, 0.00017647647473495454, 0.00014936689694877714, 0.0001264234888367355, 0.00010700385610107332, 9.056788258021697e-05, 7.665782322874293e-05, 6.488256622105837e-05, 5.4915901273489e-05, 4.647938840207644e-05, 3.93389564123936e-05, 3.3295284083578736e-05, 2.8181531888549216e-05, 2.3853501261328347e-05, 2.0189174392726272e-05, 1.708748641249258e-05, 1.446292117179837e-05, 1.224155039381003e-05, 1.0361248314438853e-05, 8.769873602432199e-06, 7.422404905810254e-06, 6.282514732447453e-06, 5.317564500728622e-06, 4.500543582253158e-06, 3.809111376540386e-06, 3.223929070372833e-06, 2.729111656663008e-06, 2.310152012796607e-06, 1.955312654899899e-06, 1.6550993677810766e-06, 1.400695509801153e-06, 1.1856109267682768e-06, 1.0036731055151904e-06, 8.495792371832067e-07, 7.191970894382393e-07, 6.085647328291088e-07]\n",
      "final a : 1.5003588199615479\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for idx in range(100):\n",
    "  loss = (a * x - y) ** 2\n",
    "  losses.append(loss.item())\n",
    "  grad = loss.backward()\n",
    "  print(f\"a value: {a.item()}, dl/da :  {a.grad}\" )\n",
    "\n",
    "  # requires_grad=True로 만든 텐서는 모든 연산이 자동으로 추적\n",
    "  # torch.no_grad()를 사용하여 연산을 추적하지 않도록 설정해 메모리 절약\n",
    "  with torch.no_grad():\n",
    "    a -= 0.01 * a.grad\n",
    "\n",
    "  a.grad.zero_()\n",
    "print(losses)\n",
    "print(f\"final a : {a.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
