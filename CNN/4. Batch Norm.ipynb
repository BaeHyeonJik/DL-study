{"cells":[{"cell_type":"markdown","id":"00769a74","metadata":{"id":"00769a74"},"source":["## 16. CNN Batch Norm\n","\n","- 8번의 설명이랑 유사\n","- CNN에서는 **convolution 연산 후, 활성화 함수 적용 전에** BatchNorm을 적용\n","⇒ 정규화는 **각 배치의 같은 채널**을 기준으로 수행함"]},{"cell_type":"code","execution_count":null,"id":"83a45af7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83a45af7","executionInfo":{"status":"ok","timestamp":1747745249431,"user_tz":-540,"elapsed":33,"user":{"displayName":"배현직","userId":"06422137012407551312"}},"outputId":"d4dac8bc-eefa-4055-dd1b-bc9c113ae172"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","\n","# CPU/GPU 선택\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"]},{"cell_type":"code","execution_count":null,"id":"20550b4c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20550b4c","executionInfo":{"status":"ok","timestamp":1747744578838,"user_tz":-540,"elapsed":46,"user":{"displayName":"배현직","userId":"06422137012407551312"}},"outputId":"4d589c26-1ac5-4093-9940-a34145f777c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input Tensor shape: torch.Size([1, 1, 4, 4])\n","Output Tensor shape: torch.Size([1, 1, 2, 2])\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","input_tensor = torch.Tensor([[[[1, 2, 3, 4],\n","                             [5, 6, 7, 8],\n","                             [9, 10, 11, 12],\n","                             [13, 14, 15, 16],\n","                             ]]])\n","\n","# Pooling layer 생성, 절반으로 줄이기\n","maxpool_layer = nn.MaxPool2d(kernel_size=2)\n","output_tensor = maxpool_layer(input_tensor)\n","print(f'Input Tensor shape: {input_tensor.shape}')\n","print(f'Output Tensor shape: {output_tensor.shape}')"]},{"cell_type":"code","execution_count":null,"id":"cf4d4f65","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cf4d4f65","executionInfo":{"status":"ok","timestamp":1747745274474,"user_tz":-540,"elapsed":1856,"user":{"displayName":"배현직","userId":"06422137012407551312"}},"outputId":"9a3b3f8d-7fa4-4186-c457-a5ec8b5c3d13"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train dataset size: 50000\n","Validation dataset size: 10000\n"]}],"source":["import torch\n","from torchvision import datasets, transforms\n","\n","# 이미지 변환(전처리)\n","transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# CIFAR-10은 10개의 클래스에 걸쳐 총 60,000개의 32x32 컬러 이미지로 구성된 데이터셋\n","train_dataset = datasets.CIFAR10(\n","    root='./data',\n","    train=True,\n","    download=True,\n","    transform=transforms\n",")\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=4,\n","    shuffle=True,\n","    num_workers=4,\n",")\n","\n","test_dataset = datasets.CIFAR10(\n","    root='./data',\n","    train=False,\n","    download=True,\n","    transform=transforms\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=4,\n","    shuffle=False,\n","    num_workers=4,\n",")\n","\n","print(\"Train dataset size:\", len(train_dataset))\n","print(\"Validation dataset size:\", len(test_dataset))\n","\n"]},{"cell_type":"code","execution_count":null,"id":"1a2800dd","metadata":{"id":"1a2800dd"},"outputs":[],"source":["class ModernGAPCNN(nn.Module):\n","  def __init__(self, num_classes=10):\n","    super().__init__()\n","\n","    self.feature_extractor = nn.Sequential(\n","        nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1), # 16 * 30 * 30\n","        # channel을 기준으로 batch 정규화\n","        nn.BatchNorm2d(16),\n","        nn.ReLU(inplace=True),\n","        # stride를 2로 설정하여 feature map 크기를 줄임(pooling 대체)\n","        nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=1), # 32 * 15 * 15\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=1), # 64 * 7 * 17\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(inplace=True),\n","    )\n","\n","    # Global Average Pooling을 이용해 Channel별로 전체 값을 평균내어 1개의 값으로 축소\n","    self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1)) # 64 × 1 × 1\n","    self.classifier = nn.Linear(64, num_classes)\n","\n","  def forward(self, x):\n","      x = self.feature_extractor(x)\n","      x = self.global_avg_pool(x)\n","      x = torch.flatten(x, 1)\n","      x = self.classifier(x)\n","      return x\n"]},{"cell_type":"code","execution_count":13,"id":"f1187888","metadata":{"id":"f1187888","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a3125e99-2789-4223-dd9a-9ed225d6af66","executionInfo":{"status":"ok","timestamp":1747746002557,"user_tz":-540,"elapsed":436710,"user":{"displayName":"배현직","userId":"06422137012407551312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 1.9442, Val Loss: 0.3325, Accuracy: 52.87%\n","Epoch 2, Loss: 0.7816, Val Loss: 0.2853, Accuracy: 59.85%\n","Epoch 3, Loss: 0.4893, Val Loss: 0.2663, Accuracy: 62.05%\n","Epoch 4, Loss: 1.0107, Val Loss: 0.2509, Accuracy: 64.83%\n","Epoch 5, Loss: 1.1344, Val Loss: 0.2421, Accuracy: 66.15%\n","Epoch 6, Loss: 2.3736, Val Loss: 0.2262, Accuracy: 68.12%\n","Epoch 7, Loss: 0.3943, Val Loss: 0.2182, Accuracy: 69.69%\n","Epoch 8, Loss: 1.3765, Val Loss: 0.2155, Accuracy: 70.19%\n","Epoch 9, Loss: 1.3116, Val Loss: 0.2207, Accuracy: 69.06%\n","Epoch 10, Loss: 1.3179, Val Loss: 0.2042, Accuracy: 71.96%\n"]}],"source":["import torch.optim as optim\n","\n","net = ModernGAPCNN(10)\n","net.to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","for epoch in range(10):\n","  net.train()\n","  for batch_idx, (data, label) in enumerate(train_loader):\n","    data, label = data.to(device), label.to(device)\n","    optimizer.zero_grad()\n","    output = net(data)\n","    train_loss = loss_fn(output, label)\n","    train_loss.backward()\n","    optimizer.step()\n","\n","  net.eval()\n","  val_loss = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for data, label in test_loader:\n","      data, label = data.to(device), label.to(device)\n","      output = net(data)\n","      val_loss += loss_fn(output, label).item()\n","      pred = output.argmax(dim=1, keepdim=True)\n","      correct += pred.eq(label.view_as(pred)).sum().item()\n","\n","  val_loss /= len(test_loader.dataset)\n","  accuracy = 100. * correct / len(test_loader.dataset)\n","\n","  print(f'Epoch {epoch+1}, Loss: {train_loss.item():.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n","\n","\n","\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}