{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00769a74",
   "metadata": {},
   "source": [
    "## 16. CNN Batch Norm\n",
    "\n",
    "- 8번의 설명이랑 유사\n",
    "- CNN에서는 **convolution 연산 후, 활성화 함수 적용 전에** BatchNorm을 적용 \n",
    "⇒ 정규화는 **각 배치의 같은 채널**을 기준으로 수행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a45af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CPU/GPU 선택\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20550b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor shape: torch.Size([1, 1, 4, 4])\n",
      "Output Tensor shape: torch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[[[1, 2, 3, 4],\n",
    "                             [5, 6, 7, 8],\n",
    "                             [9, 10, 11, 12],\n",
    "                             [13, 14, 15, 16],\n",
    "                             ]]])\n",
    "\n",
    "# Pooling layer 생성, 절반으로 줄이기\n",
    "maxpool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "output_tensor = maxpool_layer(input_tensor)\n",
    "print(f'Input Tensor shape: {input_tensor.shape}')\n",
    "print(f'Output Tensor shape: {output_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4d4f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 50000\n",
      "Validation dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 이미지 변환(전처리)\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# CIFAR-10은 10개의 클래스에 걸쳐 총 60,000개의 32x32 컬러 이미지로 구성된 데이터셋\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2800dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernGAPCNN(nn.Module):\n",
    "  def __init__(self, num_classes=10):\n",
    "    super().__init__()\n",
    "\n",
    "    self.feature_extractor = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1), # 16 * 30 * 30\n",
    "        # channel을 기준으로 batch 정규화\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(inplace=True),\n",
    "        # stride를 2로 설정하여 feature map 크기를 줄임(pooling 대체)\n",
    "        nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=1), # 32 * 15 * 15\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=1), # 64 * 7 * 17\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "    # Global Average Pooling을 이용해 Channel별로 전체 값을 평균내어 1개의 값으로 축소\n",
    "    self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1)) # 64 × 1 × 1\n",
    "    self.classifier = nn.Linear(64, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.feature_extractor(x)\n",
    "      x = self.global_avg_pool(x)\n",
    "      x = torch.flatten(x, 1)\n",
    "      x = self.classifier(x)\n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1187888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = ModernGAPCNN(10)\n",
    "net.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "  net.train()\n",
    "  for batch_idx, (data, label) in enumerate(train_loader):\n",
    "    data, label = data.to(device), label.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = net(data)\n",
    "    train_loss = loss_fn(output, label)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  net.eval()\n",
    "  val_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "      data, label = data.to(device), label.to(device)\n",
    "      output = net(data)\n",
    "      val_loss += loss_fn(output, label).item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "  \n",
    "  val_loss /= len(test_loader.dataset)\n",
    "  accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "  print(f'Epoch {epoch+1}, Loss: {train_loss.item():.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
