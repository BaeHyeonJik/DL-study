{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNQjmCS6kO38C/fcW78lTJ6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 18. Transfer Learning\n","\n","- Transfer Learningdms 이미 대규모 데이터셋에서 학습된 모델(예: ImageNet에서 학습된 CNN 모델)을 가져와, **새로운 과제에 맞게 일부 또는 전체를 재학습** 시키는 기법\n","    - **Feature Extraction (특징 추출)**: 기존 모델의 convolution layer는 그대로 두고, 마지막 분류기(classifier)만 새 데이터에 맞게 교체하고 학습.\n","    - **Fine-tuning (미세조정)**: 기존 모델의 일부 또는 전체 layer의 가중치를 **새로운 데이터에 맞춰 추가로 학습**.\n","- 이 방법은 **학습에 필요한 데이터가 적거나, 학습 시간을 줄이고자 할 때 효과적**\n","- 전이 학습의 성능은 **새로운 데이터셋이 원래 모델이 학습한 데이터와 얼마나 유사한지**, 그리고 **사용 가능한 데이터의 양**에 따라 달라지기에 따라서 **적절한 사전 학습 모델을 선택하고, 얼마나 많은 layer를 고정시킬지(freeze) 또는 학습시킬지 결정하는 것이 중요**"],"metadata":{"id":"cAiWOehsBlDo"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9lbNazWBT1T","executionInfo":{"status":"ok","timestamp":1747792288855,"user_tz":-540,"elapsed":21,"user":{"displayName":"배현직","userId":"06422137012407551312"}},"outputId":"6d1e97e4-95d5-4c28-b9b7-30c35b6cc3c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","\n","# CPU/GPU 선택\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"]},{"cell_type":"code","source":["import torch\n","from torchvision import datasets, transforms\n","\n","# 이미지 변환(전처리)\n","# 모델에 맞게 224 * 224로 변환\n","transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406] , std=[0.229, 0.224, 0.225])\n","])\n","\n","# CIFAR-10은 10개의 클래스에 걸쳐 총 60,000개의 32x32 컬러 이미지로 구성된 데이터셋\n","train_dataset = datasets.CIFAR10(\n","    root='./data',\n","    train=True,\n","    download=True,\n","    transform=transforms\n",")\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=32,\n","    shuffle=True,\n","    num_workers=8,\n",")\n","\n","test_dataset = datasets.CIFAR10(\n","    root='./data',\n","    train=False,\n","    download=True,\n","    transform=transforms\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=32,\n","    shuffle=False,\n","    num_workers=8,\n",")\n","\n","print(\"Train dataset size:\", len(train_dataset))\n","print(\"Validation dataset size:\", len(test_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7EjYzX3pf5Oa","executionInfo":{"status":"ok","timestamp":1747795285558,"user_tz":-540,"elapsed":1582,"user":{"displayName":"배현직","userId":"06422137012407551312"}},"outputId":"e8fe8e35-052d-403b-85a6-5c191b3ddc26"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset size: 50000\n","Validation dataset size: 10000\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","from torchvision import models\n","\n","# 사전 학습된(pretrained) ResNet-18 모델\n","# weights=ResNet18_Weights.DEFAULT는 ImageNet으로 학습된 가중치를 사용\n","weights = models.ResNet18_Weights.DEFAULT\n","model = models.resnet18(weights=weights)\n","\n","# 원하는 class의 개수로 output을 변경\n","model.fc = nn.Linear(512, 10)\n","print(model.fc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8S-6zsRxh_8P","executionInfo":{"status":"ok","timestamp":1747795563941,"user_tz":-540,"elapsed":191,"user":{"displayName":"배현직","userId":"06422137012407551312"}},"outputId":"92e1bb6b-6216-44b9-8824-fec8e7e6bae2"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=512, out_features=10, bias=True)\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","model.to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(10):\n","  model.train()\n","  for batch_idx, (data, label) in enumerate(train_loader):\n","    data, label = data.to(device), label.to(device)\n","    optimizer.zero_grad()\n","    output = model(data)\n","    train_loss = loss_fn(output, label)\n","    train_loss.backward()\n","    optimizer.step()\n","\n","  model.eval()\n","  val_loss = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for data, label in test_loader:\n","      data, label = data.to(device), label.to(device)\n","      output = model(data)\n","      val_loss += loss_fn(output, label).item()\n","      pred = output.argmax(dim=1, keepdim=True)\n","      correct += pred.eq(label.view_as(pred)).sum().item()\n","\n","  val_loss /= len(test_loader.dataset)\n","  accuracy = 100. * correct / len(test_loader.dataset)\n","\n","  print(f'Epoch {epoch+1}, Loss: {train_loss.item():.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywNO64GSjXov","executionInfo":{"status":"ok","timestamp":1747794503362,"user_tz":-540,"elapsed":1728977,"user":{"displayName":"배현직","userId":"06422137012407551312"}},"outputId":"e5ec67c5-6167-492d-d5f8-c9afa55b0633"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.3846, Val Loss: 0.0153, Accuracy: 83.37%\n","Epoch 2, Loss: 0.3918, Val Loss: 0.0145, Accuracy: 84.34%\n","Epoch 3, Loss: 1.3060, Val Loss: 0.0115, Accuracy: 87.81%\n","Epoch 4, Loss: 0.1076, Val Loss: 0.0108, Accuracy: 88.52%\n","Epoch 5, Loss: 0.2412, Val Loss: 0.0126, Accuracy: 88.43%\n","Epoch 6, Loss: 0.0039, Val Loss: 0.0134, Accuracy: 88.16%\n","Epoch 7, Loss: 0.0357, Val Loss: 0.0126, Accuracy: 88.92%\n","Epoch 8, Loss: 0.0249, Val Loss: 0.0137, Accuracy: 88.59%\n","Epoch 9, Loss: 0.0082, Val Loss: 0.0124, Accuracy: 89.83%\n","Epoch 10, Loss: 0.1971, Val Loss: 0.0141, Accuracy: 88.91%\n"]}]}]}