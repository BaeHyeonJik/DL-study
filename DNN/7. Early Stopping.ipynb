{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98934ae7",
   "metadata": {},
   "source": [
    "## 10. Early Stopping\n",
    "\n",
    "- 학습 도중 **Validation Loss가 더 이상 줄어들지 않으면 학습을 멈추는 방법**\n",
    "- 과적합을 방지하고 불필요한 학습 시간을 줄임\n",
    "- 단순히 한 번 증가했다고 멈추면 **노이즈에 민감할 수 있으므로**,\n",
    "    \n",
    "    `patience`를 설정하여 **연속으로 loss가 증가할 때**만 멈춤\n",
    "    \n",
    "    ⇒ 예: `patience = 3`이면, 3번 연속으로 loss가 나빠질 때 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f773fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [[-0.30249982  0.35228178]\n",
      " [-0.89796171  0.10499859]\n",
      " [-0.53929324 -0.17153895]\n",
      " ...\n",
      " [ 0.52112207 -0.09355757]\n",
      " [-0.10692036 -0.50632611]\n",
      " [ 0.33397909  0.69549823]], labels: [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/swirl_10k.csv')\n",
    "\n",
    "data = df[['x', 'y']].values\n",
    "labels = df['label'].values.reshape(-1, 1)\n",
    "\n",
    "print(f'data: {data}, labels: {labels}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e82ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis', s=10)\n",
    "plt.title('Scatter plot of data points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d164cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data_torch = torch.tensor(data, dtype=torch.float32)\n",
    "labels_torch = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# 학습데이터를 7:3 정도로 train/validation으로 나누기\n",
    "data_length = len(data_torch)\n",
    "split_n = int(data_length * 0.7)\n",
    "train_data = data_torch[:split_n]\n",
    "train_labels = labels_torch[:split_n]\n",
    "val_data = data_torch[split_n:]\n",
    "val_labels = labels_torch[split_n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90836fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "\n",
    "# 배치로 데이터를 묶음(mini-batch)\n",
    "def get_batch(x, y, batch_size):\n",
    "  data_length = len(x)\n",
    "  indices = torch.randint(0, data_length, (batch_size,), generator=g)\n",
    "\n",
    "  x_batch = x[indices]\n",
    "  y_batch = y[indices]\n",
    "  return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28133b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val_loss: 0.6951403617858887, train_loss: 0.6962078213691711\n",
      "10 val_loss: 0.6949244737625122, train_loss: 0.6959434151649475\n",
      "20 val_loss: 0.6946887969970703, train_loss: 0.6956503391265869\n",
      "30 val_loss: 0.6944698691368103, train_loss: 0.6953747868537903\n",
      "40 val_loss: 0.6943232417106628, train_loss: 0.6951892375946045\n",
      "50 val_loss: 0.6941978931427002, train_loss: 0.6950297355651855\n",
      "60 val_loss: 0.6940521597862244, train_loss: 0.6948427557945251\n",
      "70 val_loss: 0.6939194202423096, train_loss: 0.694669246673584\n",
      "80 val_loss: 0.693804144859314, train_loss: 0.6945172548294067\n",
      "90 val_loss: 0.6937388777732849, train_loss: 0.6944327354431152\n",
      "100 val_loss: 0.6936384439468384, train_loss: 0.6943000555038452\n",
      "110 val_loss: 0.6935621500015259, train_loss: 0.6942003965377808\n",
      "120 val_loss: 0.6934747099876404, train_loss: 0.6940810084342957\n",
      "130 val_loss: 0.6933416128158569, train_loss: 0.6938909292221069\n",
      "140 val_loss: 0.6932658553123474, train_loss: 0.69378262758255\n",
      "150 val_loss: 0.6932008266448975, train_loss: 0.6936860084533691\n",
      "160 val_loss: 0.6930996179580688, train_loss: 0.6935313940048218\n",
      "170 val_loss: 0.6930258870124817, train_loss: 0.6934200525283813\n",
      "180 val_loss: 0.6929795145988464, train_loss: 0.693351149559021\n",
      "190 val_loss: 0.6929187178611755, train_loss: 0.6932486295700073\n",
      "200 val_loss: 0.6928904056549072, train_loss: 0.6932069063186646\n",
      "210 val_loss: 0.6928606629371643, train_loss: 0.693167507648468\n",
      "220 val_loss: 0.692838191986084, train_loss: 0.6931376457214355\n",
      "230 val_loss: 0.6928007006645203, train_loss: 0.6930781006813049\n",
      "240 val_loss: 0.6927632093429565, train_loss: 0.6930127143859863\n",
      "250 val_loss: 0.6927362680435181, train_loss: 0.6929739713668823\n",
      "260 val_loss: 0.6927111148834229, train_loss: 0.6929367184638977\n",
      "270 val_loss: 0.6926975846290588, train_loss: 0.69292151927948\n",
      "280 val_loss: 0.6926886439323425, train_loss: 0.6929323673248291\n",
      "290 val_loss: 0.6926599740982056, train_loss: 0.6928911209106445\n",
      "300 val_loss: 0.6926305294036865, train_loss: 0.6928359866142273\n",
      "310 val_loss: 0.6926075220108032, train_loss: 0.6927970051765442\n",
      "320 val_loss: 0.692595362663269, train_loss: 0.6927774548530579\n",
      "330 val_loss: 0.6925686001777649, train_loss: 0.6927288174629211\n",
      "340 val_loss: 0.6925496459007263, train_loss: 0.6926913857460022\n",
      "350 val_loss: 0.6925275325775146, train_loss: 0.6926512718200684\n",
      "360 val_loss: 0.6925026178359985, train_loss: 0.692609429359436\n",
      "370 val_loss: 0.6924846768379211, train_loss: 0.692578911781311\n",
      "380 val_loss: 0.6924645900726318, train_loss: 0.6925486922264099\n",
      "390 val_loss: 0.6924518346786499, train_loss: 0.6925094127655029\n",
      "400 val_loss: 0.6924318075180054, train_loss: 0.692497968673706\n",
      "410 val_loss: 0.6924178600311279, train_loss: 0.6924664974212646\n",
      "420 val_loss: 0.6924033164978027, train_loss: 0.6924477815628052\n",
      "430 val_loss: 0.6923845410346985, train_loss: 0.6924363374710083\n",
      "440 val_loss: 0.6923716068267822, train_loss: 0.6924238204956055\n",
      "450 val_loss: 0.6923520565032959, train_loss: 0.6924033164978027\n",
      "460 val_loss: 0.6923465728759766, train_loss: 0.6923826932907104\n",
      "470 val_loss: 0.6923328638076782, train_loss: 0.6923536658287048\n",
      "480 val_loss: 0.6923163533210754, train_loss: 0.6923208832740784\n",
      "490 val_loss: 0.6922995448112488, train_loss: 0.6923008561134338\n",
      "500 val_loss: 0.6922938823699951, train_loss: 0.6922705173492432\n",
      "510 val_loss: 0.6922740936279297, train_loss: 0.6922458410263062\n",
      "520 val_loss: 0.6922776699066162, train_loss: 0.6922176480293274\n",
      "530 val_loss: 0.692247211933136, train_loss: 0.6921992301940918\n",
      "540 val_loss: 0.6922355890274048, train_loss: 0.692176103591919\n",
      "550 val_loss: 0.6922333836555481, train_loss: 0.69215327501297\n",
      "560 val_loss: 0.6922270655632019, train_loss: 0.6921330690383911\n",
      "570 val_loss: 0.6922079920768738, train_loss: 0.6921141147613525\n",
      "580 val_loss: 0.6922160387039185, train_loss: 0.6920979619026184\n",
      "590 val_loss: 0.6921998858451843, train_loss: 0.6920775771141052\n",
      "600 val_loss: 0.6921929717063904, train_loss: 0.6920638680458069\n",
      "610 val_loss: 0.6921685934066772, train_loss: 0.6920367479324341\n",
      "620 val_loss: 0.6921406388282776, train_loss: 0.692017674446106\n",
      "630 val_loss: 0.6921427249908447, train_loss: 0.6920024156570435\n",
      "640 val_loss: 0.6921305060386658, train_loss: 0.6919816732406616\n",
      "650 val_loss: 0.6921175122261047, train_loss: 0.6919654607772827\n",
      "660 val_loss: 0.6921260356903076, train_loss: 0.6919505000114441\n",
      "670 val_loss: 0.6921015381813049, train_loss: 0.6919298768043518\n",
      "680 val_loss: 0.6921082139015198, train_loss: 0.6919125914573669\n",
      "690 val_loss: 0.6920909285545349, train_loss: 0.6918903589248657\n",
      "700 val_loss: 0.6920501589775085, train_loss: 0.6918601393699646\n",
      "710 val_loss: 0.6920344233512878, train_loss: 0.6918459534645081\n",
      "720 val_loss: 0.6920143961906433, train_loss: 0.691829264163971\n",
      "730 val_loss: 0.6919976472854614, train_loss: 0.6918125748634338\n",
      "740 val_loss: 0.6919874548912048, train_loss: 0.6917930841445923\n",
      "750 val_loss: 0.6919814348220825, train_loss: 0.6917761564254761\n",
      "760 val_loss: 0.6919828057289124, train_loss: 0.6917638778686523\n",
      "770 val_loss: 0.6919678449630737, train_loss: 0.6917492151260376\n",
      "780 val_loss: 0.6919477581977844, train_loss: 0.6917311549186707\n",
      "790 val_loss: 0.6919194459915161, train_loss: 0.6917111277580261\n",
      "800 val_loss: 0.6918851137161255, train_loss: 0.6916890144348145\n",
      "810 val_loss: 0.6918973922729492, train_loss: 0.6916791200637817\n",
      "820 val_loss: 0.6918910145759583, train_loss: 0.6916660070419312\n",
      "830 val_loss: 0.6918641924858093, train_loss: 0.6916477680206299\n",
      "840 val_loss: 0.6918764114379883, train_loss: 0.691645085811615\n",
      "850 val_loss: 0.6918461322784424, train_loss: 0.691622793674469\n",
      "860 val_loss: 0.6918216943740845, train_loss: 0.6916083097457886\n",
      "870 val_loss: 0.6918156743049622, train_loss: 0.6915926337242126\n",
      "880 val_loss: 0.691787838935852, train_loss: 0.6915726065635681\n",
      "890 val_loss: 0.6917685270309448, train_loss: 0.6915545463562012\n",
      "900 val_loss: 0.6917498111724854, train_loss: 0.6915390491485596\n",
      "910 val_loss: 0.6917387843132019, train_loss: 0.6915267109870911\n",
      "920 val_loss: 0.6917527914047241, train_loss: 0.6915227174758911\n",
      "930 val_loss: 0.6917147636413574, train_loss: 0.6914986968040466\n",
      "940 val_loss: 0.6917159557342529, train_loss: 0.691489577293396\n",
      "950 val_loss: 0.6916733980178833, train_loss: 0.6914659738540649\n",
      "960 val_loss: 0.6916414499282837, train_loss: 0.6914474964141846\n",
      "970 val_loss: 0.6916326284408569, train_loss: 0.6914311647415161\n",
      "980 val_loss: 0.6916254758834839, train_loss: 0.6914219856262207\n",
      "990 val_loss: 0.6916064620018005, train_loss: 0.6914070844650269\n",
      "1000 val_loss: 0.6916131377220154, train_loss: 0.6913983821868896\n",
      "1010 val_loss: 0.6915633678436279, train_loss: 0.6913721561431885\n",
      "1020 val_loss: 0.6915333867073059, train_loss: 0.6913536787033081\n",
      "1030 val_loss: 0.691539466381073, train_loss: 0.6913442611694336\n",
      "1040 val_loss: 0.6915363073348999, train_loss: 0.6913362145423889\n",
      "1050 val_loss: 0.691511332988739, train_loss: 0.6913198232650757\n",
      "1060 val_loss: 0.6915047764778137, train_loss: 0.6913058757781982\n",
      "1070 val_loss: 0.6914964318275452, train_loss: 0.6912928223609924\n",
      "1080 val_loss: 0.6914712190628052, train_loss: 0.6912763714790344\n",
      "1090 val_loss: 0.6914787888526917, train_loss: 0.6912728548049927\n",
      "1100 val_loss: 0.691447913646698, train_loss: 0.6912504434585571\n",
      "1110 val_loss: 0.6914586424827576, train_loss: 0.6912456154823303\n",
      "1120 val_loss: 0.6914243698120117, train_loss: 0.6912220120429993\n",
      "1130 val_loss: 0.6914187073707581, train_loss: 0.6912041902542114\n",
      "1140 val_loss: 0.6914153695106506, train_loss: 0.6911922693252563\n",
      "1150 val_loss: 0.6914095878601074, train_loss: 0.6911759376525879\n",
      "1160 val_loss: 0.6913889050483704, train_loss: 0.6911571025848389\n",
      "1170 val_loss: 0.6913827061653137, train_loss: 0.691143274307251\n",
      "1180 val_loss: 0.6913893222808838, train_loss: 0.6911361813545227\n",
      "1190 val_loss: 0.691349446773529, train_loss: 0.6911069750785828\n",
      "1200 val_loss: 0.6913180947303772, train_loss: 0.6910801529884338\n",
      "1210 val_loss: 0.6912737488746643, train_loss: 0.6910502314567566\n",
      "1220 val_loss: 0.691264808177948, train_loss: 0.6910364031791687\n",
      "1230 val_loss: 0.6912652850151062, train_loss: 0.6910205483436584\n",
      "1240 val_loss: 0.6912171244621277, train_loss: 0.6909843683242798\n",
      "1250 val_loss: 0.6911780834197998, train_loss: 0.6909565925598145\n",
      "1260 val_loss: 0.6911658644676208, train_loss: 0.690937876701355\n",
      "1270 val_loss: 0.691133439540863, train_loss: 0.6909129023551941\n",
      "1280 val_loss: 0.6911329030990601, train_loss: 0.6908990144729614\n",
      "1290 val_loss: 0.6911081671714783, train_loss: 0.6908774375915527\n",
      "1300 val_loss: 0.6910670399665833, train_loss: 0.6908459067344666\n",
      "1310 val_loss: 0.6910333037376404, train_loss: 0.6908177733421326\n",
      "1320 val_loss: 0.6910251379013062, train_loss: 0.690800666809082\n",
      "1330 val_loss: 0.6909778714179993, train_loss: 0.6907661557197571\n",
      "1340 val_loss: 0.6909386515617371, train_loss: 0.6907378435134888\n",
      "1350 val_loss: 0.6909083127975464, train_loss: 0.6907130479812622\n",
      "1360 val_loss: 0.6908769011497498, train_loss: 0.6906858682632446\n",
      "1370 val_loss: 0.6908761262893677, train_loss: 0.6906701326370239\n",
      "1380 val_loss: 0.6908475160598755, train_loss: 0.690648078918457\n",
      "1390 val_loss: 0.69086092710495, train_loss: 0.6906432509422302\n",
      "1400 val_loss: 0.6908273100852966, train_loss: 0.6906198263168335\n",
      "1410 val_loss: 0.6908035278320312, train_loss: 0.6905994415283203\n",
      "1420 val_loss: 0.6908072233200073, train_loss: 0.6905834078788757\n",
      "1430 val_loss: 0.6907718181610107, train_loss: 0.6905580163002014\n",
      "1440 val_loss: 0.6907371282577515, train_loss: 0.6905293464660645\n",
      "1450 val_loss: 0.6907203197479248, train_loss: 0.6905094981193542\n",
      "1460 val_loss: 0.6906963586807251, train_loss: 0.6904891133308411\n",
      "1470 val_loss: 0.6906919479370117, train_loss: 0.6904698014259338\n",
      "1480 val_loss: 0.6906718611717224, train_loss: 0.6904464960098267\n",
      "1490 val_loss: 0.6906464695930481, train_loss: 0.6904176473617554\n",
      "1500 val_loss: 0.6906334757804871, train_loss: 0.6903995275497437\n",
      "1510 val_loss: 0.6906081438064575, train_loss: 0.6903781294822693\n",
      "1520 val_loss: 0.6905847191810608, train_loss: 0.6903533339500427\n",
      "1530 val_loss: 0.6905645132064819, train_loss: 0.690326988697052\n",
      "1540 val_loss: 0.6905363202095032, train_loss: 0.6902989745140076\n",
      "1550 val_loss: 0.6905366778373718, train_loss: 0.6902847290039062\n",
      "1560 val_loss: 0.6905176043510437, train_loss: 0.6902596354484558\n",
      "1570 val_loss: 0.6904901266098022, train_loss: 0.690234363079071\n",
      "1580 val_loss: 0.6904693841934204, train_loss: 0.6902087330818176\n",
      "1590 val_loss: 0.6904756426811218, train_loss: 0.690194308757782\n",
      "1600 val_loss: 0.6904515624046326, train_loss: 0.6901660561561584\n",
      "1610 val_loss: 0.6904472708702087, train_loss: 0.6901479363441467\n",
      "1620 val_loss: 0.6904098987579346, train_loss: 0.6901143789291382\n",
      "1630 val_loss: 0.6903753876686096, train_loss: 0.6900860667228699\n",
      "1640 val_loss: 0.6903311610221863, train_loss: 0.6900490522384644\n",
      "1650 val_loss: 0.6903077960014343, train_loss: 0.6900194883346558\n",
      "1660 val_loss: 0.6902614831924438, train_loss: 0.6899816393852234\n",
      "1670 val_loss: 0.6902300715446472, train_loss: 0.6899470686912537\n",
      "1680 val_loss: 0.690184473991394, train_loss: 0.6899128556251526\n",
      "1690 val_loss: 0.690133273601532, train_loss: 0.6898749470710754\n",
      "1700 val_loss: 0.6901056170463562, train_loss: 0.6898549795150757\n",
      "1710 val_loss: 0.6900380253791809, train_loss: 0.6898102760314941\n",
      "1720 val_loss: 0.6899999380111694, train_loss: 0.6897807717323303\n",
      "1730 val_loss: 0.6899707317352295, train_loss: 0.6897451877593994\n",
      "1740 val_loss: 0.6899686455726624, train_loss: 0.6897255182266235\n",
      "1750 val_loss: 0.6899467706680298, train_loss: 0.6897022724151611\n",
      "1760 val_loss: 0.6898865699768066, train_loss: 0.6896599531173706\n",
      "1770 val_loss: 0.6898759603500366, train_loss: 0.6896271705627441\n",
      "1780 val_loss: 0.6898505687713623, train_loss: 0.6896041631698608\n",
      "1790 val_loss: 0.6898287534713745, train_loss: 0.6895736455917358\n",
      "1800 val_loss: 0.6898103952407837, train_loss: 0.6895560622215271\n",
      "1810 val_loss: 0.6897509694099426, train_loss: 0.6895115971565247\n",
      "1820 val_loss: 0.6897119283676147, train_loss: 0.6894789338111877\n",
      "1830 val_loss: 0.6896705627441406, train_loss: 0.6894432902336121\n",
      "1840 val_loss: 0.6896493434906006, train_loss: 0.6894192099571228\n",
      "1850 val_loss: 0.6896206140518188, train_loss: 0.6893879771232605\n",
      "1860 val_loss: 0.6896104216575623, train_loss: 0.6893642544746399\n",
      "1870 val_loss: 0.689582109451294, train_loss: 0.6893337965011597\n",
      "1880 val_loss: 0.6895592212677002, train_loss: 0.6893004775047302\n",
      "1890 val_loss: 0.6895310878753662, train_loss: 0.6892647743225098\n",
      "1900 val_loss: 0.6895217299461365, train_loss: 0.6892386078834534\n",
      "1910 val_loss: 0.689513087272644, train_loss: 0.6892154216766357\n",
      "1920 val_loss: 0.6894907355308533, train_loss: 0.6891785860061646\n",
      "1930 val_loss: 0.6894508600234985, train_loss: 0.6891382336616516\n",
      "1940 val_loss: 0.6894005537033081, train_loss: 0.6890972256660461\n",
      "1950 val_loss: 0.6893482804298401, train_loss: 0.6890595555305481\n",
      "1960 val_loss: 0.6892973780632019, train_loss: 0.6890078783035278\n",
      "1970 val_loss: 0.6892776489257812, train_loss: 0.6889744400978088\n",
      "1980 val_loss: 0.6892406344413757, train_loss: 0.6889405846595764\n",
      "1990 val_loss: 0.6892063617706299, train_loss: 0.6889073848724365\n",
      "2000 val_loss: 0.6891796588897705, train_loss: 0.6888722777366638\n",
      "2010 val_loss: 0.6891469955444336, train_loss: 0.6888388395309448\n",
      "2020 val_loss: 0.6891437768936157, train_loss: 0.6888109445571899\n",
      "2030 val_loss: 0.6891098618507385, train_loss: 0.6887713670730591\n",
      "2040 val_loss: 0.6890763640403748, train_loss: 0.6887403130531311\n",
      "2050 val_loss: 0.6890125274658203, train_loss: 0.6886844038963318\n",
      "2060 val_loss: 0.6889864206314087, train_loss: 0.6886500716209412\n",
      "2070 val_loss: 0.6889340281486511, train_loss: 0.6886040568351746\n",
      "2080 val_loss: 0.6889171600341797, train_loss: 0.6885802149772644\n",
      "2090 val_loss: 0.6889151334762573, train_loss: 0.6885549426078796\n",
      "2100 val_loss: 0.6888594031333923, train_loss: 0.6885024309158325\n",
      "2110 val_loss: 0.6888261437416077, train_loss: 0.6884653568267822\n",
      "2120 val_loss: 0.6887802481651306, train_loss: 0.6884170770645142\n",
      "2130 val_loss: 0.6887026429176331, train_loss: 0.6883493065834045\n",
      "2140 val_loss: 0.6886653900146484, train_loss: 0.6883077621459961\n",
      "2150 val_loss: 0.688591480255127, train_loss: 0.688254177570343\n",
      "2160 val_loss: 0.6885717511177063, train_loss: 0.6882185935974121\n",
      "2170 val_loss: 0.6885115504264832, train_loss: 0.6881645917892456\n",
      "2180 val_loss: 0.6884641051292419, train_loss: 0.6881177425384521\n",
      "2190 val_loss: 0.6884247064590454, train_loss: 0.6880742311477661\n",
      "2200 val_loss: 0.688366711139679, train_loss: 0.6880125403404236\n",
      "2210 val_loss: 0.688302218914032, train_loss: 0.6879581212997437\n",
      "2220 val_loss: 0.6882407069206238, train_loss: 0.6879135966300964\n",
      "2230 val_loss: 0.6881903409957886, train_loss: 0.6878620386123657\n",
      "2240 val_loss: 0.6881321668624878, train_loss: 0.6878093481063843\n",
      "2250 val_loss: 0.6880792379379272, train_loss: 0.6877598762512207\n",
      "2260 val_loss: 0.688042163848877, train_loss: 0.6877270936965942\n",
      "2270 val_loss: 0.6880054473876953, train_loss: 0.6876882910728455\n",
      "2280 val_loss: 0.6879474520683289, train_loss: 0.6876421570777893\n",
      "2290 val_loss: 0.6879085302352905, train_loss: 0.687592089176178\n",
      "2300 val_loss: 0.6878515481948853, train_loss: 0.6875364184379578\n",
      "2310 val_loss: 0.687799870967865, train_loss: 0.6874843835830688\n",
      "2320 val_loss: 0.6877329349517822, train_loss: 0.6874302625656128\n",
      "2330 val_loss: 0.6876562237739563, train_loss: 0.6873682141304016\n",
      "2340 val_loss: 0.687595546245575, train_loss: 0.6873098611831665\n",
      "2350 val_loss: 0.6875577569007874, train_loss: 0.6872653365135193\n",
      "2360 val_loss: 0.687526524066925, train_loss: 0.6872084140777588\n",
      "2370 val_loss: 0.6874661445617676, train_loss: 0.6871543526649475\n",
      "2380 val_loss: 0.6874325275421143, train_loss: 0.6870979070663452\n",
      "2390 val_loss: 0.6873923540115356, train_loss: 0.6870466470718384\n",
      "2400 val_loss: 0.6873293519020081, train_loss: 0.686992883682251\n",
      "2410 val_loss: 0.6872767806053162, train_loss: 0.6869281530380249\n",
      "2420 val_loss: 0.687235414981842, train_loss: 0.6868744492530823\n",
      "2430 val_loss: 0.68719482421875, train_loss: 0.686812162399292\n",
      "2440 val_loss: 0.6871609687805176, train_loss: 0.6867653727531433\n",
      "2450 val_loss: 0.6871001720428467, train_loss: 0.6867058873176575\n",
      "2460 val_loss: 0.6870651841163635, train_loss: 0.6866537928581238\n",
      "2470 val_loss: 0.6869755983352661, train_loss: 0.6865767240524292\n",
      "2480 val_loss: 0.6869236826896667, train_loss: 0.6865158081054688\n",
      "2490 val_loss: 0.6868900656700134, train_loss: 0.6864585876464844\n",
      "2500 val_loss: 0.6867792010307312, train_loss: 0.6863731741905212\n",
      "2510 val_loss: 0.6867424249649048, train_loss: 0.6863129734992981\n",
      "2520 val_loss: 0.6866876482963562, train_loss: 0.6862613558769226\n",
      "2530 val_loss: 0.6866399645805359, train_loss: 0.6862034201622009\n",
      "2540 val_loss: 0.6865803003311157, train_loss: 0.6861392855644226\n",
      "2550 val_loss: 0.6865224838256836, train_loss: 0.6860723495483398\n",
      "2560 val_loss: 0.6864339113235474, train_loss: 0.6859920620918274\n",
      "2570 val_loss: 0.6863788366317749, train_loss: 0.6859359741210938\n",
      "2580 val_loss: 0.686331570148468, train_loss: 0.6858652830123901\n",
      "2590 val_loss: 0.6862901449203491, train_loss: 0.6858097910881042\n",
      "2600 val_loss: 0.6862375736236572, train_loss: 0.6857522130012512\n",
      "2610 val_loss: 0.6861606240272522, train_loss: 0.6856719255447388\n",
      "2620 val_loss: 0.6860892176628113, train_loss: 0.6855948567390442\n",
      "2630 val_loss: 0.6860028505325317, train_loss: 0.6855111718177795\n",
      "2640 val_loss: 0.6859611868858337, train_loss: 0.6854429244995117\n",
      "2650 val_loss: 0.6858852505683899, train_loss: 0.6853581070899963\n",
      "2660 val_loss: 0.6857882738113403, train_loss: 0.6852694749832153\n",
      "2670 val_loss: 0.6857798099517822, train_loss: 0.6852273941040039\n",
      "2680 val_loss: 0.6857183575630188, train_loss: 0.6851564049720764\n",
      "2690 val_loss: 0.6856369376182556, train_loss: 0.6850820183753967\n",
      "2700 val_loss: 0.6855391263961792, train_loss: 0.6849979758262634\n",
      "2710 val_loss: 0.6854903101921082, train_loss: 0.6849437952041626\n",
      "2720 val_loss: 0.6854215264320374, train_loss: 0.684871256351471\n",
      "2730 val_loss: 0.6853293180465698, train_loss: 0.6847895383834839\n",
      "2740 val_loss: 0.6852149367332458, train_loss: 0.6846978068351746\n",
      "2750 val_loss: 0.6851290464401245, train_loss: 0.6846091747283936\n",
      "2760 val_loss: 0.685045599937439, train_loss: 0.6845255494117737\n",
      "2770 val_loss: 0.6849623918533325, train_loss: 0.6844269037246704\n",
      "2780 val_loss: 0.6848818063735962, train_loss: 0.6843384504318237\n",
      "2790 val_loss: 0.684781014919281, train_loss: 0.6842365860939026\n",
      "2800 val_loss: 0.6847246885299683, train_loss: 0.6841516494750977\n",
      "2810 val_loss: 0.6846513152122498, train_loss: 0.684077262878418\n",
      "2820 val_loss: 0.6845898628234863, train_loss: 0.684002161026001\n",
      "2830 val_loss: 0.6844869256019592, train_loss: 0.6839029788970947\n",
      "2840 val_loss: 0.6843898892402649, train_loss: 0.683806300163269\n",
      "2850 val_loss: 0.6843289136886597, train_loss: 0.6837432980537415\n",
      "2860 val_loss: 0.684211254119873, train_loss: 0.6836358308792114\n",
      "2870 val_loss: 0.6840965747833252, train_loss: 0.6835474371910095\n",
      "2880 val_loss: 0.6840038299560547, train_loss: 0.683455765247345\n",
      "2890 val_loss: 0.6839025616645813, train_loss: 0.6833590865135193\n",
      "2900 val_loss: 0.683818519115448, train_loss: 0.6832576990127563\n",
      "2910 val_loss: 0.683708667755127, train_loss: 0.6831539273262024\n",
      "2920 val_loss: 0.6836414337158203, train_loss: 0.6830816864967346\n",
      "2930 val_loss: 0.6835758686065674, train_loss: 0.6830048561096191\n",
      "2940 val_loss: 0.6835024952888489, train_loss: 0.6828992962837219\n",
      "2950 val_loss: 0.6833999752998352, train_loss: 0.6827928423881531\n",
      "2960 val_loss: 0.6833342909812927, train_loss: 0.6827051043510437\n",
      "2970 val_loss: 0.683217465877533, train_loss: 0.6825854778289795\n",
      "2980 val_loss: 0.6831127405166626, train_loss: 0.6824662685394287\n",
      "2990 val_loss: 0.6830811500549316, train_loss: 0.6823984384536743\n",
      "3000 val_loss: 0.6829337477684021, train_loss: 0.682271420955658\n",
      "3010 val_loss: 0.6828042268753052, train_loss: 0.6821478605270386\n",
      "3020 val_loss: 0.682666540145874, train_loss: 0.6820203065872192\n",
      "3030 val_loss: 0.6825367212295532, train_loss: 0.6818863153457642\n",
      "3040 val_loss: 0.6824069619178772, train_loss: 0.6817750334739685\n",
      "3050 val_loss: 0.6822826862335205, train_loss: 0.6816365718841553\n",
      "3060 val_loss: 0.6821439862251282, train_loss: 0.6815224885940552\n",
      "3070 val_loss: 0.6820499897003174, train_loss: 0.6814082860946655\n",
      "3080 val_loss: 0.6819368600845337, train_loss: 0.6813017725944519\n",
      "3090 val_loss: 0.6817940473556519, train_loss: 0.6811707615852356\n",
      "3100 val_loss: 0.6816686391830444, train_loss: 0.6810511350631714\n",
      "3110 val_loss: 0.6815675497055054, train_loss: 0.6809353828430176\n",
      "3120 val_loss: 0.6814738512039185, train_loss: 0.6808153390884399\n",
      "3130 val_loss: 0.6813427209854126, train_loss: 0.6806745529174805\n",
      "3140 val_loss: 0.6812236905097961, train_loss: 0.6805608868598938\n",
      "3150 val_loss: 0.6811230182647705, train_loss: 0.6804373860359192\n",
      "3160 val_loss: 0.6809844374656677, train_loss: 0.6802908778190613\n",
      "3170 val_loss: 0.6808390021324158, train_loss: 0.6801407933235168\n",
      "3180 val_loss: 0.6806841492652893, train_loss: 0.6800012588500977\n",
      "3190 val_loss: 0.6805517077445984, train_loss: 0.6798688769340515\n",
      "3200 val_loss: 0.680443525314331, train_loss: 0.6797490119934082\n",
      "3210 val_loss: 0.6803054809570312, train_loss: 0.6796097755432129\n",
      "3220 val_loss: 0.6801573038101196, train_loss: 0.6794630289077759\n",
      "3230 val_loss: 0.6800277829170227, train_loss: 0.6793215274810791\n",
      "3240 val_loss: 0.6799101829528809, train_loss: 0.6792086362838745\n",
      "3250 val_loss: 0.6797639727592468, train_loss: 0.6790794730186462\n",
      "3260 val_loss: 0.6796388030052185, train_loss: 0.6789603233337402\n",
      "3270 val_loss: 0.6795383095741272, train_loss: 0.6788557767868042\n",
      "3280 val_loss: 0.6794240474700928, train_loss: 0.6787323355674744\n",
      "3290 val_loss: 0.6792916059494019, train_loss: 0.6785816550254822\n",
      "3300 val_loss: 0.679120659828186, train_loss: 0.6784026026725769\n",
      "3310 val_loss: 0.6790211796760559, train_loss: 0.6782713532447815\n",
      "3320 val_loss: 0.6789014339447021, train_loss: 0.6781390309333801\n",
      "3330 val_loss: 0.6787751317024231, train_loss: 0.6779971122741699\n",
      "3340 val_loss: 0.6786277294158936, train_loss: 0.6778391599655151\n",
      "3350 val_loss: 0.6784441471099854, train_loss: 0.677654504776001\n",
      "3360 val_loss: 0.6783204674720764, train_loss: 0.6775112748146057\n",
      "3370 val_loss: 0.6781705617904663, train_loss: 0.6773539185523987\n",
      "3380 val_loss: 0.6780482530593872, train_loss: 0.6772193312644958\n",
      "3390 val_loss: 0.6778883337974548, train_loss: 0.6770657896995544\n",
      "3400 val_loss: 0.6777269840240479, train_loss: 0.676895797252655\n",
      "3410 val_loss: 0.6775568723678589, train_loss: 0.6767162680625916\n",
      "3420 val_loss: 0.6774032115936279, train_loss: 0.6765766739845276\n",
      "3430 val_loss: 0.6772810816764832, train_loss: 0.6764249205589294\n",
      "3440 val_loss: 0.677115797996521, train_loss: 0.6762757897377014\n",
      "3450 val_loss: 0.6769915223121643, train_loss: 0.6761568188667297\n",
      "3460 val_loss: 0.6768659949302673, train_loss: 0.6759938597679138\n",
      "3470 val_loss: 0.6767326593399048, train_loss: 0.6758630871772766\n",
      "3480 val_loss: 0.6766186952590942, train_loss: 0.675719678401947\n",
      "3490 val_loss: 0.6764593720436096, train_loss: 0.6755525469779968\n",
      "3500 val_loss: 0.6763348579406738, train_loss: 0.6754183173179626\n",
      "3510 val_loss: 0.676184892654419, train_loss: 0.6752740144729614\n",
      "3520 val_loss: 0.6760215163230896, train_loss: 0.6751127243041992\n",
      "3530 val_loss: 0.675865113735199, train_loss: 0.674953281879425\n",
      "3540 val_loss: 0.6757084131240845, train_loss: 0.6747874021530151\n",
      "3550 val_loss: 0.6755696535110474, train_loss: 0.6746411323547363\n",
      "3560 val_loss: 0.6754342317581177, train_loss: 0.6744793653488159\n",
      "3570 val_loss: 0.6752829551696777, train_loss: 0.6742995381355286\n",
      "3580 val_loss: 0.6751226782798767, train_loss: 0.6741169691085815\n",
      "3590 val_loss: 0.6749441623687744, train_loss: 0.673944890499115\n",
      "3600 val_loss: 0.6747512817382812, train_loss: 0.6737470030784607\n",
      "3610 val_loss: 0.6745920181274414, train_loss: 0.6735631823539734\n",
      "3620 val_loss: 0.6744344830513, train_loss: 0.6733756065368652\n",
      "3630 val_loss: 0.6742585301399231, train_loss: 0.673180103302002\n",
      "3640 val_loss: 0.6741194128990173, train_loss: 0.6730023622512817\n",
      "3650 val_loss: 0.6739352345466614, train_loss: 0.6728025078773499\n",
      "3660 val_loss: 0.6737469434738159, train_loss: 0.6725901961326599\n",
      "3670 val_loss: 0.6735829710960388, train_loss: 0.6724103689193726\n",
      "3680 val_loss: 0.6734064221382141, train_loss: 0.672222375869751\n",
      "3690 val_loss: 0.6733061075210571, train_loss: 0.6720794439315796\n",
      "3700 val_loss: 0.6731656193733215, train_loss: 0.67194664478302\n",
      "3710 val_loss: 0.6729482412338257, train_loss: 0.6717163324356079\n",
      "3720 val_loss: 0.6727551221847534, train_loss: 0.6715139746665955\n",
      "3730 val_loss: 0.6725996136665344, train_loss: 0.6713351011276245\n",
      "3740 val_loss: 0.6723485589027405, train_loss: 0.6710982322692871\n",
      "3750 val_loss: 0.6721084117889404, train_loss: 0.670868992805481\n",
      "3760 val_loss: 0.6719853281974792, train_loss: 0.6707236766815186\n",
      "3770 val_loss: 0.6717993021011353, train_loss: 0.6705335378646851\n",
      "3780 val_loss: 0.6715959310531616, train_loss: 0.6703205704689026\n",
      "3790 val_loss: 0.6714017987251282, train_loss: 0.6701193451881409\n",
      "3800 val_loss: 0.6712208390235901, train_loss: 0.6699230074882507\n",
      "3810 val_loss: 0.6710392832756042, train_loss: 0.6697408556938171\n",
      "3820 val_loss: 0.6708205342292786, train_loss: 0.6695147752761841\n",
      "3830 val_loss: 0.6706742644309998, train_loss: 0.6693501472473145\n",
      "3840 val_loss: 0.6705520153045654, train_loss: 0.6692075729370117\n",
      "3850 val_loss: 0.6703372597694397, train_loss: 0.6689900755882263\n",
      "3860 val_loss: 0.670098602771759, train_loss: 0.6687585711479187\n",
      "3870 val_loss: 0.669851541519165, train_loss: 0.6685062050819397\n",
      "3880 val_loss: 0.6696177124977112, train_loss: 0.6682707071304321\n",
      "3890 val_loss: 0.6694129109382629, train_loss: 0.6680527329444885\n",
      "3900 val_loss: 0.669221043586731, train_loss: 0.6678482890129089\n",
      "3910 val_loss: 0.6690067052841187, train_loss: 0.66761314868927\n",
      "3920 val_loss: 0.6687324047088623, train_loss: 0.667374849319458\n",
      "3930 val_loss: 0.6685700416564941, train_loss: 0.66717928647995\n",
      "3940 val_loss: 0.6682994365692139, train_loss: 0.6669015884399414\n",
      "3950 val_loss: 0.6681207418441772, train_loss: 0.6667040586471558\n",
      "3960 val_loss: 0.6678743362426758, train_loss: 0.6664933562278748\n",
      "3970 val_loss: 0.6676950454711914, train_loss: 0.6662904620170593\n",
      "3980 val_loss: 0.6674728989601135, train_loss: 0.6660518050193787\n",
      "3990 val_loss: 0.6673062443733215, train_loss: 0.665867030620575\n",
      "4000 val_loss: 0.6671044230461121, train_loss: 0.6656609773635864\n",
      "4010 val_loss: 0.6669596433639526, train_loss: 0.6654877662658691\n",
      "4020 val_loss: 0.6667667031288147, train_loss: 0.6652920842170715\n",
      "4030 val_loss: 0.6665208339691162, train_loss: 0.6650418639183044\n",
      "4040 val_loss: 0.6662930846214294, train_loss: 0.6648309230804443\n",
      "4050 val_loss: 0.666124701499939, train_loss: 0.664657711982727\n",
      "4060 val_loss: 0.665861189365387, train_loss: 0.664378821849823\n",
      "4070 val_loss: 0.6656510233879089, train_loss: 0.6641421318054199\n",
      "4080 val_loss: 0.6654612421989441, train_loss: 0.663932740688324\n",
      "4090 val_loss: 0.6651941537857056, train_loss: 0.6636481881141663\n",
      "4100 val_loss: 0.6650319695472717, train_loss: 0.6634705662727356\n",
      "4110 val_loss: 0.6648682951927185, train_loss: 0.6633010506629944\n",
      "4120 val_loss: 0.6645899415016174, train_loss: 0.6630502939224243\n",
      "4130 val_loss: 0.6643765568733215, train_loss: 0.6628456115722656\n",
      "4140 val_loss: 0.6641747355461121, train_loss: 0.6626368165016174\n",
      "4150 val_loss: 0.6638899445533752, train_loss: 0.662367045879364\n",
      "4160 val_loss: 0.663690447807312, train_loss: 0.662115216255188\n",
      "4170 val_loss: 0.663481593132019, train_loss: 0.6619059443473816\n",
      "4180 val_loss: 0.6633196473121643, train_loss: 0.6617259383201599\n",
      "4190 val_loss: 0.6631755232810974, train_loss: 0.6615524291992188\n",
      "4200 val_loss: 0.6630440950393677, train_loss: 0.6613847613334656\n",
      "4210 val_loss: 0.6628643870353699, train_loss: 0.661190927028656\n",
      "4220 val_loss: 0.662730872631073, train_loss: 0.6609973311424255\n",
      "4230 val_loss: 0.6624518036842346, train_loss: 0.6607125997543335\n",
      "4240 val_loss: 0.6621481776237488, train_loss: 0.660427987575531\n",
      "4250 val_loss: 0.6620118618011475, train_loss: 0.6602628827095032\n",
      "4260 val_loss: 0.6617487668991089, train_loss: 0.6600050330162048\n",
      "4270 val_loss: 0.661558985710144, train_loss: 0.6598040461540222\n",
      "4280 val_loss: 0.6613963842391968, train_loss: 0.6596202850341797\n",
      "4290 val_loss: 0.6612131595611572, train_loss: 0.6594129204750061\n",
      "4300 val_loss: 0.6610614657402039, train_loss: 0.6592748165130615\n",
      "4310 val_loss: 0.6607885956764221, train_loss: 0.6590022444725037\n",
      "4320 val_loss: 0.6605736613273621, train_loss: 0.6587827205657959\n",
      "4330 val_loss: 0.6603596210479736, train_loss: 0.6585426926612854\n",
      "4340 val_loss: 0.6600487232208252, train_loss: 0.6582339406013489\n",
      "4350 val_loss: 0.6598024964332581, train_loss: 0.6579573154449463\n",
      "4360 val_loss: 0.6596506237983704, train_loss: 0.6577903628349304\n",
      "4370 val_loss: 0.6594367623329163, train_loss: 0.6575825810432434\n",
      "4380 val_loss: 0.6593343019485474, train_loss: 0.6574573516845703\n",
      "4390 val_loss: 0.6590687036514282, train_loss: 0.657232403755188\n",
      "4400 val_loss: 0.658865749835968, train_loss: 0.6570054292678833\n",
      "4410 val_loss: 0.6588510274887085, train_loss: 0.6569350361824036\n",
      "4420 val_loss: 0.6586959362030029, train_loss: 0.656771183013916\n",
      "4430 val_loss: 0.6585361957550049, train_loss: 0.6565746665000916\n",
      "4440 val_loss: 0.6582767963409424, train_loss: 0.6563025116920471\n",
      "4450 val_loss: 0.6580044627189636, train_loss: 0.6560357809066772\n",
      "4460 val_loss: 0.6578497886657715, train_loss: 0.6558369994163513\n",
      "4470 val_loss: 0.6577003002166748, train_loss: 0.6556798815727234\n",
      "4480 val_loss: 0.6575265526771545, train_loss: 0.6554902791976929\n",
      "4490 val_loss: 0.6572571992874146, train_loss: 0.6552106142044067\n",
      "4500 val_loss: 0.6570358276367188, train_loss: 0.6549919843673706\n",
      "4510 val_loss: 0.6568757891654968, train_loss: 0.6548210978507996\n",
      "4520 val_loss: 0.6567485332489014, train_loss: 0.6546816825866699\n",
      "4530 val_loss: 0.6567047238349915, train_loss: 0.6545774936676025\n",
      "4540 val_loss: 0.6565191745758057, train_loss: 0.6543641686439514\n",
      "4550 val_loss: 0.6562800407409668, train_loss: 0.6541213989257812\n",
      "4560 val_loss: 0.6559884548187256, train_loss: 0.6538487672805786\n",
      "4570 val_loss: 0.6557604074478149, train_loss: 0.6536445021629333\n",
      "4580 val_loss: 0.6555243730545044, train_loss: 0.6534101366996765\n",
      "4590 val_loss: 0.6553975343704224, train_loss: 0.6532747149467468\n",
      "4600 val_loss: 0.6552051901817322, train_loss: 0.6530940532684326\n",
      "4610 val_loss: 0.654977560043335, train_loss: 0.65288245677948\n",
      "4620 val_loss: 0.6547882556915283, train_loss: 0.6526703238487244\n",
      "4630 val_loss: 0.6547009944915771, train_loss: 0.6525293588638306\n",
      "4640 val_loss: 0.6544695496559143, train_loss: 0.652292013168335\n",
      "4650 val_loss: 0.6543940305709839, train_loss: 0.6521826982498169\n",
      "4660 val_loss: 0.6540839672088623, train_loss: 0.6518773436546326\n",
      "4670 val_loss: 0.6539769172668457, train_loss: 0.6517235040664673\n",
      "4680 val_loss: 0.6537341475486755, train_loss: 0.6515135765075684\n",
      "4690 val_loss: 0.6533890962600708, train_loss: 0.6511968970298767\n",
      "4700 val_loss: 0.6532055139541626, train_loss: 0.6509924530982971\n",
      "4710 val_loss: 0.6530261635780334, train_loss: 0.65077143907547\n",
      "4720 val_loss: 0.6527672410011292, train_loss: 0.6504907011985779\n",
      "4730 val_loss: 0.6525925993919373, train_loss: 0.6503168344497681\n",
      "4740 val_loss: 0.6524048447608948, train_loss: 0.6501137018203735\n",
      "4750 val_loss: 0.6522814035415649, train_loss: 0.6499425172805786\n",
      "4760 val_loss: 0.6522611975669861, train_loss: 0.6499002575874329\n",
      "4770 val_loss: 0.6520556211471558, train_loss: 0.6496683955192566\n",
      "4780 val_loss: 0.6519953012466431, train_loss: 0.6495559215545654\n",
      "4790 val_loss: 0.6518265008926392, train_loss: 0.649361789226532\n",
      "4800 val_loss: 0.6516707539558411, train_loss: 0.6492007374763489\n",
      "4810 val_loss: 0.651264488697052, train_loss: 0.6488759517669678\n",
      "4820 val_loss: 0.6510671973228455, train_loss: 0.6486993432044983\n",
      "4830 val_loss: 0.6509190797805786, train_loss: 0.6485615372657776\n",
      "4840 val_loss: 0.6508803963661194, train_loss: 0.6484925150871277\n",
      "4850 val_loss: 0.6507099866867065, train_loss: 0.6482837796211243\n",
      "4860 val_loss: 0.6504495739936829, train_loss: 0.6480254530906677\n",
      "4870 val_loss: 0.6502952575683594, train_loss: 0.6478704214096069\n",
      "4880 val_loss: 0.6500593423843384, train_loss: 0.647628128528595\n",
      "4890 val_loss: 0.649956464767456, train_loss: 0.6475477814674377\n",
      "4900 val_loss: 0.6500272750854492, train_loss: 0.6475664973258972\n",
      "4910 val_loss: 0.6499049663543701, train_loss: 0.6474257707595825\n",
      "4920 val_loss: 0.6497571468353271, train_loss: 0.6472373008728027\n",
      "4930 val_loss: 0.6496199369430542, train_loss: 0.6470895409584045\n",
      "4940 val_loss: 0.6493748426437378, train_loss: 0.6468628644943237\n",
      "4950 val_loss: 0.6491861343383789, train_loss: 0.6466736793518066\n",
      "4960 val_loss: 0.6490120887756348, train_loss: 0.6465231776237488\n",
      "4970 val_loss: 0.6489130854606628, train_loss: 0.6464084386825562\n",
      "4980 val_loss: 0.6487958431243896, train_loss: 0.6462803483009338\n",
      "4990 val_loss: 0.6487547755241394, train_loss: 0.6461739540100098\n",
      "5000 val_loss: 0.6484845876693726, train_loss: 0.6459429264068604\n",
      "5010 val_loss: 0.648302435874939, train_loss: 0.6457700729370117\n",
      "5020 val_loss: 0.6481605768203735, train_loss: 0.6456328630447388\n",
      "5030 val_loss: 0.6480141878128052, train_loss: 0.6455050110816956\n",
      "5040 val_loss: 0.6479704976081848, train_loss: 0.6454140543937683\n",
      "5050 val_loss: 0.6478951573371887, train_loss: 0.6453310251235962\n",
      "5060 val_loss: 0.647627055644989, train_loss: 0.6451182961463928\n",
      "5070 val_loss: 0.647577166557312, train_loss: 0.6450252532958984\n",
      "5080 val_loss: 0.6473420262336731, train_loss: 0.6448205709457397\n",
      "5090 val_loss: 0.6471853256225586, train_loss: 0.6446785926818848\n",
      "5100 val_loss: 0.647087574005127, train_loss: 0.6445553302764893\n",
      "5110 val_loss: 0.6470316052436829, train_loss: 0.6444788575172424\n",
      "5120 val_loss: 0.646838366985321, train_loss: 0.6443002223968506\n",
      "5130 val_loss: 0.6468639969825745, train_loss: 0.6443212032318115\n",
      "5140 val_loss: 0.6467396020889282, train_loss: 0.6441596746444702\n",
      "5150 val_loss: 0.6465388536453247, train_loss: 0.6440059542655945\n",
      "5160 val_loss: 0.6463556885719299, train_loss: 0.6438024640083313\n",
      "5170 val_loss: 0.6461905241012573, train_loss: 0.6436452269554138\n",
      "5180 val_loss: 0.645977795124054, train_loss: 0.643435537815094\n",
      "5190 val_loss: 0.6458962559700012, train_loss: 0.6433547139167786\n",
      "5200 val_loss: 0.645667314529419, train_loss: 0.6431285738945007\n",
      "5210 val_loss: 0.6454015374183655, train_loss: 0.6428733468055725\n",
      "5220 val_loss: 0.6451979279518127, train_loss: 0.6426500678062439\n",
      "5230 val_loss: 0.6451201438903809, train_loss: 0.6425215005874634\n",
      "5240 val_loss: 0.6450555920600891, train_loss: 0.6424343585968018\n",
      "5250 val_loss: 0.6448843479156494, train_loss: 0.642242968082428\n",
      "5260 val_loss: 0.644778311252594, train_loss: 0.6420639157295227\n",
      "5270 val_loss: 0.6445557475090027, train_loss: 0.6418306231498718\n",
      "5280 val_loss: 0.6444223523139954, train_loss: 0.6416618227958679\n",
      "5290 val_loss: 0.6443787217140198, train_loss: 0.6416041254997253\n",
      "5300 val_loss: 0.6442548632621765, train_loss: 0.6415178775787354\n",
      "5310 val_loss: 0.6442321538925171, train_loss: 0.6414490342140198\n",
      "5320 val_loss: 0.6440398097038269, train_loss: 0.6412975192070007\n",
      "5330 val_loss: 0.6439008116722107, train_loss: 0.6411005854606628\n",
      "5340 val_loss: 0.6438021063804626, train_loss: 0.6409690380096436\n",
      "5350 val_loss: 0.6436737775802612, train_loss: 0.6408588290214539\n",
      "5360 val_loss: 0.643544614315033, train_loss: 0.6407368779182434\n",
      "5370 val_loss: 0.6434330940246582, train_loss: 0.6405876874923706\n",
      "5380 val_loss: 0.6432503461837769, train_loss: 0.6404021382331848\n",
      "5390 val_loss: 0.6430132389068604, train_loss: 0.6401874423027039\n",
      "5400 val_loss: 0.6428481340408325, train_loss: 0.6400236487388611\n",
      "5410 val_loss: 0.6427446007728577, train_loss: 0.6398943662643433\n",
      "5420 val_loss: 0.6426820755004883, train_loss: 0.6398902535438538\n",
      "5430 val_loss: 0.6425652503967285, train_loss: 0.6397709250450134\n",
      "5440 val_loss: 0.6424083709716797, train_loss: 0.6395643949508667\n",
      "5450 val_loss: 0.6422816514968872, train_loss: 0.6393947601318359\n",
      "5460 val_loss: 0.6420345306396484, train_loss: 0.6391528844833374\n",
      "5470 val_loss: 0.6419551372528076, train_loss: 0.6390880942344666\n",
      "5480 val_loss: 0.6418238282203674, train_loss: 0.6389235258102417\n",
      "5490 val_loss: 0.6417461633682251, train_loss: 0.6388570666313171\n",
      "5500 val_loss: 0.641740083694458, train_loss: 0.638778030872345\n",
      "5510 val_loss: 0.6416329145431519, train_loss: 0.6386754512786865\n",
      "5520 val_loss: 0.6415168046951294, train_loss: 0.6385716199874878\n",
      "5530 val_loss: 0.6414133906364441, train_loss: 0.6384803056716919\n",
      "5540 val_loss: 0.6413224935531616, train_loss: 0.6384104490280151\n",
      "5550 val_loss: 0.6412926316261292, train_loss: 0.6383165717124939\n",
      "5560 val_loss: 0.6410275101661682, train_loss: 0.6381415724754333\n",
      "5570 val_loss: 0.641006588935852, train_loss: 0.6381078958511353\n",
      "5580 val_loss: 0.6409115195274353, train_loss: 0.6379599571228027\n",
      "5590 val_loss: 0.640811026096344, train_loss: 0.6378359794616699\n",
      "5600 val_loss: 0.640779972076416, train_loss: 0.637735903263092\n",
      "5610 val_loss: 0.6407023072242737, train_loss: 0.6377272605895996\n",
      "5620 val_loss: 0.6405979990959167, train_loss: 0.6375991702079773\n",
      "5630 val_loss: 0.6405337452888489, train_loss: 0.6374912261962891\n",
      "5640 val_loss: 0.6404127478599548, train_loss: 0.6374291777610779\n",
      "5650 val_loss: 0.6402618885040283, train_loss: 0.6373006701469421\n",
      "5660 val_loss: 0.6401711702346802, train_loss: 0.6372146606445312\n",
      "5670 val_loss: 0.640067458152771, train_loss: 0.6370670199394226\n",
      "5680 val_loss: 0.6398309469223022, train_loss: 0.6368635892868042\n",
      "5690 val_loss: 0.6398235559463501, train_loss: 0.6367567777633667\n",
      "5700 val_loss: 0.6397205591201782, train_loss: 0.6365954875946045\n",
      "5710 val_loss: 0.6396582126617432, train_loss: 0.6364962458610535\n",
      "5720 val_loss: 0.6395902633666992, train_loss: 0.6364508867263794\n",
      "5730 val_loss: 0.6394869089126587, train_loss: 0.6363503336906433\n",
      "5740 val_loss: 0.6394374370574951, train_loss: 0.6362414956092834\n",
      "5750 val_loss: 0.6393736004829407, train_loss: 0.6361600756645203\n",
      "5760 val_loss: 0.6392303109169006, train_loss: 0.6360448002815247\n",
      "5770 val_loss: 0.6390895247459412, train_loss: 0.6359025239944458\n",
      "5780 val_loss: 0.6390455365180969, train_loss: 0.6358110904693604\n",
      "5790 val_loss: 0.6390275359153748, train_loss: 0.6357625126838684\n",
      "5800 val_loss: 0.6388391256332397, train_loss: 0.6355738639831543\n",
      "5810 val_loss: 0.6386651396751404, train_loss: 0.6354353427886963\n",
      "5820 val_loss: 0.6385323405265808, train_loss: 0.6352717876434326\n",
      "5830 val_loss: 0.6383528113365173, train_loss: 0.6351835131645203\n",
      "5840 val_loss: 0.6382606029510498, train_loss: 0.6350848078727722\n",
      "5850 val_loss: 0.6381210684776306, train_loss: 0.6349542140960693\n",
      "5860 val_loss: 0.6381064653396606, train_loss: 0.6348884105682373\n",
      "5870 val_loss: 0.6381137371063232, train_loss: 0.6348655819892883\n",
      "5880 val_loss: 0.638063371181488, train_loss: 0.634752631187439\n",
      "5890 val_loss: 0.637978732585907, train_loss: 0.6346301436424255\n",
      "5900 val_loss: 0.6378918290138245, train_loss: 0.6345885992050171\n",
      "5910 val_loss: 0.6378746628761292, train_loss: 0.6345211267471313\n",
      "5920 val_loss: 0.6377614140510559, train_loss: 0.634401798248291\n",
      "5930 val_loss: 0.6376601457595825, train_loss: 0.6343129277229309\n",
      "5940 val_loss: 0.6375603675842285, train_loss: 0.6342012882232666\n",
      "5950 val_loss: 0.6374325156211853, train_loss: 0.6341122984886169\n",
      "5960 val_loss: 0.637399435043335, train_loss: 0.6340391039848328\n",
      "5970 val_loss: 0.6373027563095093, train_loss: 0.633935809135437\n",
      "5980 val_loss: 0.6372538805007935, train_loss: 0.6338221430778503\n",
      "5990 val_loss: 0.6373041272163391, train_loss: 0.633807361125946\n",
      "6000 val_loss: 0.6374170780181885, train_loss: 0.6338410973548889\n",
      "6010 val_loss: 0.6373288035392761, train_loss: 0.6337297558784485\n",
      "6020 val_loss: 0.6371828317642212, train_loss: 0.6336003541946411\n",
      "6030 val_loss: 0.6367943286895752, train_loss: 0.6333311200141907\n",
      "6040 val_loss: 0.6367584466934204, train_loss: 0.6332667469978333\n",
      "6050 val_loss: 0.6366475224494934, train_loss: 0.6331508159637451\n",
      "6060 val_loss: 0.6365172266960144, train_loss: 0.6330324411392212\n",
      "6070 val_loss: 0.6363121867179871, train_loss: 0.6328498721122742\n",
      "6080 val_loss: 0.63612300157547, train_loss: 0.6327088475227356\n",
      "6090 val_loss: 0.6361004114151001, train_loss: 0.6326696872711182\n",
      "6100 val_loss: 0.6361632347106934, train_loss: 0.632712185382843\n",
      "6110 val_loss: 0.6360612511634827, train_loss: 0.6325732469558716\n",
      "6120 val_loss: 0.6359058618545532, train_loss: 0.6324450373649597\n",
      "6130 val_loss: 0.6357900500297546, train_loss: 0.6323710680007935\n",
      "6140 val_loss: 0.6358280777931213, train_loss: 0.6323251724243164\n",
      "6150 val_loss: 0.6357021331787109, train_loss: 0.6321550011634827\n",
      "6160 val_loss: 0.6355809569358826, train_loss: 0.6320289969444275\n",
      "6170 val_loss: 0.635500431060791, train_loss: 0.6319395899772644\n",
      "6180 val_loss: 0.6353201270103455, train_loss: 0.6318367719650269\n",
      "6190 val_loss: 0.6352816820144653, train_loss: 0.6317529082298279\n",
      "6200 val_loss: 0.6352115273475647, train_loss: 0.6316577196121216\n",
      "6210 val_loss: 0.6349837779998779, train_loss: 0.6315241456031799\n",
      "6220 val_loss: 0.6348240971565247, train_loss: 0.6313799023628235\n",
      "6230 val_loss: 0.6346996426582336, train_loss: 0.6312145590782166\n",
      "6240 val_loss: 0.6346641182899475, train_loss: 0.6311727166175842\n",
      "6250 val_loss: 0.6345865726470947, train_loss: 0.6311753392219543\n",
      "6260 val_loss: 0.6346209645271301, train_loss: 0.6312038898468018\n",
      "6270 val_loss: 0.6346913576126099, train_loss: 0.6311763525009155\n",
      "6280 val_loss: 0.634655773639679, train_loss: 0.6311367750167847\n",
      "6290 val_loss: 0.634476900100708, train_loss: 0.6309840083122253\n",
      "6300 val_loss: 0.6344655156135559, train_loss: 0.6309098601341248\n",
      "6310 val_loss: 0.6344814300537109, train_loss: 0.6308789253234863\n",
      "6320 val_loss: 0.6343534588813782, train_loss: 0.6307569146156311\n",
      "6330 val_loss: 0.6343508362770081, train_loss: 0.6306900382041931\n",
      "6340 val_loss: 0.6341684460639954, train_loss: 0.6305252313613892\n",
      "6350 val_loss: 0.6342470645904541, train_loss: 0.630553126335144\n",
      "6360 val_loss: 0.6343230605125427, train_loss: 0.6305708289146423\n",
      "6370 val_loss: 0.6341084241867065, train_loss: 0.6304190158843994\n",
      "6380 val_loss: 0.6339343786239624, train_loss: 0.6303116083145142\n",
      "6390 val_loss: 0.6338879466056824, train_loss: 0.630262553691864\n",
      "6400 val_loss: 0.6338437795639038, train_loss: 0.6302163004875183\n",
      "6410 val_loss: 0.6337279081344604, train_loss: 0.6300953030586243\n",
      "6420 val_loss: 0.6336419582366943, train_loss: 0.6299961805343628\n",
      "6430 val_loss: 0.6335020065307617, train_loss: 0.629909873008728\n",
      "6440 val_loss: 0.6334384083747864, train_loss: 0.6298233866691589\n",
      "6450 val_loss: 0.6333180069923401, train_loss: 0.6296969652175903\n",
      "6460 val_loss: 0.6333410739898682, train_loss: 0.629680871963501\n",
      "6470 val_loss: 0.6332000494003296, train_loss: 0.629524290561676\n",
      "6480 val_loss: 0.6331247687339783, train_loss: 0.6294204592704773\n",
      "6490 val_loss: 0.6330665946006775, train_loss: 0.6293647289276123\n",
      "6500 val_loss: 0.6327049136161804, train_loss: 0.6290737390518188\n",
      "6510 val_loss: 0.6326391100883484, train_loss: 0.6289979815483093\n",
      "6520 val_loss: 0.6326449513435364, train_loss: 0.6289920210838318\n",
      "6530 val_loss: 0.6324772238731384, train_loss: 0.6288353800773621\n",
      "6540 val_loss: 0.6323816776275635, train_loss: 0.6287387013435364\n",
      "6550 val_loss: 0.6324430108070374, train_loss: 0.6287257075309753\n",
      "6560 val_loss: 0.6323748230934143, train_loss: 0.6286454796791077\n",
      "6570 val_loss: 0.6321959495544434, train_loss: 0.6284707188606262\n",
      "6580 val_loss: 0.6322320699691772, train_loss: 0.6284675598144531\n",
      "6590 val_loss: 0.6323026418685913, train_loss: 0.6285278797149658\n",
      "6600 val_loss: 0.6321570873260498, train_loss: 0.628383457660675\n",
      "6610 val_loss: 0.632047176361084, train_loss: 0.6282835602760315\n",
      "6620 val_loss: 0.6321411728858948, train_loss: 0.6283488869667053\n",
      "6630 val_loss: 0.6319833397865295, train_loss: 0.6282517910003662\n",
      "6640 val_loss: 0.6318551301956177, train_loss: 0.6281079649925232\n",
      "6650 val_loss: 0.6318609118461609, train_loss: 0.6281232833862305\n",
      "6660 val_loss: 0.6317770481109619, train_loss: 0.62799072265625\n",
      "6670 val_loss: 0.6316344141960144, train_loss: 0.6278495192527771\n",
      "6680 val_loss: 0.631501317024231, train_loss: 0.627764105796814\n",
      "6690 val_loss: 0.6315738558769226, train_loss: 0.6277544498443604\n",
      "6700 val_loss: 0.6314815878868103, train_loss: 0.6276459097862244\n",
      "6710 val_loss: 0.631549060344696, train_loss: 0.6276196837425232\n",
      "6720 val_loss: 0.6313432455062866, train_loss: 0.6274510025978088\n",
      "6730 val_loss: 0.6311162710189819, train_loss: 0.6272621154785156\n",
      "6740 val_loss: 0.6311380863189697, train_loss: 0.6272562742233276\n",
      "6750 val_loss: 0.6310563683509827, train_loss: 0.627182126045227\n",
      "6760 val_loss: 0.6308962106704712, train_loss: 0.6270403861999512\n",
      "6770 val_loss: 0.6308842897415161, train_loss: 0.6269497871398926\n",
      "6780 val_loss: 0.6307879090309143, train_loss: 0.626873254776001\n",
      "6790 val_loss: 0.630779504776001, train_loss: 0.6268638968467712\n",
      "6800 val_loss: 0.6305901408195496, train_loss: 0.6266499757766724\n",
      "6810 val_loss: 0.6304505467414856, train_loss: 0.6265178322792053\n",
      "6820 val_loss: 0.630353569984436, train_loss: 0.6264411211013794\n",
      "6830 val_loss: 0.630205512046814, train_loss: 0.6263570785522461\n",
      "6840 val_loss: 0.6301154494285583, train_loss: 0.6262802481651306\n",
      "6850 val_loss: 0.6300193071365356, train_loss: 0.6261726021766663\n",
      "6860 val_loss: 0.6298957467079163, train_loss: 0.6260769367218018\n",
      "6870 val_loss: 0.6299047470092773, train_loss: 0.6260499358177185\n",
      "6880 val_loss: 0.6297590136528015, train_loss: 0.625933051109314\n",
      "6890 val_loss: 0.6297615766525269, train_loss: 0.6259486675262451\n",
      "6900 val_loss: 0.6296225190162659, train_loss: 0.6257807016372681\n",
      "6910 val_loss: 0.6295066475868225, train_loss: 0.6256504654884338\n",
      "6920 val_loss: 0.6293907165527344, train_loss: 0.6255853772163391\n",
      "6930 val_loss: 0.6292712688446045, train_loss: 0.6254771947860718\n",
      "6940 val_loss: 0.6291940808296204, train_loss: 0.6253747344017029\n",
      "6950 val_loss: 0.6292659640312195, train_loss: 0.6253647208213806\n",
      "6960 val_loss: 0.6293284296989441, train_loss: 0.6253494620323181\n",
      "6970 val_loss: 0.6292005777359009, train_loss: 0.625235378742218\n",
      "6980 val_loss: 0.6291152238845825, train_loss: 0.625119686126709\n",
      "6990 val_loss: 0.6290659308433533, train_loss: 0.6250531673431396\n",
      "7000 val_loss: 0.6289548277854919, train_loss: 0.6249554753303528\n",
      "7010 val_loss: 0.628950297832489, train_loss: 0.624915599822998\n",
      "7020 val_loss: 0.6289725303649902, train_loss: 0.6249335408210754\n",
      "7030 val_loss: 0.6288824677467346, train_loss: 0.6248492002487183\n",
      "7040 val_loss: 0.6287510991096497, train_loss: 0.6246649622917175\n",
      "7050 val_loss: 0.628495454788208, train_loss: 0.6244662404060364\n",
      "7060 val_loss: 0.6285657286643982, train_loss: 0.6245419383049011\n",
      "7070 val_loss: 0.6284610033035278, train_loss: 0.6244044899940491\n",
      "7080 val_loss: 0.6283077597618103, train_loss: 0.6242738366127014\n",
      "7090 val_loss: 0.628301203250885, train_loss: 0.624233603477478\n",
      "7100 val_loss: 0.6281766891479492, train_loss: 0.6241534352302551\n",
      "7110 val_loss: 0.6280688047409058, train_loss: 0.6240319013595581\n",
      "7120 val_loss: 0.6280903816223145, train_loss: 0.624046266078949\n",
      "7130 val_loss: 0.6280127167701721, train_loss: 0.6239264011383057\n",
      "7140 val_loss: 0.6277914047241211, train_loss: 0.6237226128578186\n",
      "7150 val_loss: 0.6277384161949158, train_loss: 0.6236408352851868\n",
      "7160 val_loss: 0.627598226070404, train_loss: 0.6234496235847473\n",
      "7170 val_loss: 0.6274479627609253, train_loss: 0.6233545541763306\n",
      "7180 val_loss: 0.6274013519287109, train_loss: 0.6232865452766418\n",
      "7190 val_loss: 0.6273786425590515, train_loss: 0.6232302188873291\n",
      "7200 val_loss: 0.6275743246078491, train_loss: 0.6233898997306824\n",
      "7210 val_loss: 0.6275014877319336, train_loss: 0.6232843995094299\n",
      "7220 val_loss: 0.6273283362388611, train_loss: 0.6230926513671875\n",
      "7230 val_loss: 0.6270578503608704, train_loss: 0.622850775718689\n",
      "7240 val_loss: 0.6271105408668518, train_loss: 0.6228880286216736\n",
      "7250 val_loss: 0.6271460652351379, train_loss: 0.6229531168937683\n",
      "7260 val_loss: 0.6269791126251221, train_loss: 0.6228282451629639\n",
      "7270 val_loss: 0.6269776225090027, train_loss: 0.6228183507919312\n",
      "7280 val_loss: 0.626814067363739, train_loss: 0.622640073299408\n",
      "7290 val_loss: 0.6267192959785461, train_loss: 0.6225666999816895\n",
      "7300 val_loss: 0.6265760064125061, train_loss: 0.6224411725997925\n",
      "7310 val_loss: 0.6262351274490356, train_loss: 0.6221972703933716\n",
      "7320 val_loss: 0.626397430896759, train_loss: 0.6222695112228394\n",
      "7330 val_loss: 0.6263545155525208, train_loss: 0.6221889853477478\n",
      "7340 val_loss: 0.626322329044342, train_loss: 0.6220976114273071\n",
      "7350 val_loss: 0.6263831853866577, train_loss: 0.6221133470535278\n",
      "7360 val_loss: 0.6263452768325806, train_loss: 0.6220802068710327\n",
      "7370 val_loss: 0.6263064742088318, train_loss: 0.6220393180847168\n",
      "7380 val_loss: 0.626237154006958, train_loss: 0.6219114065170288\n",
      "7390 val_loss: 0.6262343525886536, train_loss: 0.621881902217865\n",
      "7400 val_loss: 0.6263490915298462, train_loss: 0.621940553188324\n",
      "7410 val_loss: 0.6261903643608093, train_loss: 0.621745765209198\n",
      "7420 val_loss: 0.626130998134613, train_loss: 0.6217024922370911\n",
      "7430 val_loss: 0.6257773637771606, train_loss: 0.6214177012443542\n",
      "7440 val_loss: 0.6258783936500549, train_loss: 0.6214526891708374\n",
      "7450 val_loss: 0.6257129311561584, train_loss: 0.6213177442550659\n",
      "7460 val_loss: 0.6255452036857605, train_loss: 0.6211989521980286\n",
      "7470 val_loss: 0.6253093481063843, train_loss: 0.6209940910339355\n",
      "7480 val_loss: 0.6254833340644836, train_loss: 0.6210928559303284\n",
      "7490 val_loss: 0.6255795359611511, train_loss: 0.6211392879486084\n",
      "7500 val_loss: 0.6255248785018921, train_loss: 0.6210746169090271\n",
      "7510 val_loss: 0.6252934336662292, train_loss: 0.6208934187889099\n",
      "7520 val_loss: 0.6252974271774292, train_loss: 0.6208947896957397\n",
      "7530 val_loss: 0.6252163648605347, train_loss: 0.6208081245422363\n",
      "7540 val_loss: 0.6251729130744934, train_loss: 0.6207559704780579\n",
      "7550 val_loss: 0.6253216862678528, train_loss: 0.6208754181861877\n",
      "7560 val_loss: 0.6251163482666016, train_loss: 0.620653510093689\n",
      "7570 val_loss: 0.6249264478683472, train_loss: 0.6204836964607239\n",
      "7580 val_loss: 0.6250187754631042, train_loss: 0.6204993724822998\n",
      "7590 val_loss: 0.6249719858169556, train_loss: 0.6203985810279846\n",
      "7600 val_loss: 0.62494295835495, train_loss: 0.620381236076355\n",
      "7610 val_loss: 0.6248009204864502, train_loss: 0.6202220916748047\n",
      "7620 val_loss: 0.6246452927589417, train_loss: 0.6200692653656006\n",
      "7630 val_loss: 0.6244330406188965, train_loss: 0.6198940277099609\n",
      "7640 val_loss: 0.6242201924324036, train_loss: 0.6197080016136169\n",
      "7650 val_loss: 0.6241012215614319, train_loss: 0.6195659041404724\n",
      "7660 val_loss: 0.6239256262779236, train_loss: 0.6194236874580383\n",
      "7670 val_loss: 0.6239320039749146, train_loss: 0.6194093823432922\n",
      "7680 val_loss: 0.6237062215805054, train_loss: 0.6192322373390198\n",
      "7690 val_loss: 0.6237472891807556, train_loss: 0.6192278861999512\n",
      "7700 val_loss: 0.6235275864601135, train_loss: 0.6190284490585327\n",
      "7710 val_loss: 0.6234474778175354, train_loss: 0.6189030408859253\n",
      "7720 val_loss: 0.6235374808311462, train_loss: 0.6189508438110352\n",
      "7730 val_loss: 0.6233260631561279, train_loss: 0.6187610030174255\n",
      "7740 val_loss: 0.6233165264129639, train_loss: 0.6186637878417969\n",
      "7750 val_loss: 0.6231665015220642, train_loss: 0.6185150146484375\n",
      "7760 val_loss: 0.6230192184448242, train_loss: 0.6183585524559021\n",
      "7770 val_loss: 0.6227036714553833, train_loss: 0.6181151866912842\n",
      "7780 val_loss: 0.6226621270179749, train_loss: 0.6180568337440491\n",
      "7790 val_loss: 0.6226456165313721, train_loss: 0.6180378794670105\n",
      "7800 val_loss: 0.6225202679634094, train_loss: 0.6178778409957886\n",
      "7810 val_loss: 0.622310221195221, train_loss: 0.6176885962486267\n",
      "7820 val_loss: 0.6220661997795105, train_loss: 0.6174759268760681\n",
      "7830 val_loss: 0.621927797794342, train_loss: 0.6173534393310547\n",
      "7840 val_loss: 0.6217408776283264, train_loss: 0.6172387003898621\n",
      "7850 val_loss: 0.6219021081924438, train_loss: 0.6172943711280823\n",
      "7860 val_loss: 0.6216781139373779, train_loss: 0.6170961856842041\n",
      "7870 val_loss: 0.6215609312057495, train_loss: 0.616959273815155\n",
      "7880 val_loss: 0.6214479804039001, train_loss: 0.6168778538703918\n",
      "7890 val_loss: 0.6212766170501709, train_loss: 0.6167299747467041\n",
      "7900 val_loss: 0.6213133335113525, train_loss: 0.6167061924934387\n",
      "7910 val_loss: 0.6211288571357727, train_loss: 0.6164986491203308\n",
      "7920 val_loss: 0.6209990382194519, train_loss: 0.6163449883460999\n",
      "7930 val_loss: 0.6208570003509521, train_loss: 0.616179347038269\n",
      "7940 val_loss: 0.6207444071769714, train_loss: 0.616081178188324\n",
      "7950 val_loss: 0.6205739378929138, train_loss: 0.6158705949783325\n",
      "7960 val_loss: 0.6204839944839478, train_loss: 0.6158272624015808\n",
      "7970 val_loss: 0.6202216744422913, train_loss: 0.6155673861503601\n",
      "7980 val_loss: 0.6201474070549011, train_loss: 0.6154837608337402\n",
      "7990 val_loss: 0.6199878454208374, train_loss: 0.6153274774551392\n",
      "8000 val_loss: 0.6199846267700195, train_loss: 0.6153055429458618\n",
      "8010 val_loss: 0.6198071837425232, train_loss: 0.6151114106178284\n",
      "8020 val_loss: 0.6196896433830261, train_loss: 0.6149694323539734\n",
      "8030 val_loss: 0.6194766163825989, train_loss: 0.614791214466095\n",
      "8040 val_loss: 0.6193259954452515, train_loss: 0.6146584749221802\n",
      "8050 val_loss: 0.6191758513450623, train_loss: 0.6144974231719971\n",
      "8060 val_loss: 0.6191064715385437, train_loss: 0.6144153475761414\n",
      "8070 val_loss: 0.6189514994621277, train_loss: 0.6142287254333496\n",
      "8080 val_loss: 0.618705153465271, train_loss: 0.6139582991600037\n",
      "8090 val_loss: 0.6185042858123779, train_loss: 0.6137445569038391\n",
      "8100 val_loss: 0.6183208227157593, train_loss: 0.6135807633399963\n",
      "8110 val_loss: 0.6181949973106384, train_loss: 0.613460123538971\n",
      "8120 val_loss: 0.6179961562156677, train_loss: 0.613282322883606\n",
      "8130 val_loss: 0.6180586218833923, train_loss: 0.6133298873901367\n",
      "8140 val_loss: 0.6179972290992737, train_loss: 0.6132709980010986\n",
      "8150 val_loss: 0.617802619934082, train_loss: 0.6130874156951904\n",
      "8160 val_loss: 0.6178156137466431, train_loss: 0.6130757331848145\n",
      "8170 val_loss: 0.6176934242248535, train_loss: 0.6129501461982727\n",
      "8180 val_loss: 0.6176607012748718, train_loss: 0.6128795146942139\n",
      "8190 val_loss: 0.6177830696105957, train_loss: 0.6129481196403503\n",
      "8200 val_loss: 0.6175878047943115, train_loss: 0.6127607226371765\n",
      "8210 val_loss: 0.6174705624580383, train_loss: 0.6126160025596619\n",
      "8220 val_loss: 0.617246687412262, train_loss: 0.6123504042625427\n",
      "8230 val_loss: 0.6169771552085876, train_loss: 0.6120946407318115\n",
      "8240 val_loss: 0.6168171167373657, train_loss: 0.6119057536125183\n",
      "8250 val_loss: 0.6165796518325806, train_loss: 0.6116620898246765\n",
      "8260 val_loss: 0.6163073778152466, train_loss: 0.6113626956939697\n",
      "8270 val_loss: 0.6162433624267578, train_loss: 0.611306369304657\n",
      "8280 val_loss: 0.6160628795623779, train_loss: 0.6111078262329102\n",
      "8290 val_loss: 0.6160119771957397, train_loss: 0.6110541224479675\n",
      "8300 val_loss: 0.6158183217048645, train_loss: 0.610852837562561\n",
      "8310 val_loss: 0.6156274080276489, train_loss: 0.6107223629951477\n",
      "8320 val_loss: 0.6156333684921265, train_loss: 0.6106569766998291\n",
      "8330 val_loss: 0.6153643727302551, train_loss: 0.6104360222816467\n",
      "8340 val_loss: 0.6154099702835083, train_loss: 0.6104231476783752\n",
      "8350 val_loss: 0.6152586936950684, train_loss: 0.6103118062019348\n",
      "8360 val_loss: 0.6151006817817688, train_loss: 0.6101474165916443\n",
      "8370 val_loss: 0.614960789680481, train_loss: 0.6099717020988464\n",
      "8380 val_loss: 0.6148327589035034, train_loss: 0.6098050475120544\n",
      "8390 val_loss: 0.6147689819335938, train_loss: 0.6096941828727722\n",
      "8400 val_loss: 0.6147658824920654, train_loss: 0.609691321849823\n",
      "8410 val_loss: 0.61434406042099, train_loss: 0.6093226671218872\n",
      "8420 val_loss: 0.6139757633209229, train_loss: 0.6089590787887573\n",
      "8430 val_loss: 0.6138812899589539, train_loss: 0.6088615655899048\n",
      "8440 val_loss: 0.6136685609817505, train_loss: 0.6086077094078064\n",
      "8450 val_loss: 0.6135908961296082, train_loss: 0.6085181832313538\n",
      "8460 val_loss: 0.6134650707244873, train_loss: 0.6084210872650146\n",
      "8470 val_loss: 0.6134411692619324, train_loss: 0.6083583235740662\n",
      "8480 val_loss: 0.6131020784378052, train_loss: 0.6079833507537842\n",
      "8490 val_loss: 0.612892746925354, train_loss: 0.6078053712844849\n",
      "8500 val_loss: 0.6126973628997803, train_loss: 0.607636570930481\n",
      "8510 val_loss: 0.6126143932342529, train_loss: 0.6075366735458374\n",
      "8520 val_loss: 0.6124392151832581, train_loss: 0.6073818802833557\n",
      "8530 val_loss: 0.6122814416885376, train_loss: 0.6072519421577454\n",
      "8540 val_loss: 0.6120985150337219, train_loss: 0.6070953011512756\n",
      "8550 val_loss: 0.6119025349617004, train_loss: 0.606913685798645\n",
      "8560 val_loss: 0.6117981672286987, train_loss: 0.606770932674408\n",
      "8570 val_loss: 0.6115725636482239, train_loss: 0.6065576076507568\n",
      "8580 val_loss: 0.6113796234130859, train_loss: 0.606358528137207\n",
      "8590 val_loss: 0.6112117767333984, train_loss: 0.6061376333236694\n",
      "8600 val_loss: 0.6111369729042053, train_loss: 0.6060568690299988\n",
      "8610 val_loss: 0.6109622716903687, train_loss: 0.6058624386787415\n",
      "8620 val_loss: 0.6108185052871704, train_loss: 0.6057173609733582\n",
      "8630 val_loss: 0.6106348633766174, train_loss: 0.6055233478546143\n",
      "8640 val_loss: 0.6104558110237122, train_loss: 0.6053798794746399\n",
      "8650 val_loss: 0.6102157235145569, train_loss: 0.6051516532897949\n",
      "8660 val_loss: 0.6101447939872742, train_loss: 0.6050569415092468\n",
      "8670 val_loss: 0.6099538803100586, train_loss: 0.604831337928772\n",
      "8680 val_loss: 0.6097378730773926, train_loss: 0.6045960783958435\n",
      "8690 val_loss: 0.6095860004425049, train_loss: 0.6043761372566223\n",
      "8700 val_loss: 0.6093729734420776, train_loss: 0.604148268699646\n",
      "8710 val_loss: 0.609287440776825, train_loss: 0.6040403246879578\n",
      "8720 val_loss: 0.6090929508209229, train_loss: 0.6038448810577393\n",
      "8730 val_loss: 0.6090095043182373, train_loss: 0.6037063598632812\n",
      "8740 val_loss: 0.6088250279426575, train_loss: 0.6035401225090027\n",
      "8750 val_loss: 0.6085022687911987, train_loss: 0.6031721830368042\n",
      "8760 val_loss: 0.6082126498222351, train_loss: 0.6028695106506348\n",
      "8770 val_loss: 0.6079131960868835, train_loss: 0.6025919914245605\n",
      "8780 val_loss: 0.6076861619949341, train_loss: 0.6023728251457214\n",
      "8790 val_loss: 0.6075260639190674, train_loss: 0.6021900177001953\n",
      "8800 val_loss: 0.6073426008224487, train_loss: 0.602016806602478\n",
      "8810 val_loss: 0.6072644591331482, train_loss: 0.6019476056098938\n",
      "8820 val_loss: 0.6069951057434082, train_loss: 0.6016713380813599\n",
      "8830 val_loss: 0.6068562865257263, train_loss: 0.6015273928642273\n",
      "8840 val_loss: 0.6066312789916992, train_loss: 0.6013180613517761\n",
      "8850 val_loss: 0.606460452079773, train_loss: 0.6011030673980713\n",
      "8860 val_loss: 0.6062913537025452, train_loss: 0.6009252667427063\n",
      "8870 val_loss: 0.6061082482337952, train_loss: 0.6007600426673889\n",
      "8880 val_loss: 0.6058982014656067, train_loss: 0.6005585789680481\n",
      "8890 val_loss: 0.6057572364807129, train_loss: 0.6003759503364563\n",
      "8900 val_loss: 0.6056334376335144, train_loss: 0.6002472639083862\n",
      "8910 val_loss: 0.605410635471344, train_loss: 0.6000385880470276\n",
      "8920 val_loss: 0.6052224040031433, train_loss: 0.5998421907424927\n",
      "8930 val_loss: 0.6050618290901184, train_loss: 0.5996894240379333\n",
      "8940 val_loss: 0.6049286127090454, train_loss: 0.5995268821716309\n",
      "8950 val_loss: 0.6048473715782166, train_loss: 0.5994325280189514\n",
      "8960 val_loss: 0.604672908782959, train_loss: 0.5992833375930786\n",
      "8970 val_loss: 0.6045736074447632, train_loss: 0.5991629362106323\n",
      "8980 val_loss: 0.6041977405548096, train_loss: 0.5987868309020996\n",
      "8990 val_loss: 0.6040769815444946, train_loss: 0.5986158847808838\n",
      "9000 val_loss: 0.6038526296615601, train_loss: 0.5984063148498535\n",
      "9010 val_loss: 0.6036117076873779, train_loss: 0.5981466174125671\n",
      "9020 val_loss: 0.6033673882484436, train_loss: 0.5978652834892273\n",
      "9030 val_loss: 0.6031076908111572, train_loss: 0.597607433795929\n",
      "9040 val_loss: 0.6028872728347778, train_loss: 0.5974150896072388\n",
      "9050 val_loss: 0.6027454733848572, train_loss: 0.5972336530685425\n",
      "9060 val_loss: 0.6025205254554749, train_loss: 0.5970267653465271\n",
      "9070 val_loss: 0.6023300290107727, train_loss: 0.5968000292778015\n",
      "9080 val_loss: 0.6019940376281738, train_loss: 0.5964718461036682\n",
      "9090 val_loss: 0.6017762422561646, train_loss: 0.5962486267089844\n",
      "9100 val_loss: 0.601632833480835, train_loss: 0.5961016416549683\n",
      "9110 val_loss: 0.6014116406440735, train_loss: 0.5958660840988159\n",
      "9120 val_loss: 0.6010621190071106, train_loss: 0.5954433679580688\n",
      "9130 val_loss: 0.6007794737815857, train_loss: 0.595173180103302\n",
      "9140 val_loss: 0.6005731225013733, train_loss: 0.5949593186378479\n",
      "9150 val_loss: 0.6002886295318604, train_loss: 0.5946070551872253\n",
      "9160 val_loss: 0.5999720692634583, train_loss: 0.5942562818527222\n",
      "9170 val_loss: 0.5998095273971558, train_loss: 0.5940452218055725\n",
      "9180 val_loss: 0.5996493101119995, train_loss: 0.593842089176178\n",
      "9190 val_loss: 0.5994268655776978, train_loss: 0.5935869812965393\n",
      "9200 val_loss: 0.5992327332496643, train_loss: 0.5933942794799805\n",
      "9210 val_loss: 0.5989996790885925, train_loss: 0.593174934387207\n",
      "9220 val_loss: 0.5986890196800232, train_loss: 0.5928481221199036\n",
      "9230 val_loss: 0.5985109806060791, train_loss: 0.5926690697669983\n",
      "9240 val_loss: 0.5982812643051147, train_loss: 0.5924131274223328\n",
      "9250 val_loss: 0.5979249477386475, train_loss: 0.5920064449310303\n",
      "9260 val_loss: 0.5976634621620178, train_loss: 0.5917699933052063\n",
      "9270 val_loss: 0.5974752902984619, train_loss: 0.5916112661361694\n",
      "9280 val_loss: 0.5972895622253418, train_loss: 0.5914295315742493\n",
      "9290 val_loss: 0.5971662402153015, train_loss: 0.5912535786628723\n",
      "9300 val_loss: 0.5967982411384583, train_loss: 0.5908756852149963\n",
      "9310 val_loss: 0.5964882373809814, train_loss: 0.5905409455299377\n",
      "9320 val_loss: 0.5963453650474548, train_loss: 0.5903909206390381\n",
      "9330 val_loss: 0.5961251854896545, train_loss: 0.5901837348937988\n",
      "9340 val_loss: 0.5958998203277588, train_loss: 0.5899913311004639\n",
      "9350 val_loss: 0.5956023931503296, train_loss: 0.5896552801132202\n",
      "9360 val_loss: 0.5954376459121704, train_loss: 0.5894928574562073\n",
      "9370 val_loss: 0.5952674150466919, train_loss: 0.5892715454101562\n",
      "9380 val_loss: 0.5951289534568787, train_loss: 0.5891534090042114\n",
      "9390 val_loss: 0.5948630571365356, train_loss: 0.5889172554016113\n",
      "9400 val_loss: 0.5946469902992249, train_loss: 0.5886727571487427\n",
      "9410 val_loss: 0.594233512878418, train_loss: 0.5881940126419067\n",
      "9420 val_loss: 0.5939792394638062, train_loss: 0.5879005789756775\n",
      "9430 val_loss: 0.5936899185180664, train_loss: 0.58760666847229\n",
      "9440 val_loss: 0.5935259461402893, train_loss: 0.5874593257904053\n",
      "9450 val_loss: 0.5933101177215576, train_loss: 0.5872464179992676\n",
      "9460 val_loss: 0.5930843949317932, train_loss: 0.5870218873023987\n",
      "9470 val_loss: 0.5927724242210388, train_loss: 0.5866416692733765\n",
      "9480 val_loss: 0.5924715399742126, train_loss: 0.586308479309082\n",
      "9490 val_loss: 0.5921401977539062, train_loss: 0.585896909236908\n",
      "9500 val_loss: 0.591895341873169, train_loss: 0.5856070518493652\n",
      "9510 val_loss: 0.5914694666862488, train_loss: 0.5851515531539917\n",
      "9520 val_loss: 0.5913447737693787, train_loss: 0.5850788950920105\n",
      "9530 val_loss: 0.5910958051681519, train_loss: 0.5847897529602051\n",
      "9540 val_loss: 0.5909371972084045, train_loss: 0.5845671892166138\n",
      "9550 val_loss: 0.590343713760376, train_loss: 0.5838927030563354\n",
      "9560 val_loss: 0.5900057554244995, train_loss: 0.5834981203079224\n",
      "9570 val_loss: 0.5896832942962646, train_loss: 0.5830995440483093\n",
      "9580 val_loss: 0.5894397497177124, train_loss: 0.5828903913497925\n",
      "9590 val_loss: 0.589255154132843, train_loss: 0.5827212333679199\n",
      "9600 val_loss: 0.5888842940330505, train_loss: 0.5823197960853577\n",
      "9610 val_loss: 0.5886006355285645, train_loss: 0.582057774066925\n",
      "9620 val_loss: 0.58829665184021, train_loss: 0.5817552208900452\n",
      "9630 val_loss: 0.5880560874938965, train_loss: 0.5815241932868958\n",
      "9640 val_loss: 0.5878674983978271, train_loss: 0.5813866257667542\n",
      "9650 val_loss: 0.5876907706260681, train_loss: 0.5811983942985535\n",
      "9660 val_loss: 0.5874210596084595, train_loss: 0.5809050798416138\n",
      "9670 val_loss: 0.587178647518158, train_loss: 0.5806340575218201\n",
      "9680 val_loss: 0.586887001991272, train_loss: 0.580345869064331\n",
      "9690 val_loss: 0.5865892171859741, train_loss: 0.5799899697303772\n",
      "9700 val_loss: 0.5862934589385986, train_loss: 0.5796763300895691\n",
      "9710 val_loss: 0.5860385894775391, train_loss: 0.5793703198432922\n",
      "9720 val_loss: 0.5857601761817932, train_loss: 0.5790886878967285\n",
      "9730 val_loss: 0.5854649543762207, train_loss: 0.578761875629425\n",
      "9740 val_loss: 0.5852326154708862, train_loss: 0.5785036087036133\n",
      "9750 val_loss: 0.5849401950836182, train_loss: 0.5781667828559875\n",
      "9760 val_loss: 0.5847088098526001, train_loss: 0.577968418598175\n",
      "9770 val_loss: 0.58428555727005, train_loss: 0.577540397644043\n",
      "9780 val_loss: 0.5840451121330261, train_loss: 0.577247679233551\n",
      "9790 val_loss: 0.5836145877838135, train_loss: 0.5767443776130676\n",
      "9800 val_loss: 0.583364725112915, train_loss: 0.5764287710189819\n",
      "9810 val_loss: 0.5831676721572876, train_loss: 0.5762426853179932\n",
      "9820 val_loss: 0.582886815071106, train_loss: 0.575939953327179\n",
      "9830 val_loss: 0.5824981927871704, train_loss: 0.5755196809768677\n",
      "9840 val_loss: 0.5823493003845215, train_loss: 0.5753627419471741\n",
      "9850 val_loss: 0.581931471824646, train_loss: 0.5749329328536987\n",
      "9860 val_loss: 0.5816298127174377, train_loss: 0.5745758414268494\n",
      "9870 val_loss: 0.581308901309967, train_loss: 0.5742306113243103\n",
      "9880 val_loss: 0.5809393525123596, train_loss: 0.5738386511802673\n",
      "9890 val_loss: 0.5806494951248169, train_loss: 0.5735333561897278\n",
      "9900 val_loss: 0.5802875757217407, train_loss: 0.5731144547462463\n",
      "9910 val_loss: 0.5800772309303284, train_loss: 0.5728939175605774\n",
      "9920 val_loss: 0.5797643065452576, train_loss: 0.5725831389427185\n",
      "9930 val_loss: 0.5793384909629822, train_loss: 0.5721529722213745\n",
      "9940 val_loss: 0.5791270136833191, train_loss: 0.5719574093818665\n",
      "9950 val_loss: 0.5788201689720154, train_loss: 0.5716301798820496\n",
      "9960 val_loss: 0.5785157680511475, train_loss: 0.5713533163070679\n",
      "9970 val_loss: 0.5782329440116882, train_loss: 0.5710628032684326\n",
      "9980 val_loss: 0.5778932571411133, train_loss: 0.5707231163978577\n",
      "9990 val_loss: 0.5776543617248535, train_loss: 0.5704967379570007\n",
      "10000 val_loss: 0.5774194598197937, train_loss: 0.5702510476112366\n",
      "10010 val_loss: 0.5773629546165466, train_loss: 0.5701700448989868\n",
      "10020 val_loss: 0.5768238306045532, train_loss: 0.5695633292198181\n",
      "10030 val_loss: 0.5763315558433533, train_loss: 0.5690476298332214\n",
      "10040 val_loss: 0.5760288834571838, train_loss: 0.5687344670295715\n",
      "10050 val_loss: 0.5757763981819153, train_loss: 0.5684848427772522\n",
      "10060 val_loss: 0.5754528045654297, train_loss: 0.568124532699585\n",
      "10070 val_loss: 0.5751451849937439, train_loss: 0.5677820444107056\n",
      "10080 val_loss: 0.5749239921569824, train_loss: 0.5676028728485107\n",
      "10090 val_loss: 0.5745517015457153, train_loss: 0.5671694278717041\n",
      "10100 val_loss: 0.5742908716201782, train_loss: 0.5669286847114563\n",
      "10110 val_loss: 0.5739108324050903, train_loss: 0.5664684176445007\n",
      "10120 val_loss: 0.573644757270813, train_loss: 0.5662109851837158\n",
      "10130 val_loss: 0.5732629299163818, train_loss: 0.5657722353935242\n",
      "10140 val_loss: 0.5730913877487183, train_loss: 0.5656365156173706\n",
      "10150 val_loss: 0.5727499723434448, train_loss: 0.5652396082878113\n",
      "10160 val_loss: 0.5723677277565002, train_loss: 0.5648450255393982\n",
      "10170 val_loss: 0.5719706416130066, train_loss: 0.5643985867500305\n",
      "10180 val_loss: 0.5716858506202698, train_loss: 0.5641154050827026\n",
      "10190 val_loss: 0.5714209079742432, train_loss: 0.5638176202774048\n",
      "10200 val_loss: 0.5709198117256165, train_loss: 0.5632746815681458\n",
      "10210 val_loss: 0.5705019235610962, train_loss: 0.5628265142440796\n",
      "10220 val_loss: 0.5701428055763245, train_loss: 0.5624484419822693\n",
      "10230 val_loss: 0.5699131488800049, train_loss: 0.5622345209121704\n",
      "10240 val_loss: 0.5696068406105042, train_loss: 0.5618889331817627\n",
      "10250 val_loss: 0.5692439675331116, train_loss: 0.5615177750587463\n",
      "10260 val_loss: 0.5689243674278259, train_loss: 0.56122225522995\n",
      "10270 val_loss: 0.5686547160148621, train_loss: 0.5609467625617981\n",
      "10280 val_loss: 0.5684217810630798, train_loss: 0.5607150793075562\n",
      "10290 val_loss: 0.5682284235954285, train_loss: 0.5605490803718567\n",
      "10300 val_loss: 0.567736804485321, train_loss: 0.5599808692932129\n",
      "10310 val_loss: 0.5675344467163086, train_loss: 0.5597550272941589\n",
      "10320 val_loss: 0.5672495365142822, train_loss: 0.5594983696937561\n",
      "10330 val_loss: 0.5668889880180359, train_loss: 0.5591261982917786\n",
      "10340 val_loss: 0.5666748881340027, train_loss: 0.5588945150375366\n",
      "10350 val_loss: 0.5663196444511414, train_loss: 0.5585318207740784\n",
      "10360 val_loss: 0.5659646987915039, train_loss: 0.55815589427948\n",
      "10370 val_loss: 0.5656262636184692, train_loss: 0.5577781796455383\n",
      "10380 val_loss: 0.5652185678482056, train_loss: 0.5573444366455078\n",
      "10390 val_loss: 0.5648983120918274, train_loss: 0.5570050477981567\n",
      "10400 val_loss: 0.5645145773887634, train_loss: 0.5565413236618042\n",
      "10410 val_loss: 0.564189612865448, train_loss: 0.5562214851379395\n",
      "10420 val_loss: 0.5639157891273499, train_loss: 0.5559539198875427\n",
      "10430 val_loss: 0.5635023713111877, train_loss: 0.5555050373077393\n",
      "10440 val_loss: 0.5633106827735901, train_loss: 0.5553816556930542\n",
      "10450 val_loss: 0.5630913376808167, train_loss: 0.5551497340202332\n",
      "10460 val_loss: 0.5628302097320557, train_loss: 0.5548932552337646\n",
      "10470 val_loss: 0.5623108744621277, train_loss: 0.5542972087860107\n",
      "10480 val_loss: 0.5619653463363647, train_loss: 0.5539361834526062\n",
      "10490 val_loss: 0.5616437196731567, train_loss: 0.5536064505577087\n",
      "10500 val_loss: 0.5612541437149048, train_loss: 0.5531755685806274\n",
      "10510 val_loss: 0.5609018206596375, train_loss: 0.5527909994125366\n",
      "10520 val_loss: 0.5606153011322021, train_loss: 0.5524827241897583\n",
      "10530 val_loss: 0.560498833656311, train_loss: 0.5523829460144043\n",
      "10540 val_loss: 0.5599297881126404, train_loss: 0.5517464876174927\n",
      "10550 val_loss: 0.5594953298568726, train_loss: 0.5512663722038269\n",
      "10560 val_loss: 0.5592498183250427, train_loss: 0.5510136485099792\n",
      "10570 val_loss: 0.5588636994361877, train_loss: 0.5506072044372559\n",
      "10580 val_loss: 0.5585899949073792, train_loss: 0.5503410696983337\n",
      "10590 val_loss: 0.5583357810974121, train_loss: 0.5500828623771667\n",
      "10600 val_loss: 0.558046281337738, train_loss: 0.5497644543647766\n",
      "10610 val_loss: 0.5578098893165588, train_loss: 0.549593985080719\n",
      "10620 val_loss: 0.5574959516525269, train_loss: 0.5492779016494751\n",
      "10630 val_loss: 0.5570995807647705, train_loss: 0.5488172173500061\n",
      "10640 val_loss: 0.5567594170570374, train_loss: 0.5484362244606018\n",
      "10650 val_loss: 0.5563912987709045, train_loss: 0.5480079650878906\n",
      "10660 val_loss: 0.5559760928153992, train_loss: 0.5475344657897949\n",
      "10670 val_loss: 0.5558018684387207, train_loss: 0.5473756790161133\n",
      "10680 val_loss: 0.5556779503822327, train_loss: 0.5472854971885681\n",
      "10690 val_loss: 0.5550508499145508, train_loss: 0.5465224385261536\n",
      "10700 val_loss: 0.5549638867378235, train_loss: 0.5464780330657959\n",
      "10710 val_loss: 0.5543504357337952, train_loss: 0.5457228422164917\n",
      "10720 val_loss: 0.5541853308677673, train_loss: 0.5455906391143799\n",
      "10730 val_loss: 0.5539259314537048, train_loss: 0.5453291535377502\n",
      "10740 val_loss: 0.5534562468528748, train_loss: 0.5447465777397156\n",
      "10750 val_loss: 0.553164541721344, train_loss: 0.5444806814193726\n",
      "10760 val_loss: 0.5530070066452026, train_loss: 0.5443980097770691\n",
      "10770 val_loss: 0.5527543425559998, train_loss: 0.5441731214523315\n",
      "10780 val_loss: 0.5522118210792542, train_loss: 0.5435084104537964\n",
      "10790 val_loss: 0.5518790483474731, train_loss: 0.5431824922561646\n",
      "10800 val_loss: 0.5519312620162964, train_loss: 0.5433722734451294\n",
      "10810 val_loss: 0.5515374541282654, train_loss: 0.5428867340087891\n",
      "10820 val_loss: 0.5512387156486511, train_loss: 0.5425648093223572\n",
      "10830 val_loss: 0.5510101318359375, train_loss: 0.542306661605835\n",
      "10840 val_loss: 0.5505537390708923, train_loss: 0.5417647361755371\n",
      "10850 val_loss: 0.5502777099609375, train_loss: 0.5415079593658447\n",
      "10860 val_loss: 0.5499824285507202, train_loss: 0.5412222146987915\n",
      "10870 val_loss: 0.5496680736541748, train_loss: 0.540873110294342\n",
      "10880 val_loss: 0.5493587255477905, train_loss: 0.540568470954895\n",
      "10890 val_loss: 0.5493305921554565, train_loss: 0.5406416058540344\n",
      "10900 val_loss: 0.5488827228546143, train_loss: 0.5401054620742798\n",
      "10910 val_loss: 0.548342227935791, train_loss: 0.5394341945648193\n",
      "10920 val_loss: 0.548056423664093, train_loss: 0.5391234755516052\n",
      "10930 val_loss: 0.5477979183197021, train_loss: 0.5388708114624023\n",
      "10940 val_loss: 0.5475668907165527, train_loss: 0.5386070609092712\n",
      "10950 val_loss: 0.5473179221153259, train_loss: 0.5383606553077698\n",
      "10960 val_loss: 0.5469912886619568, train_loss: 0.5379868149757385\n",
      "10970 val_loss: 0.546795666217804, train_loss: 0.5378389954566956\n",
      "10980 val_loss: 0.5463294386863708, train_loss: 0.5372572541236877\n",
      "10990 val_loss: 0.5462316274642944, train_loss: 0.5372329950332642\n",
      "11000 val_loss: 0.5457779765129089, train_loss: 0.5366898775100708\n",
      "11010 val_loss: 0.5454602241516113, train_loss: 0.5363476276397705\n",
      "11020 val_loss: 0.5453341603279114, train_loss: 0.5362626910209656\n",
      "11030 val_loss: 0.545066773891449, train_loss: 0.5359988212585449\n",
      "11040 val_loss: 0.5447216629981995, train_loss: 0.5356152057647705\n",
      "11050 val_loss: 0.5445978045463562, train_loss: 0.5355092883110046\n",
      "11060 val_loss: 0.544341504573822, train_loss: 0.5352336764335632\n",
      "11070 val_loss: 0.5438299775123596, train_loss: 0.5346320867538452\n",
      "11080 val_loss: 0.5435200333595276, train_loss: 0.5342763662338257\n",
      "11090 val_loss: 0.5432431101799011, train_loss: 0.533976674079895\n",
      "11100 val_loss: 0.5429503917694092, train_loss: 0.5336604118347168\n",
      "11110 val_loss: 0.5427379608154297, train_loss: 0.5334739685058594\n",
      "11120 val_loss: 0.5424574613571167, train_loss: 0.5331733226776123\n",
      "11130 val_loss: 0.5422173142433167, train_loss: 0.532943069934845\n",
      "11140 val_loss: 0.5419338941574097, train_loss: 0.5326095223426819\n",
      "11150 val_loss: 0.5417100191116333, train_loss: 0.5324071049690247\n",
      "11160 val_loss: 0.5415191650390625, train_loss: 0.5322275161743164\n",
      "11170 val_loss: 0.5412561297416687, train_loss: 0.5318809747695923\n",
      "11180 val_loss: 0.5409205555915833, train_loss: 0.5315792560577393\n",
      "11190 val_loss: 0.5406506061553955, train_loss: 0.5312752723693848\n",
      "11200 val_loss: 0.5404106378555298, train_loss: 0.5310927033424377\n",
      "11210 val_loss: 0.5402618050575256, train_loss: 0.5309973955154419\n",
      "11220 val_loss: 0.5402031540870667, train_loss: 0.5310099124908447\n",
      "11230 val_loss: 0.5397875308990479, train_loss: 0.530514657497406\n",
      "11240 val_loss: 0.5396931767463684, train_loss: 0.5304688215255737\n",
      "11250 val_loss: 0.539294421672821, train_loss: 0.5299887657165527\n",
      "11260 val_loss: 0.5390561819076538, train_loss: 0.5297805070877075\n",
      "11270 val_loss: 0.5387855768203735, train_loss: 0.529451310634613\n",
      "11280 val_loss: 0.5385828614234924, train_loss: 0.5292654037475586\n",
      "11290 val_loss: 0.5383066534996033, train_loss: 0.5289729833602905\n",
      "11300 val_loss: 0.5379864573478699, train_loss: 0.5286397337913513\n",
      "11310 val_loss: 0.5377326011657715, train_loss: 0.5283640027046204\n",
      "11320 val_loss: 0.5375616550445557, train_loss: 0.5282120108604431\n",
      "11330 val_loss: 0.537287175655365, train_loss: 0.5279056429862976\n",
      "11340 val_loss: 0.5371476411819458, train_loss: 0.5278273820877075\n",
      "11350 val_loss: 0.5367738604545593, train_loss: 0.5273858904838562\n",
      "11360 val_loss: 0.5364882946014404, train_loss: 0.5270468592643738\n",
      "11370 val_loss: 0.5361925363540649, train_loss: 0.5266813039779663\n",
      "11380 val_loss: 0.5359415411949158, train_loss: 0.5264703035354614\n",
      "11390 val_loss: 0.5356581807136536, train_loss: 0.5261118412017822\n",
      "11400 val_loss: 0.5354494452476501, train_loss: 0.5259354710578918\n",
      "11410 val_loss: 0.5353119969367981, train_loss: 0.5258477330207825\n",
      "11420 val_loss: 0.5349893569946289, train_loss: 0.5254616141319275\n",
      "11430 val_loss: 0.5347290635108948, train_loss: 0.5251802802085876\n",
      "11440 val_loss: 0.5344167351722717, train_loss: 0.5247588753700256\n",
      "11450 val_loss: 0.5343737006187439, train_loss: 0.5248399376869202\n",
      "11460 val_loss: 0.534013032913208, train_loss: 0.5243377089500427\n",
      "11470 val_loss: 0.5338497757911682, train_loss: 0.5242747068405151\n",
      "11480 val_loss: 0.5334798693656921, train_loss: 0.5238608121871948\n",
      "11490 val_loss: 0.5336185693740845, train_loss: 0.5241659283638\n",
      "11500 val_loss: 0.5335941910743713, train_loss: 0.5242010354995728\n",
      "11510 val_loss: 0.5328850746154785, train_loss: 0.5232945680618286\n",
      "11520 val_loss: 0.5325130224227905, train_loss: 0.5226234793663025\n",
      "11530 val_loss: 0.53230881690979, train_loss: 0.5224769711494446\n",
      "11540 val_loss: 0.5321125388145447, train_loss: 0.5224030613899231\n",
      "11550 val_loss: 0.5322295427322388, train_loss: 0.522714376449585\n",
      "11560 val_loss: 0.5319086313247681, train_loss: 0.5223071575164795\n",
      "11570 val_loss: 0.5318574905395508, train_loss: 0.5223057866096497\n",
      "11580 val_loss: 0.531832218170166, train_loss: 0.5223568677902222\n",
      "11590 val_loss: 0.5313714742660522, train_loss: 0.5217691659927368\n",
      "11600 val_loss: 0.5309927463531494, train_loss: 0.5213118195533752\n",
      "11610 val_loss: 0.5308602452278137, train_loss: 0.5211753249168396\n",
      "11620 val_loss: 0.5306131839752197, train_loss: 0.5208706259727478\n",
      "11630 val_loss: 0.5306696891784668, train_loss: 0.521025538444519\n",
      "11640 val_loss: 0.5301162600517273, train_loss: 0.5203254818916321\n",
      "11650 val_loss: 0.5299199819564819, train_loss: 0.520155668258667\n",
      "11660 val_loss: 0.529726505279541, train_loss: 0.5199649333953857\n",
      "11670 val_loss: 0.5296099781990051, train_loss: 0.5198855400085449\n",
      "11680 val_loss: 0.529410719871521, train_loss: 0.5196905136108398\n",
      "11690 val_loss: 0.5291627645492554, train_loss: 0.5194003582000732\n",
      "11700 val_loss: 0.5293243527412415, train_loss: 0.519659698009491\n",
      "11710 val_loss: 0.5292943120002747, train_loss: 0.5196714997291565\n",
      "11720 val_loss: 0.5288470983505249, train_loss: 0.5191565752029419\n",
      "11730 val_loss: 0.5283051133155823, train_loss: 0.5184212327003479\n",
      "11740 val_loss: 0.5280880331993103, train_loss: 0.5180241465568542\n",
      "11750 val_loss: 0.5277289152145386, train_loss: 0.5177162885665894\n",
      "11760 val_loss: 0.5277060270309448, train_loss: 0.5178467631340027\n",
      "11770 val_loss: 0.5274457931518555, train_loss: 0.5175346732139587\n",
      "11780 val_loss: 0.5271153450012207, train_loss: 0.5170729160308838\n",
      "11790 val_loss: 0.5269227027893066, train_loss: 0.516884982585907\n",
      "11800 val_loss: 0.5270096063613892, train_loss: 0.5172381401062012\n",
      "11810 val_loss: 0.526832103729248, train_loss: 0.517015814781189\n",
      "11820 val_loss: 0.5265405774116516, train_loss: 0.5165566802024841\n",
      "11830 val_loss: 0.5263234376907349, train_loss: 0.5164034366607666\n",
      "11840 val_loss: 0.5262691974639893, train_loss: 0.5163630843162537\n",
      "11850 val_loss: 0.526501476764679, train_loss: 0.5167770385742188\n",
      "11860 val_loss: 0.5257575511932373, train_loss: 0.5157963037490845\n",
      "11870 val_loss: 0.5254612565040588, train_loss: 0.5154927372932434\n",
      "11880 val_loss: 0.5253033638000488, train_loss: 0.5153615474700928\n",
      "11890 val_loss: 0.5251179933547974, train_loss: 0.515055239200592\n",
      "11900 val_loss: 0.5249831676483154, train_loss: 0.5149459838867188\n",
      "11910 val_loss: 0.524813175201416, train_loss: 0.5148293375968933\n",
      "11920 val_loss: 0.5247048735618591, train_loss: 0.5148576498031616\n",
      "11930 val_loss: 0.5246121287345886, train_loss: 0.5148224830627441\n",
      "11940 val_loss: 0.5244219303131104, train_loss: 0.5145670175552368\n",
      "11950 val_loss: 0.5242742896080017, train_loss: 0.5144152641296387\n",
      "11960 val_loss: 0.5241506695747375, train_loss: 0.5142419338226318\n",
      "11970 val_loss: 0.5238698124885559, train_loss: 0.514032244682312\n",
      "11980 val_loss: 0.523759126663208, train_loss: 0.5140131711959839\n",
      "11990 val_loss: 0.5236150622367859, train_loss: 0.5138466358184814\n",
      "12000 val_loss: 0.5233768820762634, train_loss: 0.5135912895202637\n",
      "12010 val_loss: 0.5230538845062256, train_loss: 0.5131405591964722\n",
      "12020 val_loss: 0.5228259563446045, train_loss: 0.5128570795059204\n",
      "12030 val_loss: 0.522666871547699, train_loss: 0.5126816034317017\n",
      "12040 val_loss: 0.5226022005081177, train_loss: 0.5127126574516296\n",
      "12050 val_loss: 0.5226638913154602, train_loss: 0.5128424167633057\n",
      "12060 val_loss: 0.5220968127250671, train_loss: 0.5121126770973206\n",
      "12070 val_loss: 0.5220862627029419, train_loss: 0.5122320055961609\n",
      "12080 val_loss: 0.5218111276626587, train_loss: 0.5118812918663025\n",
      "12090 val_loss: 0.5216850638389587, train_loss: 0.5117709040641785\n",
      "12100 val_loss: 0.5213552117347717, train_loss: 0.5113500356674194\n",
      "12110 val_loss: 0.5212122201919556, train_loss: 0.5111860632896423\n",
      "12120 val_loss: 0.5211241841316223, train_loss: 0.5111294388771057\n",
      "12130 val_loss: 0.5211418271064758, train_loss: 0.5112226009368896\n",
      "12140 val_loss: 0.5208055973052979, train_loss: 0.5108607411384583\n",
      "12150 val_loss: 0.5205429196357727, train_loss: 0.5104544758796692\n",
      "12160 val_loss: 0.5208848714828491, train_loss: 0.5110226273536682\n",
      "12170 val_loss: 0.5201711654663086, train_loss: 0.5100783109664917\n",
      "12180 val_loss: 0.5201067328453064, train_loss: 0.5100517272949219\n",
      "12190 val_loss: 0.5198987126350403, train_loss: 0.5097599029541016\n",
      "12200 val_loss: 0.5196850895881653, train_loss: 0.509502112865448\n",
      "12210 val_loss: 0.5196011662483215, train_loss: 0.5094944834709167\n",
      "12220 val_loss: 0.5195282101631165, train_loss: 0.5094618797302246\n",
      "12230 val_loss: 0.5193484425544739, train_loss: 0.5092352032661438\n",
      "12240 val_loss: 0.5192191004753113, train_loss: 0.5090953707695007\n",
      "12250 val_loss: 0.5192424058914185, train_loss: 0.5091955065727234\n",
      "12260 val_loss: 0.5187684893608093, train_loss: 0.5085144639015198\n",
      "12270 val_loss: 0.5186184644699097, train_loss: 0.5083789229393005\n",
      "12280 val_loss: 0.5186033844947815, train_loss: 0.5084332227706909\n",
      "12290 val_loss: 0.5184475779533386, train_loss: 0.508280336856842\n",
      "12300 val_loss: 0.518144965171814, train_loss: 0.5079331994056702\n",
      "12310 val_loss: 0.5180100798606873, train_loss: 0.5077977776527405\n",
      "12320 val_loss: 0.5180045366287231, train_loss: 0.5078549385070801\n",
      "12330 val_loss: 0.5176199674606323, train_loss: 0.5073156952857971\n",
      "12340 val_loss: 0.5174664855003357, train_loss: 0.5070416331291199\n",
      "12350 val_loss: 0.5174893736839294, train_loss: 0.5072693228721619\n",
      "12360 val_loss: 0.5174289345741272, train_loss: 0.5072497129440308\n",
      "12370 val_loss: 0.5170453190803528, train_loss: 0.5066815614700317\n",
      "12380 val_loss: 0.5169454216957092, train_loss: 0.5066368579864502\n",
      "12390 val_loss: 0.5167295336723328, train_loss: 0.5063299536705017\n",
      "12400 val_loss: 0.5165466070175171, train_loss: 0.5060613751411438\n",
      "12410 val_loss: 0.5163351893424988, train_loss: 0.5058291554450989\n",
      "12420 val_loss: 0.516351580619812, train_loss: 0.5060112476348877\n",
      "12430 val_loss: 0.516197919845581, train_loss: 0.5058359503746033\n",
      "12440 val_loss: 0.5162251591682434, train_loss: 0.5058844089508057\n",
      "12450 val_loss: 0.5159046053886414, train_loss: 0.5054696798324585\n",
      "12460 val_loss: 0.5156872868537903, train_loss: 0.5052164196968079\n",
      "12470 val_loss: 0.5154727101325989, train_loss: 0.5049052834510803\n",
      "12480 val_loss: 0.5154039859771729, train_loss: 0.5049291253089905\n",
      "12490 val_loss: 0.5154390931129456, train_loss: 0.5051215291023254\n",
      "12500 val_loss: 0.5153781175613403, train_loss: 0.5050793290138245\n",
      "12510 val_loss: 0.5151126980781555, train_loss: 0.5047447681427002\n",
      "12520 val_loss: 0.5150218605995178, train_loss: 0.5046977996826172\n",
      "12530 val_loss: 0.5148515105247498, train_loss: 0.5045180916786194\n",
      "12540 val_loss: 0.5147480964660645, train_loss: 0.5043764114379883\n",
      "12550 val_loss: 0.5145881175994873, train_loss: 0.5042319297790527\n",
      "12560 val_loss: 0.5144249796867371, train_loss: 0.5038197636604309\n",
      "12570 val_loss: 0.5142722725868225, train_loss: 0.5037847757339478\n",
      "12580 val_loss: 0.5142613649368286, train_loss: 0.5038760304450989\n",
      "12590 val_loss: 0.5140789151191711, train_loss: 0.5037248134613037\n",
      "12600 val_loss: 0.5141521692276001, train_loss: 0.5039126873016357\n",
      "12610 val_loss: 0.5136646032333374, train_loss: 0.5032451152801514\n",
      "12620 val_loss: 0.5134782195091248, train_loss: 0.5028939843177795\n",
      "12630 val_loss: 0.5133341550827026, train_loss: 0.5027065873146057\n",
      "12640 val_loss: 0.5132134556770325, train_loss: 0.5027400255203247\n",
      "12650 val_loss: 0.5130327939987183, train_loss: 0.5024912357330322\n",
      "12660 val_loss: 0.5129145383834839, train_loss: 0.5024765729904175\n",
      "12670 val_loss: 0.5128300786018372, train_loss: 0.5023850202560425\n",
      "12680 val_loss: 0.5125799775123596, train_loss: 0.5019540786743164\n",
      "12690 val_loss: 0.5125429034233093, train_loss: 0.5020963549613953\n",
      "12700 val_loss: 0.5125097632408142, train_loss: 0.502094566822052\n",
      "12710 val_loss: 0.5123763680458069, train_loss: 0.5019765496253967\n",
      "12720 val_loss: 0.5121325850486755, train_loss: 0.501672625541687\n",
      "12730 val_loss: 0.5121515989303589, train_loss: 0.5017301440238953\n",
      "12740 val_loss: 0.5121366381645203, train_loss: 0.5017722845077515\n",
      "12750 val_loss: 0.5120649933815002, train_loss: 0.5016996264457703\n",
      "12760 val_loss: 0.5116828083992004, train_loss: 0.5012140274047852\n",
      "12770 val_loss: 0.5115053057670593, train_loss: 0.5010040402412415\n",
      "12780 val_loss: 0.511554479598999, train_loss: 0.5011223554611206\n",
      "12790 val_loss: 0.511242687702179, train_loss: 0.5007904171943665\n",
      "12800 val_loss: 0.5112261772155762, train_loss: 0.5008307695388794\n",
      "12810 val_loss: 0.5109577775001526, train_loss: 0.5004762411117554\n",
      "12820 val_loss: 0.5108151435852051, train_loss: 0.5003321766853333\n",
      "12830 val_loss: 0.5106780529022217, train_loss: 0.500160276889801\n",
      "12840 val_loss: 0.5105314254760742, train_loss: 0.4999934434890747\n",
      "12850 val_loss: 0.5103838443756104, train_loss: 0.4998318552970886\n",
      "12860 val_loss: 0.5102672576904297, train_loss: 0.4996103048324585\n",
      "12870 val_loss: 0.5101932287216187, train_loss: 0.4996901750564575\n",
      "12880 val_loss: 0.510057806968689, train_loss: 0.4995071589946747\n",
      "12890 val_loss: 0.5100054740905762, train_loss: 0.49944594502449036\n",
      "12900 val_loss: 0.5099210143089294, train_loss: 0.4993134140968323\n",
      "12910 val_loss: 0.5098368525505066, train_loss: 0.49913489818573\n",
      "12920 val_loss: 0.509773850440979, train_loss: 0.4990450143814087\n",
      "12930 val_loss: 0.5096426010131836, train_loss: 0.49900108575820923\n",
      "12940 val_loss: 0.5095333456993103, train_loss: 0.4989086091518402\n",
      "12950 val_loss: 0.5094765424728394, train_loss: 0.49890610575675964\n",
      "12960 val_loss: 0.5093212723731995, train_loss: 0.4986884891986847\n",
      "12970 val_loss: 0.5092174410820007, train_loss: 0.49866461753845215\n",
      "12980 val_loss: 0.5090534090995789, train_loss: 0.49844929575920105\n",
      "12990 val_loss: 0.5094498991966248, train_loss: 0.49912434816360474\n",
      "13000 val_loss: 0.5091387629508972, train_loss: 0.49873295426368713\n",
      "13010 val_loss: 0.5087324976921082, train_loss: 0.4980661869049072\n",
      "13020 val_loss: 0.508644163608551, train_loss: 0.4979744255542755\n",
      "13030 val_loss: 0.5084070563316345, train_loss: 0.49773064255714417\n",
      "13040 val_loss: 0.5082855224609375, train_loss: 0.49738433957099915\n",
      "13050 val_loss: 0.5080845355987549, train_loss: 0.49726060032844543\n",
      "13060 val_loss: 0.5079614520072937, train_loss: 0.4971369206905365\n",
      "13070 val_loss: 0.507978081703186, train_loss: 0.4974379539489746\n",
      "13080 val_loss: 0.507767379283905, train_loss: 0.49714139103889465\n",
      "13090 val_loss: 0.50776606798172, train_loss: 0.49718156456947327\n",
      "13100 val_loss: 0.5075353384017944, train_loss: 0.49680861830711365\n",
      "13110 val_loss: 0.5073805451393127, train_loss: 0.4965934753417969\n",
      "13120 val_loss: 0.5074548125267029, train_loss: 0.49650320410728455\n",
      "13130 val_loss: 0.5072232484817505, train_loss: 0.496421217918396\n",
      "13140 val_loss: 0.5071107745170593, train_loss: 0.4963620901107788\n",
      "13150 val_loss: 0.5071030855178833, train_loss: 0.49631762504577637\n",
      "13160 val_loss: 0.5068989396095276, train_loss: 0.4962005019187927\n",
      "13170 val_loss: 0.5067615509033203, train_loss: 0.4960853159427643\n",
      "13180 val_loss: 0.5067267417907715, train_loss: 0.4959743618965149\n",
      "13190 val_loss: 0.5067248344421387, train_loss: 0.496168315410614\n",
      "13200 val_loss: 0.506951630115509, train_loss: 0.49646860361099243\n",
      "13210 val_loss: 0.5065324902534485, train_loss: 0.4959529638290405\n",
      "13220 val_loss: 0.5064476728439331, train_loss: 0.49588799476623535\n",
      "13230 val_loss: 0.5063633322715759, train_loss: 0.49580904841423035\n",
      "13240 val_loss: 0.5061848163604736, train_loss: 0.4955809712409973\n",
      "13250 val_loss: 0.5060281753540039, train_loss: 0.49536779522895813\n",
      "13260 val_loss: 0.5059309005737305, train_loss: 0.4950921833515167\n",
      "13270 val_loss: 0.5057362914085388, train_loss: 0.49497711658477783\n",
      "13280 val_loss: 0.5057315826416016, train_loss: 0.4951368272304535\n",
      "13290 val_loss: 0.5054659247398376, train_loss: 0.4946531355381012\n",
      "13300 val_loss: 0.5053895115852356, train_loss: 0.49471384286880493\n",
      "13310 val_loss: 0.5053682327270508, train_loss: 0.4947458803653717\n",
      "13320 val_loss: 0.5052058696746826, train_loss: 0.4944804608821869\n",
      "13330 val_loss: 0.5050886273384094, train_loss: 0.49443745613098145\n",
      "13340 val_loss: 0.5050212740898132, train_loss: 0.4943697452545166\n",
      "13350 val_loss: 0.505230724811554, train_loss: 0.49471989274024963\n",
      "13360 val_loss: 0.504814624786377, train_loss: 0.4941691756248474\n",
      "13370 val_loss: 0.5047203898429871, train_loss: 0.49399763345718384\n",
      "13380 val_loss: 0.5046849250793457, train_loss: 0.4940855801105499\n",
      "13390 val_loss: 0.5045533776283264, train_loss: 0.49391332268714905\n",
      "13400 val_loss: 0.504441499710083, train_loss: 0.49362221360206604\n",
      "13410 val_loss: 0.5044528245925903, train_loss: 0.49378833174705505\n",
      "13420 val_loss: 0.504372775554657, train_loss: 0.49366143345832825\n",
      "13430 val_loss: 0.5044623017311096, train_loss: 0.4939142167568207\n",
      "13440 val_loss: 0.5048641562461853, train_loss: 0.49445176124572754\n",
      "13450 val_loss: 0.5042568445205688, train_loss: 0.49367043375968933\n",
      "13460 val_loss: 0.5041640400886536, train_loss: 0.4935888946056366\n",
      "13470 val_loss: 0.5042842626571655, train_loss: 0.49378320574760437\n",
      "13480 val_loss: 0.504327654838562, train_loss: 0.4938563406467438\n",
      "13490 val_loss: 0.5039980411529541, train_loss: 0.49344465136528015\n",
      "13500 val_loss: 0.5035734176635742, train_loss: 0.4929015636444092\n",
      "13510 val_loss: 0.5033224821090698, train_loss: 0.49249961972236633\n",
      "13520 val_loss: 0.5032192468643188, train_loss: 0.49246811866760254\n",
      "13530 val_loss: 0.5031097531318665, train_loss: 0.49224793910980225\n",
      "13540 val_loss: 0.5029723644256592, train_loss: 0.49209004640579224\n",
      "13550 val_loss: 0.5028783082962036, train_loss: 0.49202460050582886\n",
      "13560 val_loss: 0.5029987692832947, train_loss: 0.49230363965034485\n",
      "13570 val_loss: 0.5026606917381287, train_loss: 0.49182868003845215\n",
      "13580 val_loss: 0.5024898052215576, train_loss: 0.4916364848613739\n",
      "13590 val_loss: 0.5024405121803284, train_loss: 0.4916172921657562\n",
      "13600 val_loss: 0.5023236274719238, train_loss: 0.49148115515708923\n",
      "13610 val_loss: 0.5022346377372742, train_loss: 0.4914136528968811\n",
      "13620 val_loss: 0.5023084878921509, train_loss: 0.49158141016960144\n",
      "13630 val_loss: 0.5020073056221008, train_loss: 0.49116426706314087\n",
      "13640 val_loss: 0.5021310448646545, train_loss: 0.49138757586479187\n",
      "13650 val_loss: 0.5019802451133728, train_loss: 0.491198867559433\n",
      "13660 val_loss: 0.5018107891082764, train_loss: 0.49089208245277405\n",
      "13670 val_loss: 0.5016830563545227, train_loss: 0.49079716205596924\n",
      "13680 val_loss: 0.5015995502471924, train_loss: 0.4907904267311096\n",
      "13690 val_loss: 0.5014199018478394, train_loss: 0.4904897212982178\n",
      "13700 val_loss: 0.5012786984443665, train_loss: 0.4902947247028351\n",
      "13710 val_loss: 0.5012269616127014, train_loss: 0.49023228883743286\n",
      "13720 val_loss: 0.5016239285469055, train_loss: 0.490927129983902\n",
      "13730 val_loss: 0.5014104843139648, train_loss: 0.4907208979129791\n",
      "13740 val_loss: 0.5011945962905884, train_loss: 0.49041467905044556\n",
      "13750 val_loss: 0.500992476940155, train_loss: 0.49012890458106995\n",
      "13760 val_loss: 0.5008605122566223, train_loss: 0.48987212777137756\n",
      "13770 val_loss: 0.5008842349052429, train_loss: 0.49007681012153625\n",
      "13780 val_loss: 0.5008700489997864, train_loss: 0.49008965492248535\n",
      "13790 val_loss: 0.5008401870727539, train_loss: 0.49012917280197144\n",
      "13800 val_loss: 0.5006287693977356, train_loss: 0.489826500415802\n",
      "13810 val_loss: 0.5004370808601379, train_loss: 0.48961707949638367\n",
      "13820 val_loss: 0.5003515481948853, train_loss: 0.4895993769168854\n",
      "13830 val_loss: 0.5002381205558777, train_loss: 0.4894583821296692\n",
      "13840 val_loss: 0.5003405213356018, train_loss: 0.4896412491798401\n",
      "13850 val_loss: 0.500315248966217, train_loss: 0.48960742354393005\n",
      "13860 val_loss: 0.5000568628311157, train_loss: 0.4893237352371216\n",
      "13870 val_loss: 0.49991199374198914, train_loss: 0.4891113340854645\n",
      "13880 val_loss: 0.49980297684669495, train_loss: 0.4890017807483673\n",
      "13890 val_loss: 0.49967190623283386, train_loss: 0.4888128936290741\n",
      "13900 val_loss: 0.49983441829681396, train_loss: 0.4890940189361572\n",
      "13910 val_loss: 0.49959617853164673, train_loss: 0.48877713084220886\n",
      "13920 val_loss: 0.49949008226394653, train_loss: 0.48853835463523865\n",
      "13930 val_loss: 0.4993669092655182, train_loss: 0.48857101798057556\n",
      "13940 val_loss: 0.4992794990539551, train_loss: 0.4885120391845703\n",
      "13950 val_loss: 0.49921321868896484, train_loss: 0.48844003677368164\n",
      "13960 val_loss: 0.4992228150367737, train_loss: 0.48849010467529297\n",
      "13970 val_loss: 0.49917033314704895, train_loss: 0.4884677827358246\n",
      "13980 val_loss: 0.4990825653076172, train_loss: 0.48836439847946167\n",
      "13990 val_loss: 0.4987953305244446, train_loss: 0.4879264831542969\n",
      "14000 val_loss: 0.4987950026988983, train_loss: 0.4877716302871704\n",
      "14010 val_loss: 0.49874255061149597, train_loss: 0.48778071999549866\n",
      "14020 val_loss: 0.4986216127872467, train_loss: 0.487862765789032\n",
      "14030 val_loss: 0.4985768496990204, train_loss: 0.4878290891647339\n",
      "14040 val_loss: 0.4985120892524719, train_loss: 0.48772817850112915\n",
      "14050 val_loss: 0.49832865595817566, train_loss: 0.48750174045562744\n",
      "14060 val_loss: 0.49820661544799805, train_loss: 0.48735731840133667\n",
      "14070 val_loss: 0.49839094281196594, train_loss: 0.48770076036453247\n",
      "14080 val_loss: 0.498186856508255, train_loss: 0.48746922612190247\n",
      "14090 val_loss: 0.49803775548934937, train_loss: 0.48726969957351685\n",
      "14100 val_loss: 0.4978882670402527, train_loss: 0.4871126413345337\n",
      "14110 val_loss: 0.49767786264419556, train_loss: 0.4867746829986572\n",
      "14120 val_loss: 0.4976962208747864, train_loss: 0.4866231083869934\n",
      "14130 val_loss: 0.49752604961395264, train_loss: 0.48668745160102844\n",
      "14140 val_loss: 0.49748238921165466, train_loss: 0.4866257905960083\n",
      "14150 val_loss: 0.49739545583724976, train_loss: 0.48644813895225525\n",
      "14160 val_loss: 0.49744001030921936, train_loss: 0.48648250102996826\n",
      "14170 val_loss: 0.49732235074043274, train_loss: 0.4863705337047577\n",
      "14180 val_loss: 0.4971705675125122, train_loss: 0.4861704707145691\n",
      "14190 val_loss: 0.49706193804740906, train_loss: 0.4860696792602539\n",
      "14200 val_loss: 0.4970433712005615, train_loss: 0.48601484298706055\n",
      "14210 val_loss: 0.4968799650669098, train_loss: 0.48596400022506714\n",
      "14220 val_loss: 0.49719664454460144, train_loss: 0.48598724603652954\n",
      "14230 val_loss: 0.4967426657676697, train_loss: 0.4857772886753082\n",
      "14240 val_loss: 0.49703189730644226, train_loss: 0.4864703118801117\n",
      "14250 val_loss: 0.4968731701374054, train_loss: 0.48624518513679504\n",
      "14260 val_loss: 0.49655142426490784, train_loss: 0.48573005199432373\n",
      "14270 val_loss: 0.4964407682418823, train_loss: 0.4855896234512329\n",
      "14280 val_loss: 0.49655649065971375, train_loss: 0.4857963025569916\n",
      "14290 val_loss: 0.4963575005531311, train_loss: 0.4855945110321045\n",
      "14300 val_loss: 0.49610623717308044, train_loss: 0.4852074980735779\n",
      "14310 val_loss: 0.49600523710250854, train_loss: 0.4851207435131073\n",
      "14320 val_loss: 0.4959436058998108, train_loss: 0.484885573387146\n",
      "14330 val_loss: 0.49590304493904114, train_loss: 0.48505541682243347\n",
      "14340 val_loss: 0.4960002303123474, train_loss: 0.48521560430526733\n",
      "14350 val_loss: 0.49562016129493713, train_loss: 0.4845197796821594\n",
      "14360 val_loss: 0.4955662786960602, train_loss: 0.4844607412815094\n",
      "14370 val_loss: 0.4954011142253876, train_loss: 0.48449379205703735\n",
      "14380 val_loss: 0.49542373418807983, train_loss: 0.484553724527359\n",
      "14390 val_loss: 0.49535033106803894, train_loss: 0.48451751470565796\n",
      "14400 val_loss: 0.49526160955429077, train_loss: 0.48432421684265137\n",
      "14410 val_loss: 0.4954656660556793, train_loss: 0.4847084879875183\n",
      "14420 val_loss: 0.49514248967170715, train_loss: 0.4843111038208008\n",
      "14430 val_loss: 0.4949623644351959, train_loss: 0.48401981592178345\n",
      "14440 val_loss: 0.494994580745697, train_loss: 0.48413121700286865\n",
      "14450 val_loss: 0.49484318494796753, train_loss: 0.48395606875419617\n",
      "14460 val_loss: 0.49471214413642883, train_loss: 0.48384159803390503\n",
      "14470 val_loss: 0.49453938007354736, train_loss: 0.48353809118270874\n",
      "14480 val_loss: 0.4943804144859314, train_loss: 0.4833572208881378\n",
      "14490 val_loss: 0.4943462014198303, train_loss: 0.48329779505729675\n",
      "14500 val_loss: 0.4942781925201416, train_loss: 0.4831867814064026\n",
      "14510 val_loss: 0.4942278563976288, train_loss: 0.483151376247406\n",
      "14520 val_loss: 0.49420151114463806, train_loss: 0.48307156562805176\n",
      "14530 val_loss: 0.49411314725875854, train_loss: 0.4829164445400238\n",
      "14540 val_loss: 0.493885338306427, train_loss: 0.482772558927536\n",
      "14550 val_loss: 0.4938339293003082, train_loss: 0.48275646567344666\n",
      "14560 val_loss: 0.493797242641449, train_loss: 0.4827084243297577\n",
      "14570 val_loss: 0.49381551146507263, train_loss: 0.48280394077301025\n",
      "14580 val_loss: 0.49385973811149597, train_loss: 0.4829457998275757\n",
      "14590 val_loss: 0.493618905544281, train_loss: 0.48237910866737366\n",
      "14600 val_loss: 0.49340131878852844, train_loss: 0.4823318123817444\n",
      "14610 val_loss: 0.4932888150215149, train_loss: 0.4821132719516754\n",
      "14620 val_loss: 0.49321451783180237, train_loss: 0.4820758104324341\n",
      "14630 val_loss: 0.4932469129562378, train_loss: 0.48219743371009827\n",
      "14640 val_loss: 0.4932366907596588, train_loss: 0.4822084903717041\n",
      "14650 val_loss: 0.4929641783237457, train_loss: 0.4817957580089569\n",
      "14660 val_loss: 0.4928784966468811, train_loss: 0.4817965030670166\n",
      "14670 val_loss: 0.492867648601532, train_loss: 0.481650173664093\n",
      "14680 val_loss: 0.4926586151123047, train_loss: 0.4815486967563629\n",
      "14690 val_loss: 0.4926137328147888, train_loss: 0.48158174753189087\n",
      "14700 val_loss: 0.4924704134464264, train_loss: 0.481449156999588\n",
      "14710 val_loss: 0.49229371547698975, train_loss: 0.4810918867588043\n",
      "14720 val_loss: 0.49229875206947327, train_loss: 0.4809873104095459\n",
      "14730 val_loss: 0.49210941791534424, train_loss: 0.48090484738349915\n",
      "14740 val_loss: 0.4920237362384796, train_loss: 0.4808219075202942\n",
      "14750 val_loss: 0.49195635318756104, train_loss: 0.4806775152683258\n",
      "14760 val_loss: 0.4919249713420868, train_loss: 0.4806479215621948\n",
      "14770 val_loss: 0.491946816444397, train_loss: 0.48056817054748535\n",
      "14780 val_loss: 0.4918590486049652, train_loss: 0.4804844558238983\n",
      "14790 val_loss: 0.49178874492645264, train_loss: 0.48051008582115173\n",
      "14800 val_loss: 0.4916696846485138, train_loss: 0.4804825484752655\n",
      "14810 val_loss: 0.49166959524154663, train_loss: 0.48043638467788696\n",
      "14820 val_loss: 0.49155962467193604, train_loss: 0.4804173409938812\n",
      "14830 val_loss: 0.4915546774864197, train_loss: 0.4803943634033203\n",
      "14840 val_loss: 0.49143123626708984, train_loss: 0.48024219274520874\n",
      "14850 val_loss: 0.49155890941619873, train_loss: 0.4804345667362213\n",
      "14860 val_loss: 0.4912002384662628, train_loss: 0.4800823926925659\n",
      "14870 val_loss: 0.49097099900245667, train_loss: 0.4797211289405823\n",
      "14880 val_loss: 0.4909234941005707, train_loss: 0.4796900749206543\n",
      "14890 val_loss: 0.49090278148651123, train_loss: 0.4798600673675537\n",
      "14900 val_loss: 0.49069538712501526, train_loss: 0.47957006096839905\n",
      "14910 val_loss: 0.4905748665332794, train_loss: 0.47944265604019165\n",
      "14920 val_loss: 0.49068155884742737, train_loss: 0.47966238856315613\n",
      "14930 val_loss: 0.49049699306488037, train_loss: 0.47937142848968506\n",
      "14940 val_loss: 0.49042391777038574, train_loss: 0.4792676568031311\n",
      "14950 val_loss: 0.49034085869789124, train_loss: 0.4791906177997589\n",
      "14960 val_loss: 0.4902905821800232, train_loss: 0.4792046844959259\n",
      "14970 val_loss: 0.49020084738731384, train_loss: 0.4790641665458679\n",
      "14980 val_loss: 0.4901925027370453, train_loss: 0.4791542589664459\n",
      "14990 val_loss: 0.49010688066482544, train_loss: 0.47901976108551025\n",
      "15000 val_loss: 0.4899625778198242, train_loss: 0.4788220524787903\n",
      "15010 val_loss: 0.4899316728115082, train_loss: 0.47880762815475464\n",
      "15020 val_loss: 0.4898626208305359, train_loss: 0.4786946177482605\n",
      "15030 val_loss: 0.489851713180542, train_loss: 0.4786003530025482\n",
      "15040 val_loss: 0.48973095417022705, train_loss: 0.4784030318260193\n",
      "15050 val_loss: 0.48957714438438416, train_loss: 0.478342741727829\n",
      "15060 val_loss: 0.48959341645240784, train_loss: 0.47844481468200684\n",
      "15070 val_loss: 0.4894508123397827, train_loss: 0.47823166847229004\n",
      "15080 val_loss: 0.4893384277820587, train_loss: 0.4780155420303345\n",
      "15090 val_loss: 0.48927733302116394, train_loss: 0.47813037037849426\n",
      "15100 val_loss: 0.48918816447257996, train_loss: 0.4779665172100067\n",
      "15110 val_loss: 0.48914194107055664, train_loss: 0.47789424657821655\n",
      "15120 val_loss: 0.4890839159488678, train_loss: 0.4778539836406708\n",
      "15130 val_loss: 0.48912596702575684, train_loss: 0.4779767692089081\n",
      "15140 val_loss: 0.48891857266426086, train_loss: 0.47753605246543884\n",
      "15150 val_loss: 0.4888792634010315, train_loss: 0.47739359736442566\n",
      "15160 val_loss: 0.48873376846313477, train_loss: 0.47735595703125\n",
      "15170 val_loss: 0.48864346742630005, train_loss: 0.4772995114326477\n",
      "15180 val_loss: 0.4885501563549042, train_loss: 0.47727328538894653\n",
      "15190 val_loss: 0.4887385964393616, train_loss: 0.47753942012786865\n",
      "15200 val_loss: 0.4884858727455139, train_loss: 0.47718706727027893\n",
      "15210 val_loss: 0.4883483052253723, train_loss: 0.4769781529903412\n",
      "15220 val_loss: 0.4884965717792511, train_loss: 0.47725534439086914\n",
      "15230 val_loss: 0.488258957862854, train_loss: 0.47683703899383545\n",
      "15240 val_loss: 0.4883303642272949, train_loss: 0.4768020510673523\n",
      "15250 val_loss: 0.48813509941101074, train_loss: 0.4767114520072937\n",
      "15260 val_loss: 0.48815983533859253, train_loss: 0.47678905725479126\n",
      "15270 val_loss: 0.4880434274673462, train_loss: 0.4765892028808594\n",
      "15280 val_loss: 0.4878702461719513, train_loss: 0.47645431756973267\n",
      "15290 val_loss: 0.4878823757171631, train_loss: 0.47655877470970154\n",
      "15300 val_loss: 0.4878116846084595, train_loss: 0.47640976309776306\n",
      "15310 val_loss: 0.48791536688804626, train_loss: 0.4764041006565094\n",
      "15320 val_loss: 0.4877355694770813, train_loss: 0.47639161348342896\n",
      "15330 val_loss: 0.48763346672058105, train_loss: 0.476371169090271\n",
      "15340 val_loss: 0.4876360297203064, train_loss: 0.476289838552475\n",
      "15350 val_loss: 0.487490713596344, train_loss: 0.47611209750175476\n",
      "15360 val_loss: 0.48780402541160583, train_loss: 0.47642725706100464\n",
      "15370 val_loss: 0.48742806911468506, train_loss: 0.4762204587459564\n",
      "15380 val_loss: 0.48771288990974426, train_loss: 0.4765021502971649\n",
      "15390 val_loss: 0.4877188205718994, train_loss: 0.4764871299266815\n",
      "15400 val_loss: 0.48768091201782227, train_loss: 0.47643470764160156\n",
      "15410 val_loss: 0.48713016510009766, train_loss: 0.4757808744907379\n",
      "15420 val_loss: 0.4870748817920685, train_loss: 0.4757201373577118\n",
      "15430 val_loss: 0.48704269528388977, train_loss: 0.4755817651748657\n",
      "15440 val_loss: 0.48689669370651245, train_loss: 0.47548907995224\n",
      "15450 val_loss: 0.48682498931884766, train_loss: 0.47544577717781067\n",
      "15460 val_loss: 0.48686906695365906, train_loss: 0.475541353225708\n",
      "15470 val_loss: 0.48669642210006714, train_loss: 0.4754030704498291\n",
      "15480 val_loss: 0.4866217076778412, train_loss: 0.475277304649353\n",
      "15490 val_loss: 0.4865657091140747, train_loss: 0.4752357602119446\n",
      "15500 val_loss: 0.48668795824050903, train_loss: 0.4754021465778351\n",
      "15510 val_loss: 0.4871440529823303, train_loss: 0.4758923351764679\n",
      "15520 val_loss: 0.4864429533481598, train_loss: 0.4749565124511719\n",
      "15530 val_loss: 0.4868604242801666, train_loss: 0.47509968280792236\n",
      "15540 val_loss: 0.48648279905319214, train_loss: 0.4747459292411804\n",
      "15550 val_loss: 0.4863745868206024, train_loss: 0.47469282150268555\n",
      "15560 val_loss: 0.4861971437931061, train_loss: 0.4746789336204529\n",
      "15570 val_loss: 0.48642995953559875, train_loss: 0.4750366806983948\n",
      "15580 val_loss: 0.48617005348205566, train_loss: 0.4746488928794861\n",
      "15590 val_loss: 0.4864027500152588, train_loss: 0.4750024974346161\n",
      "15600 val_loss: 0.48615002632141113, train_loss: 0.47459110617637634\n",
      "15610 val_loss: 0.485993891954422, train_loss: 0.4743359386920929\n",
      "15620 val_loss: 0.4860105812549591, train_loss: 0.474294513463974\n",
      "15630 val_loss: 0.4861293435096741, train_loss: 0.4742938280105591\n",
      "15640 val_loss: 0.48582443594932556, train_loss: 0.4740915894508362\n",
      "15650 val_loss: 0.48577019572257996, train_loss: 0.47416162490844727\n",
      "15660 val_loss: 0.4855230748653412, train_loss: 0.4739282429218292\n",
      "15670 val_loss: 0.485592782497406, train_loss: 0.47411787509918213\n",
      "15680 val_loss: 0.4854408800601959, train_loss: 0.4739258587360382\n",
      "15690 val_loss: 0.4854421317577362, train_loss: 0.4737869203090668\n",
      "15700 val_loss: 0.4854082763195038, train_loss: 0.4736969769001007\n",
      "15710 val_loss: 0.4853554368019104, train_loss: 0.47372743487358093\n",
      "15720 val_loss: 0.48567187786102295, train_loss: 0.4743277132511139\n",
      "15730 val_loss: 0.48533961176872253, train_loss: 0.4739299416542053\n",
      "15740 val_loss: 0.4850127398967743, train_loss: 0.47345808148384094\n",
      "15750 val_loss: 0.4849199652671814, train_loss: 0.47332248091697693\n",
      "15760 val_loss: 0.48487475514411926, train_loss: 0.47320154309272766\n",
      "15770 val_loss: 0.4848214387893677, train_loss: 0.47312378883361816\n",
      "15780 val_loss: 0.484762042760849, train_loss: 0.4729674160480499\n",
      "15790 val_loss: 0.4848303198814392, train_loss: 0.47304442524909973\n",
      "15800 val_loss: 0.48470500111579895, train_loss: 0.47281792759895325\n",
      "15810 val_loss: 0.484633207321167, train_loss: 0.47274452447891235\n",
      "15820 val_loss: 0.48478561639785767, train_loss: 0.47267672419548035\n",
      "15830 val_loss: 0.48457860946655273, train_loss: 0.4726346731185913\n",
      "15840 val_loss: 0.48454543948173523, train_loss: 0.47242575883865356\n",
      "15850 val_loss: 0.4842284619808197, train_loss: 0.4723735749721527\n",
      "15860 val_loss: 0.48447075486183167, train_loss: 0.472808301448822\n",
      "15870 val_loss: 0.4841637909412384, train_loss: 0.4723290205001831\n",
      "15880 val_loss: 0.484244167804718, train_loss: 0.4725261330604553\n",
      "15890 val_loss: 0.48415127396583557, train_loss: 0.4723109006881714\n",
      "15900 val_loss: 0.4841098487377167, train_loss: 0.4721837341785431\n",
      "15910 val_loss: 0.4839929938316345, train_loss: 0.4721473157405853\n",
      "15920 val_loss: 0.4840424060821533, train_loss: 0.47238507866859436\n",
      "15930 val_loss: 0.4840252697467804, train_loss: 0.4723975360393524\n",
      "15940 val_loss: 0.4838465452194214, train_loss: 0.47223204374313354\n",
      "15950 val_loss: 0.4843279719352722, train_loss: 0.4728392958641052\n",
      "15960 val_loss: 0.4837661683559418, train_loss: 0.47221308946609497\n",
      "15970 val_loss: 0.4834388792514801, train_loss: 0.47177204489707947\n",
      "15980 val_loss: 0.48332056403160095, train_loss: 0.47170543670654297\n",
      "15990 val_loss: 0.48341912031173706, train_loss: 0.47158801555633545\n",
      "16000 val_loss: 0.4832361936569214, train_loss: 0.4714786410331726\n",
      "16010 val_loss: 0.4837366044521332, train_loss: 0.47221073508262634\n",
      "16020 val_loss: 0.48311474919319153, train_loss: 0.4713461101055145\n",
      "16030 val_loss: 0.483467161655426, train_loss: 0.47162434458732605\n",
      "16040 val_loss: 0.48313066363334656, train_loss: 0.4714798629283905\n",
      "16050 val_loss: 0.4829656183719635, train_loss: 0.4711577892303467\n",
      "16060 val_loss: 0.483067125082016, train_loss: 0.47108912467956543\n",
      "16070 val_loss: 0.48287251591682434, train_loss: 0.470949649810791\n",
      "16080 val_loss: 0.48278486728668213, train_loss: 0.47097280621528625\n",
      "16090 val_loss: 0.4827626943588257, train_loss: 0.47093072533607483\n",
      "16100 val_loss: 0.4827195703983307, train_loss: 0.4708009660243988\n",
      "16110 val_loss: 0.48301994800567627, train_loss: 0.47089892625808716\n",
      "16120 val_loss: 0.48273664712905884, train_loss: 0.4706493020057678\n",
      "16130 val_loss: 0.48262688517570496, train_loss: 0.47051653265953064\n",
      "16140 val_loss: 0.4825744926929474, train_loss: 0.4705488979816437\n",
      "16150 val_loss: 0.48250260949134827, train_loss: 0.4704190194606781\n",
      "16160 val_loss: 0.4825504422187805, train_loss: 0.4703044891357422\n",
      "16170 val_loss: 0.48274722695350647, train_loss: 0.4705981910228729\n",
      "16180 val_loss: 0.482258141040802, train_loss: 0.4702942371368408\n",
      "16190 val_loss: 0.4821636974811554, train_loss: 0.47019627690315247\n",
      "16200 val_loss: 0.4821148216724396, train_loss: 0.47016632556915283\n",
      "16210 val_loss: 0.48210781812667847, train_loss: 0.4699619710445404\n",
      "16220 val_loss: 0.4819332957267761, train_loss: 0.46992993354797363\n",
      "16230 val_loss: 0.4819616973400116, train_loss: 0.4698897898197174\n",
      "16240 val_loss: 0.4820297956466675, train_loss: 0.47012776136398315\n",
      "16250 val_loss: 0.48181161284446716, train_loss: 0.4698392450809479\n",
      "16260 val_loss: 0.48173221945762634, train_loss: 0.4697207808494568\n",
      "16270 val_loss: 0.4818284213542938, train_loss: 0.4698019325733185\n",
      "16280 val_loss: 0.4816405177116394, train_loss: 0.46969684958457947\n",
      "16290 val_loss: 0.48160651326179504, train_loss: 0.4697689414024353\n",
      "16300 val_loss: 0.48160579800605774, train_loss: 0.4697866439819336\n",
      "16310 val_loss: 0.4816232919692993, train_loss: 0.4697010815143585\n",
      "16320 val_loss: 0.4815102219581604, train_loss: 0.4695989191532135\n",
      "16330 val_loss: 0.48155298829078674, train_loss: 0.4695237874984741\n",
      "16340 val_loss: 0.4814392924308777, train_loss: 0.46931809186935425\n",
      "16350 val_loss: 0.48142293095588684, train_loss: 0.4692957103252411\n",
      "16360 val_loss: 0.4813123345375061, train_loss: 0.4693599343299866\n",
      "16370 val_loss: 0.48132458329200745, train_loss: 0.4695092737674713\n",
      "16380 val_loss: 0.48120084404945374, train_loss: 0.46926403045654297\n",
      "16390 val_loss: 0.48127132654190063, train_loss: 0.46916481852531433\n",
      "16400 val_loss: 0.481353223323822, train_loss: 0.46915966272354126\n",
      "16410 val_loss: 0.48113158345222473, train_loss: 0.46900615096092224\n",
      "16420 val_loss: 0.48121339082717896, train_loss: 0.4690098762512207\n",
      "16430 val_loss: 0.48109689354896545, train_loss: 0.46884748339653015\n",
      "16440 val_loss: 0.48094871640205383, train_loss: 0.4688643515110016\n",
      "16450 val_loss: 0.48087549209594727, train_loss: 0.468691885471344\n",
      "16460 val_loss: 0.480807900428772, train_loss: 0.4687161445617676\n",
      "16470 val_loss: 0.4807303547859192, train_loss: 0.4686988592147827\n",
      "16480 val_loss: 0.48062798380851746, train_loss: 0.46847003698349\n",
      "16490 val_loss: 0.4805562198162079, train_loss: 0.4684152901172638\n",
      "16500 val_loss: 0.4804094731807709, train_loss: 0.46835508942604065\n",
      "16510 val_loss: 0.4803421199321747, train_loss: 0.4683712124824524\n",
      "16520 val_loss: 0.48036694526672363, train_loss: 0.46830451488494873\n",
      "16530 val_loss: 0.480347603559494, train_loss: 0.46830859780311584\n",
      "16540 val_loss: 0.480242520570755, train_loss: 0.46828705072402954\n",
      "16550 val_loss: 0.4802209734916687, train_loss: 0.46827805042266846\n",
      "16560 val_loss: 0.48017436265945435, train_loss: 0.4682021141052246\n",
      "16570 val_loss: 0.480316698551178, train_loss: 0.46793586015701294\n",
      "16580 val_loss: 0.4804634749889374, train_loss: 0.4678928256034851\n",
      "16590 val_loss: 0.48018473386764526, train_loss: 0.46767935156822205\n",
      "16600 val_loss: 0.4800798296928406, train_loss: 0.46761271357536316\n",
      "16610 val_loss: 0.4799879193305969, train_loss: 0.4675161838531494\n",
      "16620 val_loss: 0.48023444414138794, train_loss: 0.46748000383377075\n",
      "16630 val_loss: 0.48076969385147095, train_loss: 0.4677005112171173\n",
      "16640 val_loss: 0.48024091124534607, train_loss: 0.4676242470741272\n",
      "16650 val_loss: 0.48005416989326477, train_loss: 0.4673607647418976\n",
      "16660 val_loss: 0.4798838198184967, train_loss: 0.46738332509994507\n",
      "16670 val_loss: 0.4797637164592743, train_loss: 0.4672320485115051\n",
      "16680 val_loss: 0.4796575605869293, train_loss: 0.4672461152076721\n",
      "16690 val_loss: 0.4797106087207794, train_loss: 0.46742725372314453\n",
      "16700 val_loss: 0.4796150028705597, train_loss: 0.4672951400279999\n",
      "16710 val_loss: 0.4797584116458893, train_loss: 0.4671963155269623\n",
      "16720 val_loss: 0.4794882833957672, train_loss: 0.46719253063201904\n",
      "16730 val_loss: 0.47936198115348816, train_loss: 0.4670124650001526\n",
      "16740 val_loss: 0.4792940616607666, train_loss: 0.46699902415275574\n",
      "16750 val_loss: 0.4792117476463318, train_loss: 0.4669033885002136\n",
      "16760 val_loss: 0.47921374440193176, train_loss: 0.4668443202972412\n",
      "16770 val_loss: 0.4792146384716034, train_loss: 0.4669709801673889\n",
      "16780 val_loss: 0.47918790578842163, train_loss: 0.46706053614616394\n",
      "16790 val_loss: 0.47911596298217773, train_loss: 0.4668785631656647\n",
      "16800 val_loss: 0.47928667068481445, train_loss: 0.46674153208732605\n",
      "16810 val_loss: 0.4791259765625, train_loss: 0.46658217906951904\n",
      "16820 val_loss: 0.47912105917930603, train_loss: 0.46681690216064453\n",
      "16830 val_loss: 0.4790979027748108, train_loss: 0.46661362051963806\n",
      "16840 val_loss: 0.47919806838035583, train_loss: 0.46665117144584656\n",
      "16850 val_loss: 0.4790849983692169, train_loss: 0.46646398305892944\n",
      "16860 val_loss: 0.47900423407554626, train_loss: 0.4665055572986603\n",
      "16870 val_loss: 0.4790008068084717, train_loss: 0.46627944707870483\n",
      "16880 val_loss: 0.47885802388191223, train_loss: 0.46615105867385864\n",
      "16890 val_loss: 0.478664755821228, train_loss: 0.46612417697906494\n",
      "16900 val_loss: 0.4787145256996155, train_loss: 0.46626782417297363\n",
      "16910 val_loss: 0.47862401604652405, train_loss: 0.46629348397254944\n",
      "16920 val_loss: 0.47878140211105347, train_loss: 0.46642595529556274\n",
      "16930 val_loss: 0.4786645174026489, train_loss: 0.46615922451019287\n",
      "16940 val_loss: 0.4783819615840912, train_loss: 0.46572065353393555\n",
      "16950 val_loss: 0.4784860908985138, train_loss: 0.4657706618309021\n",
      "16960 val_loss: 0.47829973697662354, train_loss: 0.46572208404541016\n",
      "16970 val_loss: 0.4784683287143707, train_loss: 0.4658695459365845\n",
      "16980 val_loss: 0.47829097509384155, train_loss: 0.4657519459724426\n",
      "16990 val_loss: 0.4785659611225128, train_loss: 0.46611809730529785\n",
      "17000 val_loss: 0.47877487540245056, train_loss: 0.46585601568222046\n",
      "17010 val_loss: 0.47871890664100647, train_loss: 0.4658232629299164\n",
      "17020 val_loss: 0.4783770442008972, train_loss: 0.46566134691238403\n",
      "17030 val_loss: 0.4781454801559448, train_loss: 0.4652457535266876\n",
      "17040 val_loss: 0.4782847464084625, train_loss: 0.46542835235595703\n",
      "17050 val_loss: 0.4781658947467804, train_loss: 0.46533671021461487\n",
      "17060 val_loss: 0.47818082571029663, train_loss: 0.46512842178344727\n",
      "17070 val_loss: 0.47810128331184387, train_loss: 0.4649833142757416\n",
      "17080 val_loss: 0.47793343663215637, train_loss: 0.4649106562137604\n",
      "17090 val_loss: 0.47789832949638367, train_loss: 0.46481990814208984\n",
      "17100 val_loss: 0.47768810391426086, train_loss: 0.46481427550315857\n",
      "17110 val_loss: 0.4778698682785034, train_loss: 0.4649220407009125\n",
      "17120 val_loss: 0.47778084874153137, train_loss: 0.4649902284145355\n",
      "17130 val_loss: 0.47770023345947266, train_loss: 0.4648337960243225\n",
      "17140 val_loss: 0.47771668434143066, train_loss: 0.4649290144443512\n",
      "17150 val_loss: 0.4775211215019226, train_loss: 0.46504494547843933\n",
      "17160 val_loss: 0.47753751277923584, train_loss: 0.4649028182029724\n",
      "17170 val_loss: 0.47744637727737427, train_loss: 0.46459299325942993\n",
      "17180 val_loss: 0.4773082733154297, train_loss: 0.46445322036743164\n",
      "17190 val_loss: 0.47730135917663574, train_loss: 0.4644726812839508\n",
      "17200 val_loss: 0.4773361086845398, train_loss: 0.4646163582801819\n",
      "17210 val_loss: 0.47715356945991516, train_loss: 0.46427878737449646\n",
      "17220 val_loss: 0.47713711857795715, train_loss: 0.46441182494163513\n",
      "17230 val_loss: 0.4770597219467163, train_loss: 0.46397703886032104\n",
      "17240 val_loss: 0.47725048661231995, train_loss: 0.46408000588417053\n",
      "17250 val_loss: 0.47737210988998413, train_loss: 0.4640284478664398\n",
      "17260 val_loss: 0.47686222195625305, train_loss: 0.46375754475593567\n",
      "17270 val_loss: 0.47683101892471313, train_loss: 0.46372929215431213\n",
      "17280 val_loss: 0.47722724080085754, train_loss: 0.463798850774765\n",
      "17290 val_loss: 0.4770512282848358, train_loss: 0.4637410640716553\n",
      "17300 val_loss: 0.47689488530158997, train_loss: 0.4638368785381317\n",
      "17310 val_loss: 0.47696182131767273, train_loss: 0.4639774560928345\n",
      "17320 val_loss: 0.47711503505706787, train_loss: 0.4641082286834717\n",
      "17330 val_loss: 0.47697144746780396, train_loss: 0.46393081545829773\n",
      "17340 val_loss: 0.47678303718566895, train_loss: 0.4636898636817932\n",
      "17350 val_loss: 0.47664445638656616, train_loss: 0.4635446071624756\n",
      "17360 val_loss: 0.4765901565551758, train_loss: 0.46339040994644165\n",
      "17370 val_loss: 0.4765489101409912, train_loss: 0.46329402923583984\n",
      "17380 val_loss: 0.47678321599960327, train_loss: 0.4633004665374756\n",
      "17390 val_loss: 0.4764936566352844, train_loss: 0.4632001519203186\n",
      "17400 val_loss: 0.47640320658683777, train_loss: 0.4631948471069336\n",
      "17410 val_loss: 0.47650131583213806, train_loss: 0.4632067084312439\n",
      "17420 val_loss: 0.4762408435344696, train_loss: 0.4633138179779053\n",
      "17430 val_loss: 0.4761042892932892, train_loss: 0.46325552463531494\n",
      "17440 val_loss: 0.47617068886756897, train_loss: 0.46313315629959106\n",
      "17450 val_loss: 0.4761608839035034, train_loss: 0.46325159072875977\n",
      "17460 val_loss: 0.47631487250328064, train_loss: 0.4636697769165039\n",
      "17470 val_loss: 0.4761052131652832, train_loss: 0.46323859691619873\n",
      "17480 val_loss: 0.4760453999042511, train_loss: 0.4632824957370758\n",
      "17490 val_loss: 0.4760760962963104, train_loss: 0.46293583512306213\n",
      "17500 val_loss: 0.4759179651737213, train_loss: 0.46277815103530884\n",
      "17510 val_loss: 0.47588273882865906, train_loss: 0.4627087116241455\n",
      "17520 val_loss: 0.47592294216156006, train_loss: 0.46269750595092773\n",
      "17530 val_loss: 0.47581446170806885, train_loss: 0.46266695857048035\n",
      "17540 val_loss: 0.4756014943122864, train_loss: 0.4627434313297272\n",
      "17550 val_loss: 0.47557443380355835, train_loss: 0.4627749025821686\n",
      "17560 val_loss: 0.47636717557907104, train_loss: 0.46290284395217896\n",
      "17570 val_loss: 0.47574228048324585, train_loss: 0.4625990092754364\n",
      "17580 val_loss: 0.47544559836387634, train_loss: 0.46245434880256653\n",
      "17590 val_loss: 0.4754389524459839, train_loss: 0.4625426232814789\n",
      "17600 val_loss: 0.4754050672054291, train_loss: 0.4623689353466034\n",
      "17610 val_loss: 0.47537752985954285, train_loss: 0.46256783604621887\n",
      "17620 val_loss: 0.4753970801830292, train_loss: 0.46222496032714844\n",
      "17630 val_loss: 0.47536176443099976, train_loss: 0.4623180031776428\n",
      "17640 val_loss: 0.47528770565986633, train_loss: 0.4620642066001892\n",
      "17650 val_loss: 0.4752269685268402, train_loss: 0.4621643126010895\n",
      "17660 val_loss: 0.4751570522785187, train_loss: 0.46210190653800964\n",
      "17670 val_loss: 0.4752735495567322, train_loss: 0.4619286060333252\n",
      "17680 val_loss: 0.475073903799057, train_loss: 0.46211379766464233\n",
      "17690 val_loss: 0.47509029507637024, train_loss: 0.46228060126304626\n",
      "17700 val_loss: 0.47509801387786865, train_loss: 0.46191543340682983\n",
      "17710 val_loss: 0.4750039875507355, train_loss: 0.46225404739379883\n",
      "17720 val_loss: 0.47477442026138306, train_loss: 0.4618242084980011\n",
      "17730 val_loss: 0.4746803343296051, train_loss: 0.46169769763946533\n",
      "17740 val_loss: 0.47465047240257263, train_loss: 0.4615499675273895\n",
      "17750 val_loss: 0.474931001663208, train_loss: 0.46165555715560913\n",
      "17760 val_loss: 0.4747330844402313, train_loss: 0.46152350306510925\n",
      "17770 val_loss: 0.47473999857902527, train_loss: 0.46144935488700867\n",
      "17780 val_loss: 0.47460901737213135, train_loss: 0.46132197976112366\n",
      "17790 val_loss: 0.4750467836856842, train_loss: 0.4614241123199463\n",
      "17800 val_loss: 0.4746848940849304, train_loss: 0.46107494831085205\n",
      "17810 val_loss: 0.4746784269809723, train_loss: 0.4608722925186157\n",
      "17820 val_loss: 0.47439029812812805, train_loss: 0.46100664138793945\n",
      "17830 val_loss: 0.47440797090530396, train_loss: 0.4610190987586975\n",
      "17840 val_loss: 0.4744473099708557, train_loss: 0.460682213306427\n",
      "17850 val_loss: 0.4741813540458679, train_loss: 0.4607063829898834\n",
      "17860 val_loss: 0.4743991792201996, train_loss: 0.46060889959335327\n",
      "17870 val_loss: 0.4745563566684723, train_loss: 0.4607231318950653\n",
      "17880 val_loss: 0.47421368956565857, train_loss: 0.46048077940940857\n",
      "17890 val_loss: 0.47412264347076416, train_loss: 0.46027714014053345\n",
      "17900 val_loss: 0.4738711416721344, train_loss: 0.4602808654308319\n",
      "17910 val_loss: 0.47367823123931885, train_loss: 0.4601175785064697\n",
      "17920 val_loss: 0.47371208667755127, train_loss: 0.46011194586753845\n",
      "17930 val_loss: 0.47392258048057556, train_loss: 0.45983776450157166\n",
      "17940 val_loss: 0.47369831800460815, train_loss: 0.459856241941452\n",
      "17950 val_loss: 0.473740816116333, train_loss: 0.45958536863327026\n",
      "17960 val_loss: 0.4736664891242981, train_loss: 0.45975461602211\n",
      "17970 val_loss: 0.47359374165534973, train_loss: 0.46015220880508423\n",
      "17980 val_loss: 0.47333142161369324, train_loss: 0.4596804976463318\n",
      "17990 val_loss: 0.47349870204925537, train_loss: 0.4601995646953583\n",
      "18000 val_loss: 0.4731011986732483, train_loss: 0.4598310887813568\n",
      "18010 val_loss: 0.4729993939399719, train_loss: 0.45978301763534546\n",
      "18020 val_loss: 0.47262194752693176, train_loss: 0.45896226167678833\n",
      "18030 val_loss: 0.47259390354156494, train_loss: 0.45883384346961975\n",
      "18040 val_loss: 0.4725235104560852, train_loss: 0.4586386978626251\n",
      "18050 val_loss: 0.4723112881183624, train_loss: 0.45867595076560974\n",
      "18060 val_loss: 0.4722488224506378, train_loss: 0.4585174322128296\n",
      "18070 val_loss: 0.4722336530685425, train_loss: 0.45860785245895386\n",
      "18080 val_loss: 0.472128301858902, train_loss: 0.45808443427085876\n",
      "18090 val_loss: 0.47205549478530884, train_loss: 0.45790567994117737\n",
      "18100 val_loss: 0.47161155939102173, train_loss: 0.45775100588798523\n",
      "18110 val_loss: 0.47158122062683105, train_loss: 0.45797252655029297\n",
      "18120 val_loss: 0.47146251797676086, train_loss: 0.45807763934135437\n",
      "18130 val_loss: 0.47089412808418274, train_loss: 0.45722028613090515\n",
      "18140 val_loss: 0.4710475206375122, train_loss: 0.4569286108016968\n",
      "18150 val_loss: 0.47073352336883545, train_loss: 0.45688894391059875\n",
      "18160 val_loss: 0.4705279469490051, train_loss: 0.4569165110588074\n",
      "18170 val_loss: 0.470205157995224, train_loss: 0.45654454827308655\n",
      "18180 val_loss: 0.4699104428291321, train_loss: 0.4559888541698456\n",
      "18190 val_loss: 0.4696533977985382, train_loss: 0.4559459984302521\n",
      "18200 val_loss: 0.4695529639720917, train_loss: 0.45599183440208435\n",
      "18210 val_loss: 0.46908602118492126, train_loss: 0.4555291533470154\n",
      "18220 val_loss: 0.4689253270626068, train_loss: 0.45512181520462036\n",
      "18230 val_loss: 0.4685608446598053, train_loss: 0.45479243993759155\n",
      "18240 val_loss: 0.46814411878585815, train_loss: 0.45430228114128113\n",
      "18250 val_loss: 0.4683651626110077, train_loss: 0.4544351398944855\n",
      "18260 val_loss: 0.46816104650497437, train_loss: 0.4545840919017792\n",
      "18270 val_loss: 0.46758776903152466, train_loss: 0.45402783155441284\n",
      "18280 val_loss: 0.46718916296958923, train_loss: 0.45371970534324646\n",
      "18290 val_loss: 0.46707966923713684, train_loss: 0.45341137051582336\n",
      "18300 val_loss: 0.4668140411376953, train_loss: 0.45322516560554504\n",
      "18310 val_loss: 0.4665832817554474, train_loss: 0.45295435190200806\n",
      "18320 val_loss: 0.4666917324066162, train_loss: 0.4531570374965668\n",
      "18330 val_loss: 0.4663032293319702, train_loss: 0.4528041183948517\n",
      "18340 val_loss: 0.46644896268844604, train_loss: 0.45293334126472473\n",
      "18350 val_loss: 0.4661782681941986, train_loss: 0.4527292549610138\n",
      "18360 val_loss: 0.46634209156036377, train_loss: 0.4529070556163788\n",
      "18370 val_loss: 0.46591517329216003, train_loss: 0.4523929953575134\n",
      "18380 val_loss: 0.4656883180141449, train_loss: 0.45209166407585144\n",
      "18390 val_loss: 0.4653419256210327, train_loss: 0.45186400413513184\n",
      "18400 val_loss: 0.465182363986969, train_loss: 0.4518161416053772\n",
      "18410 val_loss: 0.46508651971817017, train_loss: 0.45147666335105896\n",
      "18420 val_loss: 0.46510595083236694, train_loss: 0.45150166749954224\n",
      "18430 val_loss: 0.4649747312068939, train_loss: 0.4513390064239502\n",
      "18440 val_loss: 0.4647655785083771, train_loss: 0.45121464133262634\n",
      "18450 val_loss: 0.46476051211357117, train_loss: 0.45114338397979736\n",
      "18460 val_loss: 0.46513256430625916, train_loss: 0.4518011212348938\n",
      "18470 val_loss: 0.4649008512496948, train_loss: 0.45146963000297546\n",
      "18480 val_loss: 0.4643634557723999, train_loss: 0.45100754499435425\n",
      "18490 val_loss: 0.46425652503967285, train_loss: 0.4507160186767578\n",
      "18500 val_loss: 0.4642273783683777, train_loss: 0.4506930112838745\n",
      "18510 val_loss: 0.4642486274242401, train_loss: 0.4508497416973114\n",
      "18520 val_loss: 0.4643016755580902, train_loss: 0.45089080929756165\n",
      "18530 val_loss: 0.46396997570991516, train_loss: 0.450534850358963\n",
      "18540 val_loss: 0.46371692419052124, train_loss: 0.4502071738243103\n",
      "18550 val_loss: 0.4637738764286041, train_loss: 0.45012179017066956\n",
      "18560 val_loss: 0.46356409788131714, train_loss: 0.4499528706073761\n",
      "18570 val_loss: 0.4634915292263031, train_loss: 0.4501335918903351\n",
      "18580 val_loss: 0.4632144272327423, train_loss: 0.4496886730194092\n",
      "18590 val_loss: 0.4632888734340668, train_loss: 0.44995513558387756\n",
      "18600 val_loss: 0.46310165524482727, train_loss: 0.4495036005973816\n",
      "18610 val_loss: 0.4631807506084442, train_loss: 0.449665904045105\n",
      "18620 val_loss: 0.4631996750831604, train_loss: 0.449511855840683\n",
      "18630 val_loss: 0.4626701772212982, train_loss: 0.44927868247032166\n",
      "18640 val_loss: 0.4636678993701935, train_loss: 0.4504910111427307\n",
      "18650 val_loss: 0.4625980257987976, train_loss: 0.4492216408252716\n",
      "18660 val_loss: 0.46273472905158997, train_loss: 0.44946029782295227\n",
      "18670 val_loss: 0.4621293544769287, train_loss: 0.4486599266529083\n",
      "18680 val_loss: 0.46214571595191956, train_loss: 0.44860029220581055\n",
      "18690 val_loss: 0.4625242054462433, train_loss: 0.4487842619419098\n",
      "18700 val_loss: 0.46204525232315063, train_loss: 0.4484418034553528\n",
      "18710 val_loss: 0.4620541036128998, train_loss: 0.4485476016998291\n",
      "18720 val_loss: 0.46230870485305786, train_loss: 0.4489060640335083\n",
      "18730 val_loss: 0.4620247483253479, train_loss: 0.44836071133613586\n",
      "18740 val_loss: 0.4618852138519287, train_loss: 0.44832777976989746\n",
      "18750 val_loss: 0.46141311526298523, train_loss: 0.44789597392082214\n",
      "18760 val_loss: 0.461618036031723, train_loss: 0.4478212594985962\n",
      "18770 val_loss: 0.46155208349227905, train_loss: 0.44779595732688904\n",
      "18780 val_loss: 0.46149104833602905, train_loss: 0.44785234332084656\n",
      "18790 val_loss: 0.4614723026752472, train_loss: 0.44787898659706116\n",
      "18800 val_loss: 0.4611656069755554, train_loss: 0.4475676715373993\n",
      "18810 val_loss: 0.4609147906303406, train_loss: 0.447582870721817\n",
      "18820 val_loss: 0.4608454704284668, train_loss: 0.447307288646698\n",
      "18830 val_loss: 0.4606267809867859, train_loss: 0.44730234146118164\n",
      "18840 val_loss: 0.4604452848434448, train_loss: 0.4470970332622528\n",
      "18850 val_loss: 0.4602512717247009, train_loss: 0.4469130039215088\n",
      "18860 val_loss: 0.460122287273407, train_loss: 0.44681355357170105\n",
      "18870 val_loss: 0.4600127339363098, train_loss: 0.44669967889785767\n",
      "18880 val_loss: 0.4601145088672638, train_loss: 0.44667869806289673\n",
      "18890 val_loss: 0.46000462770462036, train_loss: 0.4466131329536438\n",
      "18900 val_loss: 0.4598371684551239, train_loss: 0.44659584760665894\n",
      "18910 val_loss: 0.46000680327415466, train_loss: 0.4465925395488739\n",
      "18920 val_loss: 0.4601867198944092, train_loss: 0.44704920053482056\n",
      "18930 val_loss: 0.4598180651664734, train_loss: 0.4465236961841583\n",
      "18940 val_loss: 0.4598117768764496, train_loss: 0.44619590044021606\n",
      "18950 val_loss: 0.45983585715293884, train_loss: 0.4462144672870636\n",
      "18960 val_loss: 0.4589495360851288, train_loss: 0.4456770420074463\n",
      "18970 val_loss: 0.4595411717891693, train_loss: 0.44580602645874023\n",
      "18980 val_loss: 0.4593251645565033, train_loss: 0.44571253657341003\n",
      "18990 val_loss: 0.45913639664649963, train_loss: 0.44589000940322876\n",
      "19000 val_loss: 0.45928123593330383, train_loss: 0.4462077021598816\n",
      "19010 val_loss: 0.45874279737472534, train_loss: 0.4454127252101898\n",
      "19020 val_loss: 0.4585202634334564, train_loss: 0.44521912932395935\n",
      "19030 val_loss: 0.45990583300590515, train_loss: 0.4467175304889679\n",
      "19040 val_loss: 0.4584501087665558, train_loss: 0.4451637864112854\n",
      "19050 val_loss: 0.45804867148399353, train_loss: 0.44474008679389954\n",
      "19060 val_loss: 0.4583086669445038, train_loss: 0.4452900290489197\n",
      "19070 val_loss: 0.4577988386154175, train_loss: 0.44456908106803894\n",
      "19080 val_loss: 0.45798206329345703, train_loss: 0.44476428627967834\n",
      "19090 val_loss: 0.4583713114261627, train_loss: 0.4451295733451843\n",
      "19100 val_loss: 0.45794588327407837, train_loss: 0.4447802007198334\n",
      "19110 val_loss: 0.4573802947998047, train_loss: 0.4442552626132965\n",
      "19120 val_loss: 0.457236647605896, train_loss: 0.44415009021759033\n",
      "19130 val_loss: 0.4570922553539276, train_loss: 0.44406837224960327\n",
      "19140 val_loss: 0.45730724930763245, train_loss: 0.4443471431732178\n",
      "19150 val_loss: 0.4570881426334381, train_loss: 0.44422683119773865\n",
      "19160 val_loss: 0.45710498094558716, train_loss: 0.4439842998981476\n",
      "19170 val_loss: 0.45713508129119873, train_loss: 0.4441632628440857\n",
      "19180 val_loss: 0.45658037066459656, train_loss: 0.4435749053955078\n",
      "19190 val_loss: 0.456693559885025, train_loss: 0.4433794319629669\n",
      "19200 val_loss: 0.45646390318870544, train_loss: 0.4434193968772888\n",
      "19210 val_loss: 0.4573972225189209, train_loss: 0.4445312023162842\n",
      "19220 val_loss: 0.4565391540527344, train_loss: 0.443439245223999\n",
      "19230 val_loss: 0.45611685514450073, train_loss: 0.44298887252807617\n",
      "19240 val_loss: 0.45616963505744934, train_loss: 0.44288015365600586\n",
      "19250 val_loss: 0.4560856223106384, train_loss: 0.44311049580574036\n",
      "19260 val_loss: 0.4560336768627167, train_loss: 0.4430881142616272\n",
      "19270 val_loss: 0.4561012387275696, train_loss: 0.4427873194217682\n",
      "19280 val_loss: 0.4558677077293396, train_loss: 0.4425695538520813\n",
      "19290 val_loss: 0.4555012583732605, train_loss: 0.4425511658191681\n",
      "19300 val_loss: 0.45640406012535095, train_loss: 0.44280558824539185\n",
      "19310 val_loss: 0.45533931255340576, train_loss: 0.4421657621860504\n",
      "19320 val_loss: 0.45512738823890686, train_loss: 0.441728800535202\n",
      "19330 val_loss: 0.4551542103290558, train_loss: 0.4420817196369171\n",
      "19340 val_loss: 0.4554530382156372, train_loss: 0.44225502014160156\n",
      "19350 val_loss: 0.45518192648887634, train_loss: 0.4417791962623596\n",
      "19360 val_loss: 0.454763263463974, train_loss: 0.44215548038482666\n",
      "19370 val_loss: 0.4546225666999817, train_loss: 0.4417603015899658\n",
      "19380 val_loss: 0.45447424054145813, train_loss: 0.4415851831436157\n",
      "19390 val_loss: 0.4542483389377594, train_loss: 0.4411000609397888\n",
      "19400 val_loss: 0.4544195830821991, train_loss: 0.4411410391330719\n",
      "19410 val_loss: 0.4541938602924347, train_loss: 0.4406917691230774\n",
      "19420 val_loss: 0.45340976119041443, train_loss: 0.4403854310512543\n",
      "19430 val_loss: 0.4534887373447418, train_loss: 0.4407840967178345\n",
      "19440 val_loss: 0.45296168327331543, train_loss: 0.4400006830692291\n",
      "19450 val_loss: 0.45316198468208313, train_loss: 0.44038155674934387\n",
      "19460 val_loss: 0.453167200088501, train_loss: 0.44003576040267944\n",
      "19470 val_loss: 0.45335522294044495, train_loss: 0.4404284358024597\n",
      "19480 val_loss: 0.4529378116130829, train_loss: 0.4398707151412964\n",
      "19490 val_loss: 0.4529179632663727, train_loss: 0.4400022327899933\n",
      "19500 val_loss: 0.45270106196403503, train_loss: 0.4397681951522827\n",
      "19510 val_loss: 0.45224618911743164, train_loss: 0.43872231245040894\n",
      "19520 val_loss: 0.4518263339996338, train_loss: 0.43849024176597595\n",
      "19530 val_loss: 0.45165014266967773, train_loss: 0.4384806752204895\n",
      "19540 val_loss: 0.4513392448425293, train_loss: 0.43819358944892883\n",
      "19550 val_loss: 0.45141497254371643, train_loss: 0.43859145045280457\n",
      "19560 val_loss: 0.45127928256988525, train_loss: 0.4383060932159424\n",
      "19570 val_loss: 0.45083385705947876, train_loss: 0.4377758800983429\n",
      "19580 val_loss: 0.4503420293331146, train_loss: 0.4371757209300995\n",
      "19590 val_loss: 0.4500621259212494, train_loss: 0.43692657351493835\n",
      "19600 val_loss: 0.45002481341362, train_loss: 0.43737196922302246\n",
      "19610 val_loss: 0.4500015079975128, train_loss: 0.4375428259372711\n",
      "19620 val_loss: 0.4492946267127991, train_loss: 0.4367291331291199\n",
      "19630 val_loss: 0.44915345311164856, train_loss: 0.4365440905094147\n",
      "19640 val_loss: 0.4492444396018982, train_loss: 0.4365212023258209\n",
      "19650 val_loss: 0.4491051435470581, train_loss: 0.4364015460014343\n",
      "19660 val_loss: 0.4488372802734375, train_loss: 0.4360418915748596\n",
      "19670 val_loss: 0.449358195066452, train_loss: 0.4369722008705139\n",
      "19680 val_loss: 0.4494445025920868, train_loss: 0.4369548261165619\n",
      "19690 val_loss: 0.44851911067962646, train_loss: 0.4355139434337616\n",
      "19700 val_loss: 0.44827383756637573, train_loss: 0.43493956327438354\n",
      "19710 val_loss: 0.4482057988643646, train_loss: 0.4356953203678131\n",
      "19720 val_loss: 0.44756269454956055, train_loss: 0.43465572595596313\n",
      "19730 val_loss: 0.4474218487739563, train_loss: 0.434993714094162\n",
      "19740 val_loss: 0.447295606136322, train_loss: 0.43492963910102844\n",
      "19750 val_loss: 0.4464495778083801, train_loss: 0.43358704447746277\n",
      "19760 val_loss: 0.4458658993244171, train_loss: 0.4329691231250763\n",
      "19770 val_loss: 0.4458124041557312, train_loss: 0.4329449534416199\n",
      "19780 val_loss: 0.4461924731731415, train_loss: 0.43346184492111206\n",
      "19790 val_loss: 0.44544747471809387, train_loss: 0.43250101804733276\n",
      "19800 val_loss: 0.44539543986320496, train_loss: 0.43235665559768677\n",
      "19810 val_loss: 0.44477763772010803, train_loss: 0.43190833926200867\n",
      "19820 val_loss: 0.4443912208080292, train_loss: 0.43167924880981445\n",
      "19830 val_loss: 0.44393694400787354, train_loss: 0.4309593439102173\n",
      "19840 val_loss: 0.4442718029022217, train_loss: 0.43172353506088257\n",
      "19850 val_loss: 0.44347453117370605, train_loss: 0.4306512773036957\n",
      "19860 val_loss: 0.4432152807712555, train_loss: 0.43032366037368774\n",
      "19870 val_loss: 0.4428321123123169, train_loss: 0.430026650428772\n",
      "19880 val_loss: 0.44295966625213623, train_loss: 0.4304106831550598\n",
      "19890 val_loss: 0.442323237657547, train_loss: 0.4298814535140991\n",
      "19900 val_loss: 0.4417499899864197, train_loss: 0.4290129840373993\n",
      "19910 val_loss: 0.4412558972835541, train_loss: 0.42847511172294617\n",
      "19920 val_loss: 0.4407740533351898, train_loss: 0.4279385805130005\n",
      "19930 val_loss: 0.44205188751220703, train_loss: 0.4298950135707855\n",
      "19940 val_loss: 0.440748929977417, train_loss: 0.42826446890830994\n",
      "19950 val_loss: 0.43984732031822205, train_loss: 0.4275924861431122\n",
      "19960 val_loss: 0.43948885798454285, train_loss: 0.42653051018714905\n",
      "19970 val_loss: 0.43854373693466187, train_loss: 0.4263027310371399\n",
      "19980 val_loss: 0.4376472532749176, train_loss: 0.4251413941383362\n",
      "19990 val_loss: 0.4370450973510742, train_loss: 0.42440319061279297\n",
      "20000 val_loss: 0.437453031539917, train_loss: 0.4252403974533081\n",
      "20010 val_loss: 0.4362157881259918, train_loss: 0.42372870445251465\n",
      "20020 val_loss: 0.4360063374042511, train_loss: 0.4239185154438019\n",
      "20030 val_loss: 0.4344918727874756, train_loss: 0.4223896265029907\n",
      "20040 val_loss: 0.4341319501399994, train_loss: 0.4216040372848511\n",
      "20050 val_loss: 0.4333462417125702, train_loss: 0.42107081413269043\n",
      "20060 val_loss: 0.4328065514564514, train_loss: 0.42086029052734375\n",
      "20070 val_loss: 0.4314316511154175, train_loss: 0.419342041015625\n",
      "20080 val_loss: 0.43047115206718445, train_loss: 0.4182998538017273\n",
      "20090 val_loss: 0.430228054523468, train_loss: 0.41777166724205017\n",
      "20100 val_loss: 0.4283021092414856, train_loss: 0.41619613766670227\n",
      "20110 val_loss: 0.428215891122818, train_loss: 0.41679754853248596\n",
      "20120 val_loss: 0.4268898665904999, train_loss: 0.4152711033821106\n",
      "20130 val_loss: 0.4249521493911743, train_loss: 0.41326820850372314\n",
      "20140 val_loss: 0.4246675670146942, train_loss: 0.4128275215625763\n",
      "20150 val_loss: 0.42296102643013, train_loss: 0.41142433881759644\n",
      "20160 val_loss: 0.4220677614212036, train_loss: 0.4106179475784302\n",
      "20170 val_loss: 0.4207662045955658, train_loss: 0.4094621241092682\n",
      "20180 val_loss: 0.42037972807884216, train_loss: 0.40925875306129456\n",
      "20190 val_loss: 0.41800403594970703, train_loss: 0.4069478511810303\n",
      "20200 val_loss: 0.41632333397865295, train_loss: 0.4055137634277344\n",
      "20210 val_loss: 0.4154798984527588, train_loss: 0.4046688675880432\n",
      "20220 val_loss: 0.41520532965660095, train_loss: 0.4045705199241638\n",
      "20230 val_loss: 0.4145090878009796, train_loss: 0.40397700667381287\n",
      "20240 val_loss: 0.4129735231399536, train_loss: 0.4024691581726074\n",
      "20250 val_loss: 0.4136512875556946, train_loss: 0.4031638205051422\n",
      "20260 val_loss: 0.4120450019836426, train_loss: 0.4016459584236145\n",
      "20270 val_loss: 0.4091792404651642, train_loss: 0.39911898970603943\n",
      "20280 val_loss: 0.4096355438232422, train_loss: 0.3994135856628418\n",
      "20290 val_loss: 0.40809449553489685, train_loss: 0.39815008640289307\n",
      "20300 val_loss: 0.40691983699798584, train_loss: 0.39705413579940796\n",
      "20310 val_loss: 0.40612488985061646, train_loss: 0.39631786942481995\n",
      "20320 val_loss: 0.40594664216041565, train_loss: 0.39619725942611694\n",
      "20330 val_loss: 0.4045369029045105, train_loss: 0.3951086401939392\n",
      "20340 val_loss: 0.4035941958427429, train_loss: 0.3942800760269165\n",
      "20350 val_loss: 0.4058475196361542, train_loss: 0.39615771174430847\n",
      "20360 val_loss: 0.40216606855392456, train_loss: 0.39294910430908203\n",
      "20370 val_loss: 0.4016730487346649, train_loss: 0.39244669675827026\n",
      "20380 val_loss: 0.4007260203361511, train_loss: 0.3918893337249756\n",
      "20390 val_loss: 0.40058356523513794, train_loss: 0.39164674282073975\n",
      "20400 val_loss: 0.40129369497299194, train_loss: 0.39203593134880066\n",
      "20410 val_loss: 0.4004221260547638, train_loss: 0.3911236822605133\n",
      "20420 val_loss: 0.3993263244628906, train_loss: 0.3902701735496521\n",
      "20430 val_loss: 0.39945757389068604, train_loss: 0.3903910219669342\n",
      "20440 val_loss: 0.3998458683490753, train_loss: 0.3905611038208008\n",
      "20450 val_loss: 0.3978934586048126, train_loss: 0.3891637921333313\n",
      "20460 val_loss: 0.3978022336959839, train_loss: 0.3889361321926117\n",
      "20470 val_loss: 0.39740249514579773, train_loss: 0.3886982798576355\n",
      "20480 val_loss: 0.3962872326374054, train_loss: 0.3882856070995331\n",
      "20490 val_loss: 0.39638209342956543, train_loss: 0.38828298449516296\n",
      "20500 val_loss: 0.3957313597202301, train_loss: 0.3873777985572815\n",
      "20510 val_loss: 0.39595478773117065, train_loss: 0.3880043029785156\n",
      "20520 val_loss: 0.3947806656360626, train_loss: 0.3867027163505554\n",
      "20530 val_loss: 0.39651018381118774, train_loss: 0.3874601125717163\n",
      "20540 val_loss: 0.39530062675476074, train_loss: 0.3865358531475067\n",
      "20550 val_loss: 0.3944375813007355, train_loss: 0.385919988155365\n",
      "20560 val_loss: 0.3939174711704254, train_loss: 0.38563111424446106\n",
      "20570 val_loss: 0.3932019770145416, train_loss: 0.38538238406181335\n",
      "20580 val_loss: 0.3936806619167328, train_loss: 0.3853417932987213\n",
      "20590 val_loss: 0.39429110288619995, train_loss: 0.38590309023857117\n",
      "20600 val_loss: 0.39270150661468506, train_loss: 0.38469141721725464\n",
      "20610 val_loss: 0.39134910702705383, train_loss: 0.38376501202583313\n",
      "20620 val_loss: 0.3920588791370392, train_loss: 0.38410210609436035\n",
      "20630 val_loss: 0.39243054389953613, train_loss: 0.3842679262161255\n",
      "20640 val_loss: 0.39043888449668884, train_loss: 0.3830315172672272\n",
      "20650 val_loss: 0.3908960223197937, train_loss: 0.3830900192260742\n",
      "20660 val_loss: 0.3923479914665222, train_loss: 0.38392361998558044\n",
      "20670 val_loss: 0.39305582642555237, train_loss: 0.3844393789768219\n",
      "20680 val_loss: 0.3916403353214264, train_loss: 0.38309651613235474\n",
      "20690 val_loss: 0.3898579180240631, train_loss: 0.38190025091171265\n",
      "20700 val_loss: 0.39172086119651794, train_loss: 0.3831688165664673\n",
      "20710 val_loss: 0.3969649374485016, train_loss: 0.38754066824913025\n",
      "20720 val_loss: 0.39017847180366516, train_loss: 0.3818013072013855\n",
      "20730 val_loss: 0.3884885311126709, train_loss: 0.38064607977867126\n",
      "20740 val_loss: 0.3905400335788727, train_loss: 0.3821796178817749\n",
      "20750 val_loss: 0.3883964419364929, train_loss: 0.38043397665023804\n",
      "20760 val_loss: 0.3880845606327057, train_loss: 0.3802308440208435\n",
      "20770 val_loss: 0.3871311545372009, train_loss: 0.37956222891807556\n",
      "20780 val_loss: 0.3872988224029541, train_loss: 0.3796139657497406\n",
      "20790 val_loss: 0.3869599997997284, train_loss: 0.3794209063053131\n",
      "20800 val_loss: 0.38747209310531616, train_loss: 0.3797503411769867\n",
      "20810 val_loss: 0.3860445022583008, train_loss: 0.3785216808319092\n",
      "20820 val_loss: 0.38606008887290955, train_loss: 0.37846413254737854\n",
      "20830 val_loss: 0.38585856556892395, train_loss: 0.3783729076385498\n",
      "20840 val_loss: 0.386437326669693, train_loss: 0.37871211767196655\n",
      "20850 val_loss: 0.3853365480899811, train_loss: 0.3777831196784973\n",
      "20860 val_loss: 0.3848951458930969, train_loss: 0.37741297483444214\n",
      "20870 val_loss: 0.3844411075115204, train_loss: 0.37698543071746826\n",
      "20880 val_loss: 0.3860115706920624, train_loss: 0.3780197501182556\n",
      "20890 val_loss: 0.38615983724594116, train_loss: 0.3780577778816223\n",
      "20900 val_loss: 0.38391125202178955, train_loss: 0.3764822781085968\n",
      "20910 val_loss: 0.38616639375686646, train_loss: 0.37803560495376587\n",
      "20920 val_loss: 0.38537484407424927, train_loss: 0.37744054198265076\n",
      "20930 val_loss: 0.3832675516605377, train_loss: 0.3758326470851898\n",
      "20940 val_loss: 0.3830755949020386, train_loss: 0.37572020292282104\n",
      "20950 val_loss: 0.38329261541366577, train_loss: 0.37576523423194885\n",
      "20960 val_loss: 0.38493481278419495, train_loss: 0.37697479128837585\n",
      "20970 val_loss: 0.38264745473861694, train_loss: 0.3750740885734558\n",
      "20980 val_loss: 0.3850398063659668, train_loss: 0.37703007459640503\n",
      "20990 val_loss: 0.3852854073047638, train_loss: 0.37728044390678406\n",
      "21000 val_loss: 0.3826386034488678, train_loss: 0.3749535083770752\n",
      "21010 val_loss: 0.38423576951026917, train_loss: 0.3761238157749176\n",
      "21020 val_loss: 0.38214534521102905, train_loss: 0.37453117966651917\n",
      "21030 val_loss: 0.38475725054740906, train_loss: 0.37681809067726135\n",
      "21040 val_loss: 0.3814839720726013, train_loss: 0.3738633394241333\n",
      "21050 val_loss: 0.3834370970726013, train_loss: 0.37545180320739746\n",
      "21060 val_loss: 0.38118189573287964, train_loss: 0.37378641963005066\n",
      "21070 val_loss: 0.3802722692489624, train_loss: 0.3733166754245758\n",
      "21080 val_loss: 0.38055166602134705, train_loss: 0.37321385741233826\n",
      "21090 val_loss: 0.3833405375480652, train_loss: 0.3754321336746216\n",
      "21100 val_loss: 0.38212499022483826, train_loss: 0.3741380572319031\n",
      "21110 val_loss: 0.3821997046470642, train_loss: 0.3740743100643158\n",
      "21120 val_loss: 0.38070157170295715, train_loss: 0.3728664219379425\n",
      "21130 val_loss: 0.3827498257160187, train_loss: 0.3745013177394867\n",
      "21140 val_loss: 0.3795205354690552, train_loss: 0.3720601499080658\n",
      "21150 val_loss: 0.37923669815063477, train_loss: 0.3717772364616394\n",
      "21160 val_loss: 0.3791961371898651, train_loss: 0.3719039559364319\n",
      "21170 val_loss: 0.37953731417655945, train_loss: 0.37192749977111816\n",
      "21180 val_loss: 0.378758043050766, train_loss: 0.3712524473667145\n",
      "21190 val_loss: 0.381216436624527, train_loss: 0.3733212947845459\n",
      "21200 val_loss: 0.37887120246887207, train_loss: 0.37111353874206543\n",
      "21210 val_loss: 0.37864983081817627, train_loss: 0.37096863985061646\n",
      "21220 val_loss: 0.3782320022583008, train_loss: 0.37093910574913025\n",
      "21230 val_loss: 0.37811991572380066, train_loss: 0.3705710172653198\n",
      "21240 val_loss: 0.37889888882637024, train_loss: 0.3711969554424286\n",
      "21250 val_loss: 0.37886181473731995, train_loss: 0.3711911141872406\n",
      "21260 val_loss: 0.3776133358478546, train_loss: 0.3701518476009369\n",
      "21270 val_loss: 0.3793315887451172, train_loss: 0.37161287665367126\n",
      "21280 val_loss: 0.3781857192516327, train_loss: 0.3709346652030945\n",
      "21290 val_loss: 0.3775026500225067, train_loss: 0.3700726628303528\n",
      "21300 val_loss: 0.37863415479660034, train_loss: 0.37089037895202637\n",
      "21310 val_loss: 0.37712085247039795, train_loss: 0.3695409595966339\n",
      "21320 val_loss: 0.3767448365688324, train_loss: 0.3693521320819855\n",
      "21330 val_loss: 0.3773816227912903, train_loss: 0.3698691129684448\n",
      "21340 val_loss: 0.3780794143676758, train_loss: 0.370371550321579\n",
      "21350 val_loss: 0.3776295483112335, train_loss: 0.36981862783432007\n",
      "21360 val_loss: 0.3767554461956024, train_loss: 0.36895084381103516\n",
      "21370 val_loss: 0.37653687596321106, train_loss: 0.3690483868122101\n",
      "21380 val_loss: 0.37563520669937134, train_loss: 0.3683112859725952\n",
      "21390 val_loss: 0.37552350759506226, train_loss: 0.3680694103240967\n",
      "21400 val_loss: 0.3760048449039459, train_loss: 0.36832162737846375\n",
      "21410 val_loss: 0.3760066032409668, train_loss: 0.3682682514190674\n",
      "21420 val_loss: 0.37459829449653625, train_loss: 0.36748799681663513\n",
      "21430 val_loss: 0.37462320923805237, train_loss: 0.367336630821228\n",
      "21440 val_loss: 0.37555691599845886, train_loss: 0.3678089380264282\n",
      "21450 val_loss: 0.3757702708244324, train_loss: 0.3677482306957245\n",
      "21460 val_loss: 0.37555134296417236, train_loss: 0.36775341629981995\n",
      "21470 val_loss: 0.37547269463539124, train_loss: 0.36766767501831055\n",
      "21480 val_loss: 0.37514635920524597, train_loss: 0.3673199713230133\n",
      "21490 val_loss: 0.374565988779068, train_loss: 0.3666488528251648\n",
      "21500 val_loss: 0.3755924105644226, train_loss: 0.36722493171691895\n",
      "21510 val_loss: 0.37602654099464417, train_loss: 0.3676241934299469\n",
      "21520 val_loss: 0.3757038712501526, train_loss: 0.36729463934898376\n",
      "21530 val_loss: 0.3751297891139984, train_loss: 0.36707231402397156\n",
      "21540 val_loss: 0.37446919083595276, train_loss: 0.36661627888679504\n",
      "21550 val_loss: 0.3739365339279175, train_loss: 0.36638936400413513\n",
      "21560 val_loss: 0.3739290237426758, train_loss: 0.3661140501499176\n",
      "21570 val_loss: 0.37680718302726746, train_loss: 0.3684001863002777\n",
      "21580 val_loss: 0.3741992712020874, train_loss: 0.3659868836402893\n",
      "21590 val_loss: 0.37443026900291443, train_loss: 0.36630886793136597\n",
      "21600 val_loss: 0.37389248609542847, train_loss: 0.36564284563064575\n",
      "21610 val_loss: 0.37391531467437744, train_loss: 0.3655852973461151\n",
      "21620 val_loss: 0.37441980838775635, train_loss: 0.36625537276268005\n",
      "21630 val_loss: 0.3738771975040436, train_loss: 0.36574116349220276\n",
      "21640 val_loss: 0.3735888600349426, train_loss: 0.36518165469169617\n",
      "21650 val_loss: 0.37406182289123535, train_loss: 0.36563873291015625\n",
      "21660 val_loss: 0.3744461238384247, train_loss: 0.3664359748363495\n",
      "21670 val_loss: 0.3720344305038452, train_loss: 0.36424580216407776\n",
      "21680 val_loss: 0.37225085496902466, train_loss: 0.36432209610939026\n",
      "21690 val_loss: 0.37259799242019653, train_loss: 0.3645782768726349\n",
      "21700 val_loss: 0.37237468361854553, train_loss: 0.36431214213371277\n",
      "21710 val_loss: 0.37301668524742126, train_loss: 0.36466270685195923\n",
      "21720 val_loss: 0.3719263970851898, train_loss: 0.3638631999492645\n",
      "21730 val_loss: 0.37146317958831787, train_loss: 0.3637825548648834\n",
      "21740 val_loss: 0.3711586892604828, train_loss: 0.36323654651641846\n",
      "21750 val_loss: 0.3712242543697357, train_loss: 0.3632630407810211\n",
      "21760 val_loss: 0.37380996346473694, train_loss: 0.36560899019241333\n",
      "21770 val_loss: 0.37105900049209595, train_loss: 0.3634932339191437\n",
      "21780 val_loss: 0.37101370096206665, train_loss: 0.36310943961143494\n",
      "21790 val_loss: 0.3705724775791168, train_loss: 0.3629595637321472\n",
      "21800 val_loss: 0.3707926869392395, train_loss: 0.36352792382240295\n",
      "21810 val_loss: 0.3703137934207916, train_loss: 0.36258426308631897\n",
      "21820 val_loss: 0.3710514307022095, train_loss: 0.3629489541053772\n",
      "21830 val_loss: 0.3710233271121979, train_loss: 0.36302274465560913\n",
      "21840 val_loss: 0.37282609939575195, train_loss: 0.36467093229293823\n",
      "21850 val_loss: 0.37062883377075195, train_loss: 0.3626473844051361\n",
      "21860 val_loss: 0.37157827615737915, train_loss: 0.3636636435985565\n",
      "21870 val_loss: 0.3712635040283203, train_loss: 0.3631032407283783\n",
      "21880 val_loss: 0.3701673150062561, train_loss: 0.3623567223548889\n",
      "21890 val_loss: 0.36977672576904297, train_loss: 0.3620221018791199\n",
      "21900 val_loss: 0.37060409784317017, train_loss: 0.36281618475914\n",
      "21910 val_loss: 0.36966079473495483, train_loss: 0.36191800236701965\n",
      "21920 val_loss: 0.3695245087146759, train_loss: 0.361575186252594\n",
      "21930 val_loss: 0.369352787733078, train_loss: 0.3616500198841095\n",
      "21940 val_loss: 0.36999964714050293, train_loss: 0.36203089356422424\n",
      "21950 val_loss: 0.36907047033309937, train_loss: 0.3611127436161041\n",
      "21960 val_loss: 0.3709929287433624, train_loss: 0.36271822452545166\n",
      "21970 val_loss: 0.3691987991333008, train_loss: 0.36132174730300903\n",
      "21980 val_loss: 0.3706417977809906, train_loss: 0.3627694845199585\n",
      "21990 val_loss: 0.36850735545158386, train_loss: 0.36088427901268005\n",
      "22000 val_loss: 0.36867350339889526, train_loss: 0.36065512895584106\n",
      "22010 val_loss: 0.36886298656463623, train_loss: 0.36095327138900757\n",
      "22020 val_loss: 0.3685030937194824, train_loss: 0.360397607088089\n",
      "22030 val_loss: 0.3684788942337036, train_loss: 0.36035779118537903\n",
      "22040 val_loss: 0.36792489886283875, train_loss: 0.3602927029132843\n",
      "22050 val_loss: 0.36983203887939453, train_loss: 0.3615773618221283\n",
      "22060 val_loss: 0.3685389459133148, train_loss: 0.36029136180877686\n",
      "22070 val_loss: 0.3683975338935852, train_loss: 0.36002346873283386\n",
      "22080 val_loss: 0.3697414696216583, train_loss: 0.3616226315498352\n",
      "22090 val_loss: 0.36678311228752136, train_loss: 0.35916319489479065\n",
      "22100 val_loss: 0.36755168437957764, train_loss: 0.3597797155380249\n",
      "22110 val_loss: 0.3697024881839752, train_loss: 0.3612932860851288\n",
      "22120 val_loss: 0.36867138743400574, train_loss: 0.3607000410556793\n",
      "22130 val_loss: 0.36756759881973267, train_loss: 0.35939767956733704\n",
      "22140 val_loss: 0.36904141306877136, train_loss: 0.36057913303375244\n",
      "22150 val_loss: 0.3682789206504822, train_loss: 0.35997819900512695\n",
      "22160 val_loss: 0.3672770857810974, train_loss: 0.3595843017101288\n",
      "22170 val_loss: 0.36789411306381226, train_loss: 0.35975736379623413\n",
      "22180 val_loss: 0.3660779297351837, train_loss: 0.35831186175346375\n",
      "22190 val_loss: 0.36716580390930176, train_loss: 0.35930973291397095\n",
      "22200 val_loss: 0.3653750717639923, train_loss: 0.35784679651260376\n",
      "22210 val_loss: 0.36528337001800537, train_loss: 0.3581591546535492\n",
      "22220 val_loss: 0.36677083373069763, train_loss: 0.3589000105857849\n",
      "22230 val_loss: 0.3654178977012634, train_loss: 0.3575611412525177\n",
      "22240 val_loss: 0.36662405729293823, train_loss: 0.35859939455986023\n",
      "22250 val_loss: 0.3670116662979126, train_loss: 0.358740895986557\n",
      "22260 val_loss: 0.36564525961875916, train_loss: 0.357616126537323\n",
      "22270 val_loss: 0.3656378984451294, train_loss: 0.357473224401474\n",
      "22280 val_loss: 0.3660343289375305, train_loss: 0.35780081152915955\n",
      "22290 val_loss: 0.3665933907032013, train_loss: 0.3582129180431366\n",
      "22300 val_loss: 0.365017294883728, train_loss: 0.35709381103515625\n",
      "22310 val_loss: 0.36720186471939087, train_loss: 0.3593696355819702\n",
      "22320 val_loss: 0.364136278629303, train_loss: 0.3567748963832855\n",
      "22330 val_loss: 0.36600446701049805, train_loss: 0.35788726806640625\n",
      "22340 val_loss: 0.3643020689487457, train_loss: 0.35694029927253723\n",
      "22350 val_loss: 0.3665223717689514, train_loss: 0.3583669364452362\n",
      "22360 val_loss: 0.36446696519851685, train_loss: 0.35678842663764954\n",
      "22370 val_loss: 0.36506396532058716, train_loss: 0.35725969076156616\n",
      "22380 val_loss: 0.36341720819473267, train_loss: 0.35625767707824707\n",
      "22390 val_loss: 0.3639073073863983, train_loss: 0.3562243580818176\n",
      "22400 val_loss: 0.3655119240283966, train_loss: 0.35765549540519714\n",
      "22410 val_loss: 0.36358606815338135, train_loss: 0.3557320833206177\n",
      "22420 val_loss: 0.36572200059890747, train_loss: 0.3577093780040741\n",
      "22430 val_loss: 0.36603599786758423, train_loss: 0.3581245541572571\n",
      "22440 val_loss: 0.36381033062934875, train_loss: 0.35661301016807556\n",
      "22450 val_loss: 0.3627451956272125, train_loss: 0.3552624583244324\n",
      "22460 val_loss: 0.36257463693618774, train_loss: 0.35508427023887634\n",
      "22470 val_loss: 0.3638050854206085, train_loss: 0.35574838519096375\n",
      "22480 val_loss: 0.36504796147346497, train_loss: 0.35682910680770874\n",
      "22490 val_loss: 0.3650016188621521, train_loss: 0.356234073638916\n",
      "22500 val_loss: 0.36387208104133606, train_loss: 0.35533836483955383\n",
      "22510 val_loss: 0.3657749891281128, train_loss: 0.3580200672149658\n",
      "22520 val_loss: 0.3628081977367401, train_loss: 0.3549393117427826\n",
      "22530 val_loss: 0.36310863494873047, train_loss: 0.35477766394615173\n",
      "22540 val_loss: 0.36272934079170227, train_loss: 0.3549394905567169\n",
      "22550 val_loss: 0.362403005361557, train_loss: 0.3545035123825073\n",
      "22560 val_loss: 0.36302831768989563, train_loss: 0.3548150062561035\n",
      "22570 val_loss: 0.3633991777896881, train_loss: 0.3550995886325836\n",
      "22580 val_loss: 0.36204782128334045, train_loss: 0.3540005683898926\n",
      "22590 val_loss: 0.36216413974761963, train_loss: 0.3540344536304474\n",
      "22600 val_loss: 0.3621525764465332, train_loss: 0.3542199730873108\n",
      "22610 val_loss: 0.3633888363838196, train_loss: 0.3550613820552826\n",
      "22620 val_loss: 0.36282214522361755, train_loss: 0.354757159948349\n",
      "22630 val_loss: 0.3628171682357788, train_loss: 0.3543693423271179\n",
      "22640 val_loss: 0.36282530426979065, train_loss: 0.3543190360069275\n",
      "22650 val_loss: 0.36279061436653137, train_loss: 0.35460546612739563\n",
      "22660 val_loss: 0.3633488714694977, train_loss: 0.35505571961402893\n",
      "22670 val_loss: 0.3609400987625122, train_loss: 0.35345259308815\n",
      "22680 val_loss: 0.3611002266407013, train_loss: 0.3531748056411743\n",
      "22690 val_loss: 0.3623867928981781, train_loss: 0.3539850115776062\n",
      "22700 val_loss: 0.3614448308944702, train_loss: 0.3533942997455597\n",
      "22710 val_loss: 0.36091747879981995, train_loss: 0.35319364070892334\n",
      "22720 val_loss: 0.36066555976867676, train_loss: 0.3528967499732971\n",
      "22730 val_loss: 0.3631097078323364, train_loss: 0.3551555573940277\n",
      "22740 val_loss: 0.36107581853866577, train_loss: 0.3536411225795746\n",
      "22750 val_loss: 0.3623321056365967, train_loss: 0.3538573086261749\n",
      "22760 val_loss: 0.36239078640937805, train_loss: 0.35391783714294434\n",
      "22770 val_loss: 0.3605383336544037, train_loss: 0.35259026288986206\n",
      "22780 val_loss: 0.36189502477645874, train_loss: 0.3539777398109436\n",
      "22790 val_loss: 0.35952460765838623, train_loss: 0.3520556390285492\n",
      "22800 val_loss: 0.3596457540988922, train_loss: 0.3521668612957001\n",
      "22810 val_loss: 0.36167651414871216, train_loss: 0.35387223958969116\n",
      "22820 val_loss: 0.3599908947944641, train_loss: 0.35251349210739136\n",
      "22830 val_loss: 0.3601149022579193, train_loss: 0.35218775272369385\n",
      "22840 val_loss: 0.3622158169746399, train_loss: 0.35429421067237854\n",
      "22850 val_loss: 0.3606749176979065, train_loss: 0.3523261845111847\n",
      "22860 val_loss: 0.360769659280777, train_loss: 0.35240066051483154\n",
      "22870 val_loss: 0.35964229702949524, train_loss: 0.35168516635894775\n",
      "22880 val_loss: 0.3624580502510071, train_loss: 0.3542587161064148\n",
      "22890 val_loss: 0.360068678855896, train_loss: 0.35192549228668213\n",
      "22900 val_loss: 0.36011433601379395, train_loss: 0.35191142559051514\n",
      "22910 val_loss: 0.3642427623271942, train_loss: 0.35612422227859497\n",
      "22920 val_loss: 0.3608494997024536, train_loss: 0.35293906927108765\n",
      "22930 val_loss: 0.3607485294342041, train_loss: 0.35240495204925537\n",
      "22940 val_loss: 0.3599291145801544, train_loss: 0.35197344422340393\n",
      "22950 val_loss: 0.3599337041378021, train_loss: 0.35233446955680847\n",
      "22960 val_loss: 0.35836026072502136, train_loss: 0.3508757948875427\n",
      "22970 val_loss: 0.358363538980484, train_loss: 0.35077184438705444\n",
      "22980 val_loss: 0.3600781559944153, train_loss: 0.35213011503219604\n",
      "22990 val_loss: 0.35850265622138977, train_loss: 0.35062307119369507\n",
      "23000 val_loss: 0.3586213290691376, train_loss: 0.3508482575416565\n",
      "23010 val_loss: 0.35928213596343994, train_loss: 0.35153257846832275\n",
      "23020 val_loss: 0.3594602048397064, train_loss: 0.35181793570518494\n",
      "23030 val_loss: 0.356687992811203, train_loss: 0.3498285412788391\n",
      "23040 val_loss: 0.3571702539920807, train_loss: 0.34994810819625854\n",
      "23050 val_loss: 0.35752859711647034, train_loss: 0.350285142660141\n",
      "23060 val_loss: 0.3563980758190155, train_loss: 0.34957000613212585\n",
      "23070 val_loss: 0.3572836220264435, train_loss: 0.34976765513420105\n",
      "23080 val_loss: 0.35719677805900574, train_loss: 0.34962618350982666\n",
      "23090 val_loss: 0.3568865656852722, train_loss: 0.34957513213157654\n",
      "23100 val_loss: 0.3566548526287079, train_loss: 0.3493499457836151\n",
      "23110 val_loss: 0.35677722096443176, train_loss: 0.34958314895629883\n",
      "23120 val_loss: 0.3570447266101837, train_loss: 0.349675714969635\n",
      "23130 val_loss: 0.3581826090812683, train_loss: 0.3503815531730652\n",
      "23140 val_loss: 0.35804134607315063, train_loss: 0.3502552807331085\n",
      "23150 val_loss: 0.35677412152290344, train_loss: 0.34982892870903015\n",
      "23160 val_loss: 0.356618732213974, train_loss: 0.3493902385234833\n",
      "23170 val_loss: 0.3555455207824707, train_loss: 0.34862372279167175\n",
      "23180 val_loss: 0.3556487262248993, train_loss: 0.3486754596233368\n",
      "23190 val_loss: 0.3553827702999115, train_loss: 0.34839653968811035\n",
      "23200 val_loss: 0.3554694354534149, train_loss: 0.3485306203365326\n",
      "23210 val_loss: 0.3553273379802704, train_loss: 0.3483280539512634\n",
      "23220 val_loss: 0.3558949828147888, train_loss: 0.3485378324985504\n",
      "23230 val_loss: 0.355631023645401, train_loss: 0.34848281741142273\n",
      "23240 val_loss: 0.3563835918903351, train_loss: 0.3492131233215332\n",
      "23250 val_loss: 0.3546176850795746, train_loss: 0.347891241312027\n",
      "23260 val_loss: 0.35772770643234253, train_loss: 0.34985247254371643\n",
      "23270 val_loss: 0.3589761555194855, train_loss: 0.3514972925186157\n",
      "23280 val_loss: 0.35546615719795227, train_loss: 0.34822720289230347\n",
      "23290 val_loss: 0.3597363829612732, train_loss: 0.3519877791404724\n",
      "23300 val_loss: 0.3552182912826538, train_loss: 0.347871869802475\n",
      "23310 val_loss: 0.3549260199069977, train_loss: 0.34800952672958374\n",
      "23320 val_loss: 0.3543766140937805, train_loss: 0.34775346517562866\n",
      "23330 val_loss: 0.3556438386440277, train_loss: 0.3486870229244232\n",
      "23340 val_loss: 0.35792797803878784, train_loss: 0.3499531149864197\n",
      "23350 val_loss: 0.35431981086730957, train_loss: 0.3476012051105499\n",
      "23360 val_loss: 0.3545260429382324, train_loss: 0.3477160930633545\n",
      "23370 val_loss: 0.3564640283584595, train_loss: 0.34926337003707886\n",
      "23380 val_loss: 0.3536803424358368, train_loss: 0.3473525643348694\n",
      "23390 val_loss: 0.3552261292934418, train_loss: 0.34951338171958923\n",
      "23400 val_loss: 0.35670772194862366, train_loss: 0.34961381554603577\n",
      "23410 val_loss: 0.3532199263572693, train_loss: 0.3466423451900482\n",
      "23420 val_loss: 0.3547268509864807, train_loss: 0.3475715219974518\n",
      "23430 val_loss: 0.3540000021457672, train_loss: 0.3476654887199402\n",
      "23440 val_loss: 0.3532429337501526, train_loss: 0.3467990458011627\n",
      "23450 val_loss: 0.35407933592796326, train_loss: 0.34739696979522705\n",
      "23460 val_loss: 0.36017847061157227, train_loss: 0.3526398241519928\n",
      "23470 val_loss: 0.354111909866333, train_loss: 0.34699365496635437\n",
      "23480 val_loss: 0.35468223690986633, train_loss: 0.34723207354545593\n",
      "23490 val_loss: 0.3532792627811432, train_loss: 0.3460988700389862\n",
      "23500 val_loss: 0.3535616099834442, train_loss: 0.3463645279407501\n",
      "23510 val_loss: 0.35346704721450806, train_loss: 0.34680551290512085\n",
      "23520 val_loss: 0.3536851406097412, train_loss: 0.34695208072662354\n",
      "23530 val_loss: 0.35473737120628357, train_loss: 0.3475610613822937\n",
      "23540 val_loss: 0.355320543050766, train_loss: 0.3481546938419342\n",
      "23550 val_loss: 0.3542253375053406, train_loss: 0.34706753492355347\n",
      "23560 val_loss: 0.35174864530563354, train_loss: 0.3453594446182251\n",
      "23570 val_loss: 0.35159289836883545, train_loss: 0.34531641006469727\n",
      "23580 val_loss: 0.35121455788612366, train_loss: 0.345611572265625\n",
      "23590 val_loss: 0.35401394963264465, train_loss: 0.3474038541316986\n",
      "23600 val_loss: 0.35155680775642395, train_loss: 0.34507492184638977\n",
      "23610 val_loss: 0.35226139426231384, train_loss: 0.3455670475959778\n",
      "23620 val_loss: 0.35355451703071594, train_loss: 0.34664860367774963\n",
      "23630 val_loss: 0.35263320803642273, train_loss: 0.34575220942497253\n",
      "23640 val_loss: 0.3511636257171631, train_loss: 0.34481409192085266\n",
      "23650 val_loss: 0.35317835211753845, train_loss: 0.3460748493671417\n",
      "23660 val_loss: 0.35117045044898987, train_loss: 0.34472355246543884\n",
      "23670 val_loss: 0.35375094413757324, train_loss: 0.34682366251945496\n",
      "23680 val_loss: 0.35234156250953674, train_loss: 0.3453965485095978\n",
      "23690 val_loss: 0.3509981334209442, train_loss: 0.34478214383125305\n",
      "23700 val_loss: 0.3508940041065216, train_loss: 0.34467482566833496\n",
      "23710 val_loss: 0.35072746872901917, train_loss: 0.3443618714809418\n",
      "23720 val_loss: 0.3513507843017578, train_loss: 0.34471139311790466\n",
      "23730 val_loss: 0.3524572253227234, train_loss: 0.34536489844322205\n",
      "23740 val_loss: 0.3537289500236511, train_loss: 0.34721794724464417\n",
      "23750 val_loss: 0.3506007492542267, train_loss: 0.34388571977615356\n",
      "23760 val_loss: 0.3513597548007965, train_loss: 0.3448111116886139\n",
      "23770 val_loss: 0.35287535190582275, train_loss: 0.3457501530647278\n",
      "23780 val_loss: 0.3540513515472412, train_loss: 0.34730276465415955\n",
      "23790 val_loss: 0.35204365849494934, train_loss: 0.3443802297115326\n",
      "23800 val_loss: 0.3504880666732788, train_loss: 0.34416961669921875\n",
      "23810 val_loss: 0.35063236951828003, train_loss: 0.34392407536506653\n",
      "23820 val_loss: 0.34956416487693787, train_loss: 0.3430081903934479\n",
      "23830 val_loss: 0.3501139283180237, train_loss: 0.34330838918685913\n",
      "23840 val_loss: 0.3502977192401886, train_loss: 0.3433571755886078\n",
      "23850 val_loss: 0.3505251109600067, train_loss: 0.34347259998321533\n",
      "23860 val_loss: 0.3496011197566986, train_loss: 0.3428680896759033\n",
      "23870 val_loss: 0.34965434670448303, train_loss: 0.34299150109291077\n",
      "23880 val_loss: 0.3502306044101715, train_loss: 0.3441079556941986\n",
      "23890 val_loss: 0.3490274250507355, train_loss: 0.34253835678100586\n",
      "23900 val_loss: 0.3484806418418884, train_loss: 0.34257784485816956\n",
      "23910 val_loss: 0.3502155840396881, train_loss: 0.3436373472213745\n",
      "23920 val_loss: 0.3484223186969757, train_loss: 0.3425883650779724\n",
      "23930 val_loss: 0.34900227189064026, train_loss: 0.3433772027492523\n",
      "23940 val_loss: 0.3487030863761902, train_loss: 0.3423953056335449\n",
      "23950 val_loss: 0.3486684560775757, train_loss: 0.3426014184951782\n",
      "23960 val_loss: 0.3476014733314514, train_loss: 0.3421035706996918\n",
      "23970 val_loss: 0.3500683903694153, train_loss: 0.34375232458114624\n",
      "23980 val_loss: 0.3478884696960449, train_loss: 0.34174591302871704\n",
      "23990 val_loss: 0.3472864031791687, train_loss: 0.3416222035884857\n",
      "24000 val_loss: 0.35098665952682495, train_loss: 0.34501758217811584\n",
      "24010 val_loss: 0.346822589635849, train_loss: 0.3415783941745758\n",
      "24020 val_loss: 0.3479619026184082, train_loss: 0.341886430978775\n",
      "24030 val_loss: 0.34743350744247437, train_loss: 0.3413173258304596\n",
      "24040 val_loss: 0.3472338914871216, train_loss: 0.34135276079177856\n",
      "24050 val_loss: 0.34808602929115295, train_loss: 0.3413282334804535\n",
      "24060 val_loss: 0.3473326861858368, train_loss: 0.34128910303115845\n",
      "24070 val_loss: 0.34704214334487915, train_loss: 0.3408161401748657\n",
      "24080 val_loss: 0.3473159074783325, train_loss: 0.3410963714122772\n",
      "24090 val_loss: 0.349264532327652, train_loss: 0.34401416778564453\n",
      "24100 val_loss: 0.3472425937652588, train_loss: 0.3408677577972412\n",
      "24110 val_loss: 0.3485856056213379, train_loss: 0.34142005443573\n",
      "24120 val_loss: 0.3483639657497406, train_loss: 0.3414069414138794\n",
      "24130 val_loss: 0.3482537865638733, train_loss: 0.3417133390903473\n",
      "24140 val_loss: 0.3484521806240082, train_loss: 0.3416295349597931\n",
      "24150 val_loss: 0.3467787802219391, train_loss: 0.34057775139808655\n",
      "24160 val_loss: 0.34668660163879395, train_loss: 0.34112444519996643\n",
      "24170 val_loss: 0.3470188081264496, train_loss: 0.3408811390399933\n",
      "24180 val_loss: 0.3462114632129669, train_loss: 0.3408350646495819\n",
      "24190 val_loss: 0.3456893265247345, train_loss: 0.3400525748729706\n",
      "24200 val_loss: 0.3464718461036682, train_loss: 0.34065714478492737\n",
      "24210 val_loss: 0.3468141257762909, train_loss: 0.341154545545578\n",
      "24220 val_loss: 0.3451818823814392, train_loss: 0.34006431698799133\n",
      "24230 val_loss: 0.34478214383125305, train_loss: 0.33932438492774963\n",
      "24240 val_loss: 0.34473884105682373, train_loss: 0.3391086459159851\n",
      "24250 val_loss: 0.3448401689529419, train_loss: 0.33956801891326904\n",
      "24260 val_loss: 0.3449799120426178, train_loss: 0.3395357131958008\n",
      "24270 val_loss: 0.3462837338447571, train_loss: 0.34036242961883545\n",
      "24280 val_loss: 0.34527942538261414, train_loss: 0.3392302989959717\n",
      "24290 val_loss: 0.34542375802993774, train_loss: 0.33918288350105286\n",
      "24300 val_loss: 0.3458247184753418, train_loss: 0.3395501673221588\n",
      "24310 val_loss: 0.34406182169914246, train_loss: 0.33847564458847046\n",
      "24320 val_loss: 0.34450528025627136, train_loss: 0.3388430178165436\n",
      "24330 val_loss: 0.34515923261642456, train_loss: 0.33953726291656494\n",
      "24340 val_loss: 0.34508126974105835, train_loss: 0.33950552344322205\n",
      "24350 val_loss: 0.3439059555530548, train_loss: 0.3382577896118164\n",
      "24360 val_loss: 0.34466561675071716, train_loss: 0.338503360748291\n",
      "24370 val_loss: 0.34332340955734253, train_loss: 0.3380976617336273\n",
      "24380 val_loss: 0.34476718306541443, train_loss: 0.33867785334587097\n",
      "24390 val_loss: 0.34552013874053955, train_loss: 0.33896604180336\n",
      "24400 val_loss: 0.3441697955131531, train_loss: 0.3379509150981903\n",
      "24410 val_loss: 0.35125476121902466, train_loss: 0.3443961441516876\n",
      "24420 val_loss: 0.34824299812316895, train_loss: 0.3413727581501007\n",
      "24430 val_loss: 0.343776136636734, train_loss: 0.3379436433315277\n",
      "24440 val_loss: 0.34478455781936646, train_loss: 0.3381763994693756\n",
      "24450 val_loss: 0.3498634994029999, train_loss: 0.3434642255306244\n",
      "24460 val_loss: 0.3452317714691162, train_loss: 0.33915871381759644\n",
      "24470 val_loss: 0.34535983204841614, train_loss: 0.3399724066257477\n",
      "24480 val_loss: 0.34322038292884827, train_loss: 0.3373936116695404\n",
      "24490 val_loss: 0.3456823229789734, train_loss: 0.33950275182724\n",
      "24500 val_loss: 0.34435856342315674, train_loss: 0.3383133113384247\n",
      "24510 val_loss: 0.3428504765033722, train_loss: 0.3372984528541565\n",
      "24520 val_loss: 0.3421659469604492, train_loss: 0.33670181035995483\n",
      "24530 val_loss: 0.3429945409297943, train_loss: 0.33693358302116394\n",
      "24540 val_loss: 0.3434031307697296, train_loss: 0.3375905752182007\n",
      "24550 val_loss: 0.3459705710411072, train_loss: 0.3398055136203766\n",
      "24560 val_loss: 0.34276244044303894, train_loss: 0.3370727598667145\n",
      "24570 val_loss: 0.3415321111679077, train_loss: 0.33712849020957947\n",
      "24580 val_loss: 0.341578871011734, train_loss: 0.33776381611824036\n",
      "24590 val_loss: 0.34178057312965393, train_loss: 0.33645808696746826\n",
      "24600 val_loss: 0.3429136574268341, train_loss: 0.33685219287872314\n",
      "24610 val_loss: 0.34259459376335144, train_loss: 0.33716148138046265\n",
      "24620 val_loss: 0.3419860005378723, train_loss: 0.33667364716529846\n",
      "24630 val_loss: 0.34370091557502747, train_loss: 0.33849087357521057\n",
      "24640 val_loss: 0.34055760502815247, train_loss: 0.3355329930782318\n",
      "24650 val_loss: 0.3415670692920685, train_loss: 0.33619600534439087\n",
      "24660 val_loss: 0.33975324034690857, train_loss: 0.3356742560863495\n",
      "24670 val_loss: 0.3396458625793457, train_loss: 0.3354417681694031\n",
      "24680 val_loss: 0.3399043679237366, train_loss: 0.3351874053478241\n",
      "24690 val_loss: 0.33990079164505005, train_loss: 0.3349781036376953\n",
      "24700 val_loss: 0.3405751883983612, train_loss: 0.3353525400161743\n",
      "24710 val_loss: 0.3437696099281311, train_loss: 0.33868882060050964\n",
      "24720 val_loss: 0.3390723466873169, train_loss: 0.33455926179885864\n",
      "24730 val_loss: 0.33910807967185974, train_loss: 0.33432862162590027\n",
      "24740 val_loss: 0.3393108546733856, train_loss: 0.33441877365112305\n",
      "24750 val_loss: 0.3396318256855011, train_loss: 0.3347166180610657\n",
      "24760 val_loss: 0.33897414803504944, train_loss: 0.334256112575531\n",
      "24770 val_loss: 0.34256303310394287, train_loss: 0.33758845925331116\n",
      "24780 val_loss: 0.33903026580810547, train_loss: 0.3339952230453491\n",
      "24790 val_loss: 0.3417467176914215, train_loss: 0.33620452880859375\n",
      "24800 val_loss: 0.33857786655426025, train_loss: 0.3339564800262451\n",
      "24810 val_loss: 0.33948320150375366, train_loss: 0.33446285128593445\n",
      "24820 val_loss: 0.33790212869644165, train_loss: 0.33349376916885376\n",
      "24830 val_loss: 0.3387230336666107, train_loss: 0.33379948139190674\n",
      "24840 val_loss: 0.3383454382419586, train_loss: 0.3335193991661072\n",
      "24850 val_loss: 0.3437305986881256, train_loss: 0.3381478786468506\n",
      "24860 val_loss: 0.33985692262649536, train_loss: 0.3347095549106598\n",
      "24870 val_loss: 0.33917558193206787, train_loss: 0.33375173807144165\n",
      "24880 val_loss: 0.33849671483039856, train_loss: 0.3335667848587036\n",
      "24890 val_loss: 0.3419583737850189, train_loss: 0.3361132740974426\n",
      "24900 val_loss: 0.3381563425064087, train_loss: 0.3328380286693573\n",
      "24910 val_loss: 0.3402361273765564, train_loss: 0.33499157428741455\n",
      "24920 val_loss: 0.3384024202823639, train_loss: 0.3331487774848938\n",
      "24930 val_loss: 0.3412216305732727, train_loss: 0.33795657753944397\n",
      "24940 val_loss: 0.3378472626209259, train_loss: 0.33312395215034485\n",
      "24950 val_loss: 0.33714359998703003, train_loss: 0.33228370547294617\n",
      "24960 val_loss: 0.338900625705719, train_loss: 0.3335210084915161\n",
      "24970 val_loss: 0.33774176239967346, train_loss: 0.3326025605201721\n",
      "24980 val_loss: 0.33797144889831543, train_loss: 0.33291423320770264\n",
      "24990 val_loss: 0.3370967209339142, train_loss: 0.3321360945701599\n",
      "25000 val_loss: 0.33690646290779114, train_loss: 0.3321334421634674\n",
      "25010 val_loss: 0.3373112678527832, train_loss: 0.33226898312568665\n",
      "25020 val_loss: 0.33822670578956604, train_loss: 0.3328891694545746\n",
      "25030 val_loss: 0.34411194920539856, train_loss: 0.3393346071243286\n",
      "25040 val_loss: 0.33878955245018005, train_loss: 0.33260226249694824\n",
      "25050 val_loss: 0.3409242033958435, train_loss: 0.3350330591201782\n",
      "25060 val_loss: 0.3360791504383087, train_loss: 0.33102962374687195\n",
      "25070 val_loss: 0.338839054107666, train_loss: 0.3325149714946747\n",
      "25080 val_loss: 0.33630675077438354, train_loss: 0.33105406165122986\n",
      "25090 val_loss: 0.3379908502101898, train_loss: 0.3334716856479645\n",
      "25100 val_loss: 0.336943119764328, train_loss: 0.33227217197418213\n",
      "25110 val_loss: 0.3368458151817322, train_loss: 0.33121928572654724\n",
      "25120 val_loss: 0.3371071517467499, train_loss: 0.33132651448249817\n",
      "25130 val_loss: 0.3374485969543457, train_loss: 0.3315387964248657\n",
      "25140 val_loss: 0.33667463064193726, train_loss: 0.331428200006485\n",
      "25150 val_loss: 0.3372556269168854, train_loss: 0.3316531777381897\n",
      "25160 val_loss: 0.33572667837142944, train_loss: 0.3310960829257965\n",
      "25170 val_loss: 0.33511853218078613, train_loss: 0.33044108748435974\n",
      "25180 val_loss: 0.3348267078399658, train_loss: 0.3298782408237457\n",
      "25190 val_loss: 0.33472809195518494, train_loss: 0.3297020196914673\n",
      "25200 val_loss: 0.3348470628261566, train_loss: 0.33079642057418823\n",
      "25210 val_loss: 0.3365212380886078, train_loss: 0.33108198642730713\n",
      "25220 val_loss: 0.3344142735004425, train_loss: 0.3299429714679718\n",
      "25230 val_loss: 0.33398428559303284, train_loss: 0.3296978175640106\n",
      "25240 val_loss: 0.3347729444503784, train_loss: 0.3298196494579315\n",
      "25250 val_loss: 0.335453063249588, train_loss: 0.33049124479293823\n",
      "25260 val_loss: 0.3375023305416107, train_loss: 0.3330971598625183\n",
      "25270 val_loss: 0.3352767527103424, train_loss: 0.3300129771232605\n",
      "25280 val_loss: 0.3336111605167389, train_loss: 0.32881709933280945\n",
      "25290 val_loss: 0.33448976278305054, train_loss: 0.32917967438697815\n",
      "25300 val_loss: 0.33579689264297485, train_loss: 0.3305406868457794\n",
      "25310 val_loss: 0.33513301610946655, train_loss: 0.3298788368701935\n",
      "25320 val_loss: 0.3349442481994629, train_loss: 0.32966214418411255\n",
      "25330 val_loss: 0.33496907353401184, train_loss: 0.3291046619415283\n",
      "25340 val_loss: 0.3355342745780945, train_loss: 0.33019116520881653\n",
      "25350 val_loss: 0.3351660966873169, train_loss: 0.3295927047729492\n",
      "25360 val_loss: 0.336757093667984, train_loss: 0.33103063702583313\n",
      "25370 val_loss: 0.3358922004699707, train_loss: 0.3297067880630493\n",
      "25380 val_loss: 0.3345540463924408, train_loss: 0.3293651342391968\n",
      "25390 val_loss: 0.3349166810512543, train_loss: 0.32869669795036316\n",
      "25400 val_loss: 0.3356562554836273, train_loss: 0.3305293917655945\n",
      "25410 val_loss: 0.3339659571647644, train_loss: 0.3280479311943054\n",
      "25420 val_loss: 0.33301475644111633, train_loss: 0.32771480083465576\n",
      "25430 val_loss: 0.3341490626335144, train_loss: 0.3280297517776489\n",
      "25440 val_loss: 0.3347024917602539, train_loss: 0.32919183373451233\n",
      "25450 val_loss: 0.33200302720069885, train_loss: 0.32687005400657654\n",
      "25460 val_loss: 0.33273181319236755, train_loss: 0.32734057307243347\n",
      "25470 val_loss: 0.3368479013442993, train_loss: 0.3314608037471771\n",
      "25480 val_loss: 0.3345331847667694, train_loss: 0.3290354907512665\n",
      "25490 val_loss: 0.3331512212753296, train_loss: 0.3275211453437805\n",
      "25500 val_loss: 0.3321252167224884, train_loss: 0.32662472128868103\n",
      "25510 val_loss: 0.33211007714271545, train_loss: 0.32642874121665955\n",
      "25520 val_loss: 0.3334386944770813, train_loss: 0.3276011645793915\n",
      "25530 val_loss: 0.3330380320549011, train_loss: 0.3272872567176819\n",
      "25540 val_loss: 0.334697961807251, train_loss: 0.32812172174453735\n",
      "25550 val_loss: 0.3315453827381134, train_loss: 0.3261282444000244\n",
      "25560 val_loss: 0.33121031522750854, train_loss: 0.32701393961906433\n",
      "25570 val_loss: 0.32945191860198975, train_loss: 0.32606273889541626\n",
      "25580 val_loss: 0.3302268981933594, train_loss: 0.32539382576942444\n",
      "25590 val_loss: 0.3312360644340515, train_loss: 0.3257204592227936\n",
      "25600 val_loss: 0.33043813705444336, train_loss: 0.3258819282054901\n",
      "25610 val_loss: 0.33062952756881714, train_loss: 0.3257620334625244\n",
      "25620 val_loss: 0.33001023530960083, train_loss: 0.3251682221889496\n",
      "25630 val_loss: 0.3310769498348236, train_loss: 0.3255787193775177\n",
      "25640 val_loss: 0.33003365993499756, train_loss: 0.32547372579574585\n",
      "25650 val_loss: 0.331600546836853, train_loss: 0.3262806236743927\n",
      "25660 val_loss: 0.32858484983444214, train_loss: 0.3245299160480499\n",
      "25670 val_loss: 0.332896888256073, train_loss: 0.3289129436016083\n",
      "25680 val_loss: 0.3292524814605713, train_loss: 0.3253360092639923\n",
      "25690 val_loss: 0.32976818084716797, train_loss: 0.32475700974464417\n",
      "25700 val_loss: 0.32980701327323914, train_loss: 0.3249000310897827\n",
      "25710 val_loss: 0.3289809226989746, train_loss: 0.3242543935775757\n",
      "25720 val_loss: 0.33067938685417175, train_loss: 0.32546767592430115\n",
      "25730 val_loss: 0.3292893171310425, train_loss: 0.32426324486732483\n",
      "25740 val_loss: 0.32984477281570435, train_loss: 0.32449889183044434\n",
      "25750 val_loss: 0.3288136124610901, train_loss: 0.3242452144622803\n",
      "25760 val_loss: 0.3319777548313141, train_loss: 0.32571840286254883\n",
      "25770 val_loss: 0.3302624821662903, train_loss: 0.3249736428260803\n",
      "25780 val_loss: 0.33164456486701965, train_loss: 0.3253980278968811\n",
      "25790 val_loss: 0.3298184871673584, train_loss: 0.32520949840545654\n",
      "25800 val_loss: 0.3304957151412964, train_loss: 0.32477834820747375\n",
      "25810 val_loss: 0.33056074380874634, train_loss: 0.3249390721321106\n",
      "25820 val_loss: 0.3286736011505127, train_loss: 0.32327449321746826\n",
      "25830 val_loss: 0.32919779419898987, train_loss: 0.32354453206062317\n",
      "25840 val_loss: 0.3282332420349121, train_loss: 0.32294484972953796\n",
      "25850 val_loss: 0.3322012424468994, train_loss: 0.3268449306488037\n",
      "25860 val_loss: 0.33018285036087036, train_loss: 0.324061781167984\n",
      "25870 val_loss: 0.3293341398239136, train_loss: 0.32384124398231506\n",
      "25880 val_loss: 0.3291234076023102, train_loss: 0.3233931064605713\n",
      "25890 val_loss: 0.3283078968524933, train_loss: 0.32284414768218994\n",
      "25900 val_loss: 0.3294406235218048, train_loss: 0.3234066367149353\n",
      "25910 val_loss: 0.32585474848747253, train_loss: 0.32193195819854736\n",
      "25920 val_loss: 0.33031705021858215, train_loss: 0.32501110434532166\n",
      "25930 val_loss: 0.329813152551651, train_loss: 0.32548263669013977\n",
      "25940 val_loss: 0.3285510540008545, train_loss: 0.322714626789093\n",
      "25950 val_loss: 0.3282153010368347, train_loss: 0.32345569133758545\n",
      "25960 val_loss: 0.327746719121933, train_loss: 0.3225988447666168\n",
      "25970 val_loss: 0.33060240745544434, train_loss: 0.3242252469062805\n",
      "25980 val_loss: 0.33403316140174866, train_loss: 0.32814502716064453\n",
      "25990 val_loss: 0.3271180987358093, train_loss: 0.32154330611228943\n",
      "26000 val_loss: 0.3261392116546631, train_loss: 0.3211456835269928\n",
      "26010 val_loss: 0.32693177461624146, train_loss: 0.32164663076400757\n",
      "26020 val_loss: 0.3316860496997833, train_loss: 0.32660430669784546\n",
      "26030 val_loss: 0.32824766635894775, train_loss: 0.3221120834350586\n",
      "26040 val_loss: 0.3276509642601013, train_loss: 0.3220418393611908\n",
      "26050 val_loss: 0.3265675902366638, train_loss: 0.32211241126060486\n",
      "26060 val_loss: 0.3255431354045868, train_loss: 0.32064104080200195\n",
      "26070 val_loss: 0.3251025378704071, train_loss: 0.32035431265830994\n",
      "26080 val_loss: 0.32587260007858276, train_loss: 0.3206253945827484\n",
      "26090 val_loss: 0.3298121988773346, train_loss: 0.3249163329601288\n",
      "26100 val_loss: 0.32556116580963135, train_loss: 0.32049742341041565\n",
      "26110 val_loss: 0.3245033025741577, train_loss: 0.3200196325778961\n",
      "26120 val_loss: 0.326251357793808, train_loss: 0.32236412167549133\n",
      "26130 val_loss: 0.3230769634246826, train_loss: 0.32029440999031067\n",
      "26140 val_loss: 0.3247027099132538, train_loss: 0.31995391845703125\n",
      "26150 val_loss: 0.3230458199977875, train_loss: 0.31910401582717896\n",
      "26160 val_loss: 0.32336121797561646, train_loss: 0.31905847787857056\n",
      "26170 val_loss: 0.3238081932067871, train_loss: 0.3190586566925049\n",
      "26180 val_loss: 0.3257702887058258, train_loss: 0.31983035802841187\n",
      "26190 val_loss: 0.3242228329181671, train_loss: 0.31915146112442017\n",
      "26200 val_loss: 0.32357466220855713, train_loss: 0.31940603256225586\n",
      "26210 val_loss: 0.3233322501182556, train_loss: 0.3193611800670624\n",
      "26220 val_loss: 0.32346707582473755, train_loss: 0.3188939392566681\n",
      "26230 val_loss: 0.33234265446662903, train_loss: 0.3286619484424591\n",
      "26240 val_loss: 0.3230588436126709, train_loss: 0.31813710927963257\n",
      "26250 val_loss: 0.3239726424217224, train_loss: 0.3193223476409912\n",
      "26260 val_loss: 0.3217255175113678, train_loss: 0.317729651927948\n",
      "26270 val_loss: 0.3240683078765869, train_loss: 0.32083752751350403\n",
      "26280 val_loss: 0.3205544352531433, train_loss: 0.31686773896217346\n",
      "26290 val_loss: 0.32068756222724915, train_loss: 0.31720539927482605\n",
      "26300 val_loss: 0.32119885087013245, train_loss: 0.3183165192604065\n",
      "26310 val_loss: 0.32004019618034363, train_loss: 0.3165491819381714\n",
      "26320 val_loss: 0.32115185260772705, train_loss: 0.3173740804195404\n",
      "26330 val_loss: 0.32327690720558167, train_loss: 0.31976398825645447\n",
      "26340 val_loss: 0.3205792307853699, train_loss: 0.3166981041431427\n",
      "26350 val_loss: 0.32118934392929077, train_loss: 0.3178889751434326\n",
      "26360 val_loss: 0.3196159303188324, train_loss: 0.31600305438041687\n",
      "26370 val_loss: 0.3193153142929077, train_loss: 0.31618115305900574\n",
      "26380 val_loss: 0.3192655146121979, train_loss: 0.3159812390804291\n",
      "26390 val_loss: 0.3207758665084839, train_loss: 0.3173137903213501\n",
      "26400 val_loss: 0.3206954002380371, train_loss: 0.3177553713321686\n",
      "26410 val_loss: 0.3195423483848572, train_loss: 0.3159801661968231\n",
      "26420 val_loss: 0.3174538314342499, train_loss: 0.31475502252578735\n",
      "26430 val_loss: 0.32104411721229553, train_loss: 0.3164709210395813\n",
      "26440 val_loss: 0.3207554817199707, train_loss: 0.3158971965312958\n",
      "26450 val_loss: 0.32183167338371277, train_loss: 0.31698524951934814\n",
      "26460 val_loss: 0.3178441822528839, train_loss: 0.3145487308502197\n",
      "26470 val_loss: 0.3252636790275574, train_loss: 0.32049867510795593\n",
      "26480 val_loss: 0.3194570243358612, train_loss: 0.31509116291999817\n",
      "26490 val_loss: 0.317618727684021, train_loss: 0.31396257877349854\n",
      "26500 val_loss: 0.3170455992221832, train_loss: 0.31372717022895813\n",
      "26510 val_loss: 0.31793922185897827, train_loss: 0.31444108486175537\n",
      "26520 val_loss: 0.3169725835323334, train_loss: 0.31365326046943665\n",
      "26530 val_loss: 0.31726717948913574, train_loss: 0.3139004707336426\n",
      "26540 val_loss: 0.3165014088153839, train_loss: 0.3133222758769989\n",
      "26550 val_loss: 0.31714582443237305, train_loss: 0.31467947363853455\n",
      "26560 val_loss: 0.31615516543388367, train_loss: 0.31265947222709656\n",
      "26570 val_loss: 0.3169955909252167, train_loss: 0.3146743178367615\n",
      "26580 val_loss: 0.31486576795578003, train_loss: 0.3124324083328247\n",
      "26590 val_loss: 0.3179319500923157, train_loss: 0.31391608715057373\n",
      "26600 val_loss: 0.31570571660995483, train_loss: 0.31265079975128174\n",
      "26610 val_loss: 0.31588566303253174, train_loss: 0.3136446475982666\n",
      "26620 val_loss: 0.31547093391418457, train_loss: 0.31242918968200684\n",
      "26630 val_loss: 0.3177870512008667, train_loss: 0.313387930393219\n",
      "26640 val_loss: 0.31518131494522095, train_loss: 0.3119432330131531\n",
      "26650 val_loss: 0.31565120816230774, train_loss: 0.3117905557155609\n",
      "26660 val_loss: 0.3149903416633606, train_loss: 0.31121811270713806\n",
      "26670 val_loss: 0.3158750534057617, train_loss: 0.31245294213294983\n",
      "26680 val_loss: 0.31446585059165955, train_loss: 0.3108919560909271\n",
      "26690 val_loss: 0.31441187858581543, train_loss: 0.31072747707366943\n",
      "26700 val_loss: 0.31546247005462646, train_loss: 0.3112872540950775\n",
      "26710 val_loss: 0.31660422682762146, train_loss: 0.3118215799331665\n",
      "26720 val_loss: 0.31566086411476135, train_loss: 0.31120550632476807\n",
      "26730 val_loss: 0.3156043589115143, train_loss: 0.3115524351596832\n",
      "26740 val_loss: 0.31320762634277344, train_loss: 0.3100779056549072\n",
      "26750 val_loss: 0.31434088945388794, train_loss: 0.310409277677536\n",
      "26760 val_loss: 0.314607709646225, train_loss: 0.31067055463790894\n",
      "26770 val_loss: 0.31347647309303284, train_loss: 0.31078165769577026\n",
      "26780 val_loss: 0.31288275122642517, train_loss: 0.3104306161403656\n",
      "26790 val_loss: 0.3135087788105011, train_loss: 0.3094773590564728\n",
      "26800 val_loss: 0.31155455112457275, train_loss: 0.3083021640777588\n",
      "26810 val_loss: 0.31411147117614746, train_loss: 0.3105660676956177\n",
      "26820 val_loss: 0.310658723115921, train_loss: 0.3080603778362274\n",
      "26830 val_loss: 0.3118782043457031, train_loss: 0.3084816634654999\n",
      "26840 val_loss: 0.31195443868637085, train_loss: 0.30831804871559143\n",
      "26850 val_loss: 0.31165289878845215, train_loss: 0.3080037534236908\n",
      "26860 val_loss: 0.3104022145271301, train_loss: 0.30734339356422424\n",
      "26870 val_loss: 0.31046637892723083, train_loss: 0.30723851919174194\n",
      "26880 val_loss: 0.3120630979537964, train_loss: 0.3084467053413391\n",
      "26890 val_loss: 0.3111479878425598, train_loss: 0.30795034766197205\n",
      "26900 val_loss: 0.3106746971607208, train_loss: 0.3069310486316681\n",
      "26910 val_loss: 0.3114793002605438, train_loss: 0.30769863724708557\n",
      "26920 val_loss: 0.3102729022502899, train_loss: 0.307157427072525\n",
      "26930 val_loss: 0.31039726734161377, train_loss: 0.30646637082099915\n",
      "26940 val_loss: 0.31073808670043945, train_loss: 0.30643847584724426\n",
      "26950 val_loss: 0.30919349193573, train_loss: 0.3065515458583832\n",
      "26960 val_loss: 0.3084397315979004, train_loss: 0.3052927553653717\n",
      "26970 val_loss: 0.30826011300086975, train_loss: 0.3061944544315338\n",
      "26980 val_loss: 0.30773165822029114, train_loss: 0.3054494559764862\n",
      "26990 val_loss: 0.30786213278770447, train_loss: 0.3057633936405182\n",
      "27000 val_loss: 0.3076217770576477, train_loss: 0.3052908778190613\n",
      "27010 val_loss: 0.30658596754074097, train_loss: 0.3044160008430481\n",
      "27020 val_loss: 0.30947595834732056, train_loss: 0.3067883253097534\n",
      "27030 val_loss: 0.3071659207344055, train_loss: 0.30414170026779175\n",
      "27040 val_loss: 0.3070678412914276, train_loss: 0.3039943277835846\n",
      "27050 val_loss: 0.3083728551864624, train_loss: 0.3051491975784302\n",
      "27060 val_loss: 0.3082355856895447, train_loss: 0.3047180473804474\n",
      "27070 val_loss: 0.30647924542427063, train_loss: 0.3034123182296753\n",
      "27080 val_loss: 0.306587815284729, train_loss: 0.30459487438201904\n",
      "27090 val_loss: 0.30723896622657776, train_loss: 0.30324092507362366\n",
      "27100 val_loss: 0.30834460258483887, train_loss: 0.3041013777256012\n",
      "27110 val_loss: 0.3070647716522217, train_loss: 0.3032909333705902\n",
      "27120 val_loss: 0.30712205171585083, train_loss: 0.30336883664131165\n",
      "27130 val_loss: 0.3073263466358185, train_loss: 0.30307862162590027\n",
      "27140 val_loss: 0.3104799687862396, train_loss: 0.3068549931049347\n",
      "27150 val_loss: 0.31265997886657715, train_loss: 0.3077177405357361\n",
      "27160 val_loss: 0.3065605163574219, train_loss: 0.30243754386901855\n",
      "27170 val_loss: 0.3060823082923889, train_loss: 0.30233460664749146\n",
      "27180 val_loss: 0.30462321639060974, train_loss: 0.3014732003211975\n",
      "27190 val_loss: 0.30557674169540405, train_loss: 0.301960825920105\n",
      "27200 val_loss: 0.30509015917778015, train_loss: 0.30174052715301514\n",
      "27210 val_loss: 0.3041626214981079, train_loss: 0.3011683225631714\n",
      "27220 val_loss: 0.30506449937820435, train_loss: 0.30196964740753174\n",
      "27230 val_loss: 0.30529457330703735, train_loss: 0.30176955461502075\n",
      "27240 val_loss: 0.3066301941871643, train_loss: 0.30228477716445923\n",
      "27250 val_loss: 0.3100643754005432, train_loss: 0.3068908452987671\n",
      "27260 val_loss: 0.3063022494316101, train_loss: 0.3022419214248657\n",
      "27270 val_loss: 0.3039655089378357, train_loss: 0.3003332316875458\n",
      "27280 val_loss: 0.30308395624160767, train_loss: 0.2998378872871399\n",
      "27290 val_loss: 0.3027498722076416, train_loss: 0.29993000626564026\n",
      "27300 val_loss: 0.30571237206459045, train_loss: 0.3033115863800049\n",
      "27310 val_loss: 0.3026328980922699, train_loss: 0.2994041442871094\n",
      "27320 val_loss: 0.305825799703598, train_loss: 0.3016001582145691\n",
      "27330 val_loss: 0.30420276522636414, train_loss: 0.300022691488266\n",
      "27340 val_loss: 0.3058285415172577, train_loss: 0.30120718479156494\n",
      "27350 val_loss: 0.30548611283302307, train_loss: 0.30149585008621216\n",
      "27360 val_loss: 0.30239495635032654, train_loss: 0.2995833158493042\n",
      "27370 val_loss: 0.3027673661708832, train_loss: 0.29883480072021484\n",
      "27380 val_loss: 0.302033007144928, train_loss: 0.298431932926178\n",
      "27390 val_loss: 0.30194705724716187, train_loss: 0.29829704761505127\n",
      "27400 val_loss: 0.3018675446510315, train_loss: 0.2980723977088928\n",
      "27410 val_loss: 0.3037477433681488, train_loss: 0.29966166615486145\n",
      "27420 val_loss: 0.3033723533153534, train_loss: 0.2991677522659302\n",
      "27430 val_loss: 0.3021567463874817, train_loss: 0.2977082133293152\n",
      "27440 val_loss: 0.30227747559547424, train_loss: 0.29760053753852844\n",
      "27450 val_loss: 0.30123093724250793, train_loss: 0.29742181301116943\n",
      "27460 val_loss: 0.3030957579612732, train_loss: 0.29928719997406006\n",
      "27470 val_loss: 0.30187246203422546, train_loss: 0.2978162467479706\n",
      "27480 val_loss: 0.3002454936504364, train_loss: 0.29705360531806946\n",
      "27490 val_loss: 0.29982954263687134, train_loss: 0.29682400822639465\n",
      "27500 val_loss: 0.29957571625709534, train_loss: 0.2959538698196411\n",
      "27510 val_loss: 0.30071109533309937, train_loss: 0.29639503359794617\n",
      "27520 val_loss: 0.30119243264198303, train_loss: 0.29836559295654297\n",
      "27530 val_loss: 0.29947206377983093, train_loss: 0.2960425615310669\n",
      "27540 val_loss: 0.29965856671333313, train_loss: 0.2954520583152771\n",
      "27550 val_loss: 0.302071213722229, train_loss: 0.2971530556678772\n",
      "27560 val_loss: 0.2979641258716583, train_loss: 0.2948516309261322\n",
      "27570 val_loss: 0.29855668544769287, train_loss: 0.2951870262622833\n",
      "27580 val_loss: 0.30129578709602356, train_loss: 0.2972824275493622\n",
      "27590 val_loss: 0.29930952191352844, train_loss: 0.29505011439323425\n",
      "27600 val_loss: 0.29956361651420593, train_loss: 0.2953125834465027\n",
      "27610 val_loss: 0.29928329586982727, train_loss: 0.2951139509677887\n",
      "27620 val_loss: 0.29985371232032776, train_loss: 0.2958756387233734\n",
      "27630 val_loss: 0.30079326033592224, train_loss: 0.29706892371177673\n",
      "27640 val_loss: 0.2971062958240509, train_loss: 0.29360416531562805\n",
      "27650 val_loss: 0.2998848557472229, train_loss: 0.2955944538116455\n",
      "27660 val_loss: 0.2980146110057831, train_loss: 0.2937304675579071\n",
      "27670 val_loss: 0.2973553240299225, train_loss: 0.29354408383369446\n",
      "27680 val_loss: 0.29912251234054565, train_loss: 0.2950991094112396\n",
      "27690 val_loss: 0.29656243324279785, train_loss: 0.29272931814193726\n",
      "27700 val_loss: 0.2988901734352112, train_loss: 0.295718252658844\n",
      "27710 val_loss: 0.296438068151474, train_loss: 0.29237380623817444\n",
      "27720 val_loss: 0.29810619354248047, train_loss: 0.29365575313568115\n",
      "27730 val_loss: 0.2976759374141693, train_loss: 0.2927938997745514\n",
      "27740 val_loss: 0.2987222373485565, train_loss: 0.29370397329330444\n",
      "27750 val_loss: 0.29917019605636597, train_loss: 0.2944153845310211\n",
      "27760 val_loss: 0.2966875731945038, train_loss: 0.29264748096466064\n",
      "27770 val_loss: 0.29845812916755676, train_loss: 0.29366084933280945\n",
      "27780 val_loss: 0.2999396324157715, train_loss: 0.29520344734191895\n",
      "27790 val_loss: 0.29502788186073303, train_loss: 0.29119211435317993\n",
      "27800 val_loss: 0.2971474528312683, train_loss: 0.2921837866306305\n",
      "27810 val_loss: 0.2967878580093384, train_loss: 0.29156097769737244\n",
      "27820 val_loss: 0.2969406247138977, train_loss: 0.29213762283325195\n",
      "27830 val_loss: 0.29666489362716675, train_loss: 0.2921469807624817\n",
      "27840 val_loss: 0.2949998080730438, train_loss: 0.29061219096183777\n",
      "27850 val_loss: 0.29576095938682556, train_loss: 0.29070234298706055\n",
      "27860 val_loss: 0.29738226532936096, train_loss: 0.2932455241680145\n",
      "27870 val_loss: 0.2975737750530243, train_loss: 0.29255765676498413\n",
      "27880 val_loss: 0.29718610644340515, train_loss: 0.29224908351898193\n",
      "27890 val_loss: 0.2936660051345825, train_loss: 0.2894982099533081\n",
      "27900 val_loss: 0.29603543877601624, train_loss: 0.29126814007759094\n",
      "27910 val_loss: 0.29560747742652893, train_loss: 0.29074084758758545\n",
      "27920 val_loss: 0.2941494882106781, train_loss: 0.28985658288002014\n",
      "27930 val_loss: 0.29360687732696533, train_loss: 0.2890445590019226\n",
      "27940 val_loss: 0.2936348021030426, train_loss: 0.28903844952583313\n",
      "27950 val_loss: 0.2931865155696869, train_loss: 0.2886267304420471\n",
      "27960 val_loss: 0.2923474609851837, train_loss: 0.2885035276412964\n",
      "27970 val_loss: 0.2929118573665619, train_loss: 0.28874483704566956\n",
      "27980 val_loss: 0.29354220628738403, train_loss: 0.28910577297210693\n",
      "27990 val_loss: 0.29234516620635986, train_loss: 0.2881576418876648\n",
      "28000 val_loss: 0.29212209582328796, train_loss: 0.28738686442375183\n",
      "28010 val_loss: 0.2938671112060547, train_loss: 0.28870537877082825\n",
      "28020 val_loss: 0.29201388359069824, train_loss: 0.28724774718284607\n",
      "28030 val_loss: 0.2920910120010376, train_loss: 0.28790098428726196\n",
      "28040 val_loss: 0.29202306270599365, train_loss: 0.2870519459247589\n",
      "28050 val_loss: 0.294052392244339, train_loss: 0.28829216957092285\n",
      "28060 val_loss: 0.2943529188632965, train_loss: 0.28884613513946533\n",
      "28070 val_loss: 0.2919158935546875, train_loss: 0.28664544224739075\n",
      "28080 val_loss: 0.29147079586982727, train_loss: 0.2868720293045044\n",
      "28090 val_loss: 0.29056835174560547, train_loss: 0.28581225872039795\n",
      "28100 val_loss: 0.29292094707489014, train_loss: 0.28734681010246277\n",
      "28110 val_loss: 0.2923544645309448, train_loss: 0.2867952585220337\n",
      "28120 val_loss: 0.2948229908943176, train_loss: 0.28881946206092834\n",
      "28130 val_loss: 0.2908358871936798, train_loss: 0.28577759861946106\n",
      "28140 val_loss: 0.29011982679367065, train_loss: 0.2863611578941345\n",
      "28150 val_loss: 0.2909340262413025, train_loss: 0.28645434975624084\n",
      "28160 val_loss: 0.2906014323234558, train_loss: 0.2853655219078064\n",
      "28170 val_loss: 0.2933426797389984, train_loss: 0.2882133722305298\n",
      "28180 val_loss: 0.2906680107116699, train_loss: 0.2851845622062683\n",
      "28190 val_loss: 0.2905149757862091, train_loss: 0.2849477529525757\n",
      "28200 val_loss: 0.2896003723144531, train_loss: 0.28432828187942505\n",
      "28210 val_loss: 0.2902343273162842, train_loss: 0.2853333055973053\n",
      "28220 val_loss: 0.2886824607849121, train_loss: 0.2844468951225281\n",
      "28230 val_loss: 0.2912135124206543, train_loss: 0.2855302095413208\n",
      "28240 val_loss: 0.28881967067718506, train_loss: 0.28394615650177\n",
      "28250 val_loss: 0.2902596592903137, train_loss: 0.28476446866989136\n",
      "28260 val_loss: 0.2904731333255768, train_loss: 0.2845422029495239\n",
      "28270 val_loss: 0.28755807876586914, train_loss: 0.28378164768218994\n",
      "28280 val_loss: 0.2882283627986908, train_loss: 0.28303489089012146\n",
      "28290 val_loss: 0.2877568304538727, train_loss: 0.2834230363368988\n",
      "28300 val_loss: 0.2888762652873993, train_loss: 0.2845332622528076\n",
      "28310 val_loss: 0.28903499245643616, train_loss: 0.2835645377635956\n",
      "28320 val_loss: 0.2877057194709778, train_loss: 0.2834758162498474\n",
      "28330 val_loss: 0.28795376420021057, train_loss: 0.28261491656303406\n",
      "28340 val_loss: 0.2888294458389282, train_loss: 0.2830667495727539\n",
      "28350 val_loss: 0.28927749395370483, train_loss: 0.2835444509983063\n",
      "28360 val_loss: 0.2948756217956543, train_loss: 0.2887066602706909\n",
      "28370 val_loss: 0.2955639362335205, train_loss: 0.28945472836494446\n",
      "28380 val_loss: 0.286458283662796, train_loss: 0.2819451093673706\n",
      "28390 val_loss: 0.28802335262298584, train_loss: 0.28244107961654663\n",
      "28400 val_loss: 0.28633350133895874, train_loss: 0.28133997321128845\n",
      "28410 val_loss: 0.2879352271556854, train_loss: 0.2823665738105774\n",
      "28420 val_loss: 0.28564321994781494, train_loss: 0.2809112071990967\n",
      "28430 val_loss: 0.28619158267974854, train_loss: 0.2811620831489563\n",
      "28440 val_loss: 0.2869965732097626, train_loss: 0.2814396917819977\n",
      "28450 val_loss: 0.28593647480010986, train_loss: 0.28072482347488403\n",
      "28460 val_loss: 0.2876749336719513, train_loss: 0.2821502089500427\n",
      "28470 val_loss: 0.28622567653656006, train_loss: 0.28144150972366333\n",
      "28480 val_loss: 0.28504323959350586, train_loss: 0.28004348278045654\n",
      "28490 val_loss: 0.28637322783470154, train_loss: 0.28051167726516724\n",
      "28500 val_loss: 0.2848362326622009, train_loss: 0.2807479202747345\n",
      "28510 val_loss: 0.2848568260669708, train_loss: 0.27991536259651184\n",
      "28520 val_loss: 0.2866024672985077, train_loss: 0.28125500679016113\n",
      "28530 val_loss: 0.2847840487957001, train_loss: 0.27994146943092346\n",
      "28540 val_loss: 0.2863445580005646, train_loss: 0.28053736686706543\n",
      "28550 val_loss: 0.28723326325416565, train_loss: 0.2810690701007843\n",
      "28560 val_loss: 0.28683096170425415, train_loss: 0.2813236713409424\n",
      "28570 val_loss: 0.2848525047302246, train_loss: 0.28000321984291077\n",
      "28580 val_loss: 0.28338101506233215, train_loss: 0.28021934628486633\n",
      "28590 val_loss: 0.28357067704200745, train_loss: 0.27902400493621826\n",
      "28600 val_loss: 0.28472599387168884, train_loss: 0.2790753245353699\n",
      "28610 val_loss: 0.2846924662590027, train_loss: 0.2788965404033661\n",
      "28620 val_loss: 0.2864924371242523, train_loss: 0.280825674533844\n",
      "28630 val_loss: 0.2826560437679291, train_loss: 0.2778526544570923\n",
      "28640 val_loss: 0.28461384773254395, train_loss: 0.2792249917984009\n",
      "28650 val_loss: 0.28208667039871216, train_loss: 0.27796313166618347\n",
      "28660 val_loss: 0.2816031277179718, train_loss: 0.277391642332077\n",
      "28670 val_loss: 0.2842039465904236, train_loss: 0.2795209288597107\n",
      "28680 val_loss: 0.2826830744743347, train_loss: 0.27878537774086\n",
      "28690 val_loss: 0.282145619392395, train_loss: 0.27781835198402405\n",
      "28700 val_loss: 0.2834182679653168, train_loss: 0.27897313237190247\n",
      "28710 val_loss: 0.2826848030090332, train_loss: 0.2774631381034851\n",
      "28720 val_loss: 0.2879537045955658, train_loss: 0.28414008021354675\n",
      "28730 val_loss: 0.2839606702327728, train_loss: 0.27823275327682495\n",
      "28740 val_loss: 0.2831677496433258, train_loss: 0.2781983017921448\n",
      "28750 val_loss: 0.28237590193748474, train_loss: 0.27685314416885376\n",
      "28760 val_loss: 0.281937837600708, train_loss: 0.2769868075847626\n",
      "28770 val_loss: 0.28235846757888794, train_loss: 0.27718615531921387\n",
      "28780 val_loss: 0.2857562303543091, train_loss: 0.27982261776924133\n",
      "28790 val_loss: 0.285610169172287, train_loss: 0.279252290725708\n",
      "28800 val_loss: 0.2811450660228729, train_loss: 0.27655425667762756\n",
      "28810 val_loss: 0.28116947412490845, train_loss: 0.27579590678215027\n",
      "28820 val_loss: 0.2799951434135437, train_loss: 0.27525848150253296\n",
      "28830 val_loss: 0.2803264856338501, train_loss: 0.27537694573402405\n",
      "28840 val_loss: 0.283482164144516, train_loss: 0.27867281436920166\n",
      "28850 val_loss: 0.2829112708568573, train_loss: 0.27739453315734863\n",
      "28860 val_loss: 0.2790588140487671, train_loss: 0.27499884366989136\n",
      "28870 val_loss: 0.2800520956516266, train_loss: 0.27506372332572937\n",
      "28880 val_loss: 0.2801429331302643, train_loss: 0.2756568491458893\n",
      "28890 val_loss: 0.2792516350746155, train_loss: 0.274978369474411\n",
      "28900 val_loss: 0.28035587072372437, train_loss: 0.27508848905563354\n",
      "28910 val_loss: 0.2811184227466583, train_loss: 0.27529391646385193\n",
      "28920 val_loss: 0.27928975224494934, train_loss: 0.2739166021347046\n",
      "28930 val_loss: 0.27952906489372253, train_loss: 0.2760698199272156\n",
      "28940 val_loss: 0.2814101278781891, train_loss: 0.27562013268470764\n",
      "28950 val_loss: 0.2799442708492279, train_loss: 0.2746967673301697\n",
      "28960 val_loss: 0.28049665689468384, train_loss: 0.2760874330997467\n",
      "28970 val_loss: 0.27838268876075745, train_loss: 0.27309849858283997\n",
      "28980 val_loss: 0.2827664017677307, train_loss: 0.2766973376274109\n",
      "28990 val_loss: 0.2785946726799011, train_loss: 0.2728528678417206\n",
      "29000 val_loss: 0.27892807126045227, train_loss: 0.2733601927757263\n",
      "29010 val_loss: 0.2814674377441406, train_loss: 0.2758543789386749\n",
      "29020 val_loss: 0.2832702100276947, train_loss: 0.2766167223453522\n",
      "29030 val_loss: 0.28252944350242615, train_loss: 0.2767128646373749\n",
      "29040 val_loss: 0.2765448987483978, train_loss: 0.2716491222381592\n",
      "29050 val_loss: 0.2776440680027008, train_loss: 0.2721588611602783\n",
      "29060 val_loss: 0.27539536356925964, train_loss: 0.2712564468383789\n",
      "29070 val_loss: 0.27676287293434143, train_loss: 0.2716106176376343\n",
      "29080 val_loss: 0.2770718038082123, train_loss: 0.2714160084724426\n",
      "29090 val_loss: 0.2784821093082428, train_loss: 0.27288272976875305\n",
      "29100 val_loss: 0.2772224545478821, train_loss: 0.27120447158813477\n",
      "29110 val_loss: 0.28052055835723877, train_loss: 0.2747741937637329\n",
      "29120 val_loss: 0.2748561501502991, train_loss: 0.27033013105392456\n",
      "29130 val_loss: 0.27401408553123474, train_loss: 0.2697778046131134\n",
      "29140 val_loss: 0.2751983106136322, train_loss: 0.26997146010398865\n",
      "29150 val_loss: 0.2808687388896942, train_loss: 0.27750924229621887\n",
      "29160 val_loss: 0.27616339921951294, train_loss: 0.27268484234809875\n",
      "29170 val_loss: 0.2754943370819092, train_loss: 0.2709043622016907\n",
      "29180 val_loss: 0.27644482254981995, train_loss: 0.2708972096443176\n",
      "29190 val_loss: 0.2730860412120819, train_loss: 0.26886194944381714\n",
      "29200 val_loss: 0.27691158652305603, train_loss: 0.27131181955337524\n",
      "29210 val_loss: 0.2775818407535553, train_loss: 0.2713596820831299\n",
      "29220 val_loss: 0.27906617522239685, train_loss: 0.27230632305145264\n",
      "29230 val_loss: 0.2771129310131073, train_loss: 0.2705421447753906\n",
      "29240 val_loss: 0.27497777342796326, train_loss: 0.26937228441238403\n",
      "29250 val_loss: 0.2725459337234497, train_loss: 0.26850947737693787\n",
      "29260 val_loss: 0.27542611956596375, train_loss: 0.2696410119533539\n",
      "29270 val_loss: 0.2732259929180145, train_loss: 0.26815009117126465\n",
      "29280 val_loss: 0.2720647156238556, train_loss: 0.26761484146118164\n",
      "29290 val_loss: 0.27317389845848083, train_loss: 0.2690698206424713\n",
      "29300 val_loss: 0.2780612111091614, train_loss: 0.27227160334587097\n",
      "29310 val_loss: 0.2773939371109009, train_loss: 0.2712421417236328\n",
      "29320 val_loss: 0.27594736218452454, train_loss: 0.2688176929950714\n",
      "29330 val_loss: 0.27303579449653625, train_loss: 0.2675037980079651\n",
      "29340 val_loss: 0.27231064438819885, train_loss: 0.2672484517097473\n",
      "29350 val_loss: 0.2716934382915497, train_loss: 0.26715344190597534\n",
      "29360 val_loss: 0.2710328996181488, train_loss: 0.266988068819046\n",
      "29370 val_loss: 0.2718770205974579, train_loss: 0.26668745279312134\n",
      "29380 val_loss: 0.2758539021015167, train_loss: 0.27144554257392883\n",
      "29390 val_loss: 0.2734864354133606, train_loss: 0.26767781376838684\n",
      "29400 val_loss: 0.2696577310562134, train_loss: 0.2656954228878021\n",
      "29410 val_loss: 0.27063560485839844, train_loss: 0.26618635654449463\n",
      "29420 val_loss: 0.2700341045856476, train_loss: 0.26518622040748596\n",
      "29430 val_loss: 0.27287936210632324, train_loss: 0.26779624819755554\n",
      "29440 val_loss: 0.27165547013282776, train_loss: 0.26547950506210327\n",
      "29450 val_loss: 0.27109798789024353, train_loss: 0.2651607394218445\n",
      "29460 val_loss: 0.27169978618621826, train_loss: 0.26626425981521606\n",
      "29470 val_loss: 0.27099865674972534, train_loss: 0.2655729353427887\n",
      "29480 val_loss: 0.27274248003959656, train_loss: 0.26762017607688904\n",
      "29490 val_loss: 0.26947057247161865, train_loss: 0.2654459476470947\n",
      "29500 val_loss: 0.2706005573272705, train_loss: 0.2652781009674072\n",
      "29510 val_loss: 0.27136489748954773, train_loss: 0.26544442772865295\n",
      "29520 val_loss: 0.2702022194862366, train_loss: 0.2653837502002716\n",
      "29530 val_loss: 0.2703591287136078, train_loss: 0.26516082882881165\n",
      "29540 val_loss: 0.27523183822631836, train_loss: 0.26950234174728394\n",
      "29550 val_loss: 0.27014899253845215, train_loss: 0.26528793573379517\n",
      "29560 val_loss: 0.26923051476478577, train_loss: 0.2637844681739807\n",
      "29570 val_loss: 0.2695522606372833, train_loss: 0.26349571347236633\n",
      "29580 val_loss: 0.26976799964904785, train_loss: 0.26395803689956665\n",
      "29590 val_loss: 0.2693151533603668, train_loss: 0.2634727656841278\n",
      "29600 val_loss: 0.26891782879829407, train_loss: 0.2629983127117157\n",
      "29610 val_loss: 0.26635947823524475, train_loss: 0.26176896691322327\n",
      "29620 val_loss: 0.26980704069137573, train_loss: 0.26459017395973206\n",
      "29630 val_loss: 0.27218925952911377, train_loss: 0.26893529295921326\n",
      "29640 val_loss: 0.267238587141037, train_loss: 0.26243457198143005\n",
      "29650 val_loss: 0.2664746046066284, train_loss: 0.2620512843132019\n",
      "29660 val_loss: 0.2675012946128845, train_loss: 0.2623618245124817\n",
      "29670 val_loss: 0.26639777421951294, train_loss: 0.2623438537120819\n",
      "29680 val_loss: 0.26623478531837463, train_loss: 0.2617284953594208\n",
      "29690 val_loss: 0.2675212323665619, train_loss: 0.26194819808006287\n",
      "29700 val_loss: 0.2649170458316803, train_loss: 0.26034098863601685\n",
      "29710 val_loss: 0.26562952995300293, train_loss: 0.2601791322231293\n",
      "29720 val_loss: 0.264658123254776, train_loss: 0.25987154245376587\n",
      "29730 val_loss: 0.2657086253166199, train_loss: 0.2616250813007355\n",
      "29740 val_loss: 0.2657044231891632, train_loss: 0.26056456565856934\n",
      "29750 val_loss: 0.26621872186660767, train_loss: 0.2623834013938904\n",
      "29760 val_loss: 0.26318079233169556, train_loss: 0.25948962569236755\n",
      "29770 val_loss: 0.2637218236923218, train_loss: 0.2592494785785675\n",
      "29780 val_loss: 0.2632138431072235, train_loss: 0.25865650177001953\n",
      "29790 val_loss: 0.26628348231315613, train_loss: 0.260979026556015\n",
      "29800 val_loss: 0.26464951038360596, train_loss: 0.25920388102531433\n",
      "29810 val_loss: 0.2638649344444275, train_loss: 0.2587920129299164\n",
      "29820 val_loss: 0.2648862600326538, train_loss: 0.2596912980079651\n",
      "29830 val_loss: 0.2679802179336548, train_loss: 0.2628238797187805\n",
      "29840 val_loss: 0.26188576221466064, train_loss: 0.2579037845134735\n",
      "29850 val_loss: 0.2624398469924927, train_loss: 0.2579631209373474\n",
      "29860 val_loss: 0.26213204860687256, train_loss: 0.25741446018218994\n",
      "29870 val_loss: 0.26267099380493164, train_loss: 0.2575375735759735\n",
      "29880 val_loss: 0.26219725608825684, train_loss: 0.2579086124897003\n",
      "29890 val_loss: 0.26238638162612915, train_loss: 0.2574769854545593\n",
      "29900 val_loss: 0.2656583786010742, train_loss: 0.25925979018211365\n",
      "29910 val_loss: 0.2617662847042084, train_loss: 0.25647005438804626\n",
      "29920 val_loss: 0.2611464858055115, train_loss: 0.25618016719818115\n",
      "29930 val_loss: 0.2652004361152649, train_loss: 0.2587909400463104\n",
      "29940 val_loss: 0.263683021068573, train_loss: 0.2595665156841278\n",
      "29950 val_loss: 0.26135480403900146, train_loss: 0.2560865879058838\n",
      "29960 val_loss: 0.2640814781188965, train_loss: 0.258236289024353\n",
      "29970 val_loss: 0.2614230513572693, train_loss: 0.25598201155662537\n",
      "29980 val_loss: 0.26249510049819946, train_loss: 0.2561744153499603\n",
      "29990 val_loss: 0.26212796568870544, train_loss: 0.25670385360717773\n",
      "30000 val_loss: 0.26016807556152344, train_loss: 0.25566068291664124\n",
      "30010 val_loss: 0.2600642442703247, train_loss: 0.2558588683605194\n",
      "30020 val_loss: 0.2621447741985321, train_loss: 0.2563828229904175\n",
      "30030 val_loss: 0.2609859108924866, train_loss: 0.2560817003250122\n",
      "30040 val_loss: 0.25999313592910767, train_loss: 0.25532078742980957\n",
      "30050 val_loss: 0.2603473663330078, train_loss: 0.25527223944664\n",
      "30060 val_loss: 0.2585662305355072, train_loss: 0.2537308633327484\n",
      "30070 val_loss: 0.2583788335323334, train_loss: 0.25463351607322693\n",
      "30080 val_loss: 0.25756752490997314, train_loss: 0.2540019750595093\n",
      "30090 val_loss: 0.258436381816864, train_loss: 0.253836989402771\n",
      "30100 val_loss: 0.25974753499031067, train_loss: 0.25442489981651306\n",
      "30110 val_loss: 0.2598777711391449, train_loss: 0.2540249228477478\n",
      "30120 val_loss: 0.2585846185684204, train_loss: 0.2533254325389862\n",
      "30130 val_loss: 0.2581772208213806, train_loss: 0.2528122663497925\n",
      "30140 val_loss: 0.2583199739456177, train_loss: 0.25286439061164856\n",
      "30150 val_loss: 0.2594202160835266, train_loss: 0.2536097466945648\n",
      "30160 val_loss: 0.25655028223991394, train_loss: 0.2519499659538269\n",
      "30170 val_loss: 0.25761547684669495, train_loss: 0.2531884014606476\n",
      "30180 val_loss: 0.25586792826652527, train_loss: 0.25240981578826904\n",
      "30190 val_loss: 0.25583258271217346, train_loss: 0.25192612409591675\n",
      "30200 val_loss: 0.2565261721611023, train_loss: 0.2536877989768982\n",
      "30210 val_loss: 0.25742214918136597, train_loss: 0.2524239420890808\n",
      "30220 val_loss: 0.256865918636322, train_loss: 0.25206223130226135\n",
      "30230 val_loss: 0.26262739300727844, train_loss: 0.2590988874435425\n",
      "30240 val_loss: 0.2553842067718506, train_loss: 0.2513050436973572\n",
      "30250 val_loss: 0.25803130865097046, train_loss: 0.2526421844959259\n",
      "30260 val_loss: 0.25609520077705383, train_loss: 0.25200703740119934\n",
      "30270 val_loss: 0.256673127412796, train_loss: 0.25159722566604614\n",
      "30280 val_loss: 0.2533319890499115, train_loss: 0.2494146227836609\n",
      "30290 val_loss: 0.25323203206062317, train_loss: 0.24951311945915222\n",
      "30300 val_loss: 0.25284790992736816, train_loss: 0.2490158975124359\n",
      "30310 val_loss: 0.2543790340423584, train_loss: 0.2509276270866394\n",
      "30320 val_loss: 0.2528977394104004, train_loss: 0.24897527694702148\n",
      "30330 val_loss: 0.25737541913986206, train_loss: 0.2534812390804291\n",
      "30340 val_loss: 0.2547851502895355, train_loss: 0.25028061866760254\n",
      "30350 val_loss: 0.25151848793029785, train_loss: 0.249007910490036\n",
      "30360 val_loss: 0.25208917260169983, train_loss: 0.24825428426265717\n",
      "30370 val_loss: 0.25663426518440247, train_loss: 0.252826452255249\n",
      "30380 val_loss: 0.2542032301425934, train_loss: 0.2504754066467285\n",
      "30390 val_loss: 0.25598233938217163, train_loss: 0.25216227769851685\n",
      "30400 val_loss: 0.2561989426612854, train_loss: 0.25006866455078125\n",
      "30410 val_loss: 0.25661763548851013, train_loss: 0.25041618943214417\n",
      "30420 val_loss: 0.25575709342956543, train_loss: 0.25122708082199097\n",
      "30430 val_loss: 0.2530621886253357, train_loss: 0.24848374724388123\n",
      "30440 val_loss: 0.2536998689174652, train_loss: 0.24808335304260254\n",
      "30450 val_loss: 0.2533787786960602, train_loss: 0.24859191477298737\n",
      "30460 val_loss: 0.25339892506599426, train_loss: 0.24868692457675934\n",
      "30470 val_loss: 0.2502667307853699, train_loss: 0.24661138653755188\n",
      "30480 val_loss: 0.2523048222064972, train_loss: 0.248562291264534\n",
      "30490 val_loss: 0.2508101463317871, train_loss: 0.24668721854686737\n",
      "30500 val_loss: 0.24934343993663788, train_loss: 0.24545370042324066\n",
      "30510 val_loss: 0.25169017910957336, train_loss: 0.24663937091827393\n",
      "30520 val_loss: 0.25051912665367126, train_loss: 0.24587573111057281\n",
      "30530 val_loss: 0.2562764585018158, train_loss: 0.25019779801368713\n",
      "30540 val_loss: 0.25172320008277893, train_loss: 0.24621565639972687\n",
      "30550 val_loss: 0.2524574100971222, train_loss: 0.24659842252731323\n",
      "30560 val_loss: 0.25033771991729736, train_loss: 0.245725616812706\n",
      "30570 val_loss: 0.2505832612514496, train_loss: 0.24533593654632568\n",
      "30580 val_loss: 0.2523023188114166, train_loss: 0.2465643286705017\n",
      "30590 val_loss: 0.2510012686252594, train_loss: 0.24594639241695404\n",
      "30600 val_loss: 0.24893103539943695, train_loss: 0.2441922128200531\n",
      "30610 val_loss: 0.2506692111492157, train_loss: 0.24528923630714417\n",
      "30620 val_loss: 0.24884262681007385, train_loss: 0.24492354691028595\n",
      "30630 val_loss: 0.24963870644569397, train_loss: 0.2447962462902069\n",
      "30640 val_loss: 0.24705399572849274, train_loss: 0.2427312731742859\n",
      "30650 val_loss: 0.2478698492050171, train_loss: 0.2430354356765747\n",
      "30660 val_loss: 0.2464185357093811, train_loss: 0.2424188107252121\n",
      "30670 val_loss: 0.2506279945373535, train_loss: 0.24523356556892395\n",
      "30680 val_loss: 0.24811826646327972, train_loss: 0.24263878166675568\n",
      "30690 val_loss: 0.24681983888149261, train_loss: 0.2420547902584076\n",
      "30700 val_loss: 0.247874915599823, train_loss: 0.2437414526939392\n",
      "30710 val_loss: 0.24724511802196503, train_loss: 0.24194352328777313\n",
      "30720 val_loss: 0.24901320040225983, train_loss: 0.24501754343509674\n",
      "30730 val_loss: 0.2471189647912979, train_loss: 0.24184496700763702\n",
      "30740 val_loss: 0.246643528342247, train_loss: 0.2418978065252304\n",
      "30750 val_loss: 0.2453990876674652, train_loss: 0.24104338884353638\n",
      "30760 val_loss: 0.2480975091457367, train_loss: 0.2426161915063858\n",
      "30770 val_loss: 0.24997030198574066, train_loss: 0.244571253657341\n",
      "30780 val_loss: 0.25017955899238586, train_loss: 0.24443477392196655\n",
      "30790 val_loss: 0.24397160112857819, train_loss: 0.2399168759584427\n",
      "30800 val_loss: 0.24614134430885315, train_loss: 0.24157437682151794\n",
      "30810 val_loss: 0.24413961172103882, train_loss: 0.24031049013137817\n",
      "30820 val_loss: 0.24272193014621735, train_loss: 0.23863668739795685\n",
      "30830 val_loss: 0.24506506323814392, train_loss: 0.24037860333919525\n",
      "30840 val_loss: 0.24390733242034912, train_loss: 0.23907345533370972\n",
      "30850 val_loss: 0.24682866036891937, train_loss: 0.2409992665052414\n",
      "30860 val_loss: 0.24430429935455322, train_loss: 0.23974986374378204\n",
      "30870 val_loss: 0.2427162230014801, train_loss: 0.23825055360794067\n",
      "30880 val_loss: 0.24225449562072754, train_loss: 0.23852068185806274\n",
      "30890 val_loss: 0.2443774789571762, train_loss: 0.2389374077320099\n",
      "30900 val_loss: 0.24300818145275116, train_loss: 0.23748862743377686\n",
      "30910 val_loss: 0.24372141063213348, train_loss: 0.23822163045406342\n",
      "30920 val_loss: 0.24159830808639526, train_loss: 0.23688429594039917\n",
      "30930 val_loss: 0.24357129633426666, train_loss: 0.2386089265346527\n",
      "30940 val_loss: 0.2443361133337021, train_loss: 0.23946541547775269\n",
      "30950 val_loss: 0.24136453866958618, train_loss: 0.23757418990135193\n",
      "30960 val_loss: 0.23909629881381989, train_loss: 0.23715417087078094\n",
      "30970 val_loss: 0.24121376872062683, train_loss: 0.236506387591362\n",
      "30980 val_loss: 0.23956166207790375, train_loss: 0.2353866845369339\n",
      "30990 val_loss: 0.23950761556625366, train_loss: 0.23502440750598907\n",
      "31000 val_loss: 0.2402307391166687, train_loss: 0.23651976883411407\n",
      "31010 val_loss: 0.2411641776561737, train_loss: 0.23531214892864227\n",
      "31020 val_loss: 0.23853066563606262, train_loss: 0.23423545062541962\n",
      "31030 val_loss: 0.2393694519996643, train_loss: 0.23427800834178925\n",
      "31040 val_loss: 0.24061572551727295, train_loss: 0.23492789268493652\n",
      "31050 val_loss: 0.23941726982593536, train_loss: 0.23471888899803162\n",
      "31060 val_loss: 0.24110113084316254, train_loss: 0.2355610728263855\n",
      "31070 val_loss: 0.2388126701116562, train_loss: 0.23491987586021423\n",
      "31080 val_loss: 0.23745816946029663, train_loss: 0.23342065513134003\n",
      "31090 val_loss: 0.2386379837989807, train_loss: 0.234208881855011\n",
      "31100 val_loss: 0.2369910329580307, train_loss: 0.23306229710578918\n",
      "31110 val_loss: 0.2378845065832138, train_loss: 0.23414233326911926\n",
      "31120 val_loss: 0.24126672744750977, train_loss: 0.2352958768606186\n",
      "31130 val_loss: 0.2369447648525238, train_loss: 0.23396722972393036\n",
      "31140 val_loss: 0.24340836703777313, train_loss: 0.23925670981407166\n",
      "31150 val_loss: 0.23802192509174347, train_loss: 0.23396581411361694\n",
      "31160 val_loss: 0.23629777133464813, train_loss: 0.23205119371414185\n",
      "31170 val_loss: 0.2353915572166443, train_loss: 0.23128917813301086\n",
      "31180 val_loss: 0.23608335852622986, train_loss: 0.23202984035015106\n",
      "31190 val_loss: 0.2387617528438568, train_loss: 0.23428916931152344\n",
      "31200 val_loss: 0.23817749321460724, train_loss: 0.23281899094581604\n",
      "31210 val_loss: 0.23486384749412537, train_loss: 0.23033729195594788\n",
      "31220 val_loss: 0.23535573482513428, train_loss: 0.2305101901292801\n",
      "31230 val_loss: 0.2338624745607376, train_loss: 0.2303665429353714\n",
      "31240 val_loss: 0.2336556613445282, train_loss: 0.23065680265426636\n",
      "31250 val_loss: 0.23260945081710815, train_loss: 0.229402557015419\n",
      "31260 val_loss: 0.2333347350358963, train_loss: 0.2294725626707077\n",
      "31270 val_loss: 0.23840481042861938, train_loss: 0.23284956812858582\n",
      "31280 val_loss: 0.23803849518299103, train_loss: 0.23362509906291962\n",
      "31290 val_loss: 0.2331317812204361, train_loss: 0.22887873649597168\n",
      "31300 val_loss: 0.2328956127166748, train_loss: 0.2290736883878708\n",
      "31310 val_loss: 0.23223096132278442, train_loss: 0.22795900702476501\n",
      "31320 val_loss: 0.2312963455915451, train_loss: 0.22784653306007385\n",
      "31330 val_loss: 0.2305586338043213, train_loss: 0.22766734659671783\n",
      "31340 val_loss: 0.23493851721286774, train_loss: 0.22926703095436096\n",
      "31350 val_loss: 0.2333621382713318, train_loss: 0.2278953343629837\n",
      "31360 val_loss: 0.23046965897083282, train_loss: 0.22672709822654724\n",
      "31370 val_loss: 0.23221087455749512, train_loss: 0.22888532280921936\n",
      "31380 val_loss: 0.23276108503341675, train_loss: 0.22901393473148346\n",
      "31390 val_loss: 0.22920966148376465, train_loss: 0.22696076333522797\n",
      "31400 val_loss: 0.23025201261043549, train_loss: 0.22632887959480286\n",
      "31410 val_loss: 0.23489058017730713, train_loss: 0.22996960580348969\n",
      "31420 val_loss: 0.23234675824642181, train_loss: 0.2274031788110733\n",
      "31430 val_loss: 0.23110021650791168, train_loss: 0.22630830109119415\n",
      "31440 val_loss: 0.23000803589820862, train_loss: 0.22528383135795593\n",
      "31450 val_loss: 0.2339196503162384, train_loss: 0.2302415370941162\n",
      "31460 val_loss: 0.23144446313381195, train_loss: 0.22601474821567535\n",
      "31470 val_loss: 0.22901123762130737, train_loss: 0.22676406800746918\n",
      "31480 val_loss: 0.22834137082099915, train_loss: 0.22442153096199036\n",
      "31490 val_loss: 0.22768531739711761, train_loss: 0.22415825724601746\n",
      "31500 val_loss: 0.2300776094198227, train_loss: 0.22604499757289886\n",
      "31510 val_loss: 0.22987626492977142, train_loss: 0.22484542429447174\n",
      "31520 val_loss: 0.22912998497486115, train_loss: 0.22401063144207\n",
      "31530 val_loss: 0.22994470596313477, train_loss: 0.2247205227613449\n",
      "31540 val_loss: 0.22975465655326843, train_loss: 0.22419647872447968\n",
      "31550 val_loss: 0.2270418107509613, train_loss: 0.22278837859630585\n",
      "31560 val_loss: 0.2268095165491104, train_loss: 0.22333216667175293\n",
      "31570 val_loss: 0.228608638048172, train_loss: 0.22602878510951996\n",
      "31580 val_loss: 0.22712907195091248, train_loss: 0.22348973155021667\n",
      "31590 val_loss: 0.22501996159553528, train_loss: 0.22178401052951813\n",
      "31600 val_loss: 0.22493714094161987, train_loss: 0.22109606862068176\n",
      "31610 val_loss: 0.2237490862607956, train_loss: 0.2208348959684372\n",
      "31620 val_loss: 0.22374235093593597, train_loss: 0.22098538279533386\n",
      "31630 val_loss: 0.22690071165561676, train_loss: 0.22180022299289703\n",
      "31640 val_loss: 0.22751744091510773, train_loss: 0.2227095067501068\n",
      "31650 val_loss: 0.22585353255271912, train_loss: 0.2217199206352234\n",
      "31660 val_loss: 0.2250601053237915, train_loss: 0.22050529718399048\n",
      "31670 val_loss: 0.22662511467933655, train_loss: 0.22368723154067993\n",
      "31680 val_loss: 0.22570385038852692, train_loss: 0.22090105712413788\n",
      "31690 val_loss: 0.22198441624641418, train_loss: 0.21922539174556732\n",
      "31700 val_loss: 0.22448667883872986, train_loss: 0.22101280093193054\n",
      "31710 val_loss: 0.2294854074716568, train_loss: 0.22459504008293152\n",
      "31720 val_loss: 0.22363747656345367, train_loss: 0.21871978044509888\n",
      "31730 val_loss: 0.222273051738739, train_loss: 0.21815133094787598\n",
      "31740 val_loss: 0.22233068943023682, train_loss: 0.21792161464691162\n",
      "31750 val_loss: 0.22935239970684052, train_loss: 0.22545965015888214\n",
      "31760 val_loss: 0.22348345816135406, train_loss: 0.21881920099258423\n",
      "31770 val_loss: 0.22494706511497498, train_loss: 0.22033628821372986\n",
      "31780 val_loss: 0.22291871905326843, train_loss: 0.2177605777978897\n",
      "31790 val_loss: 0.22398258745670319, train_loss: 0.22019971907138824\n",
      "31800 val_loss: 0.22196869552135468, train_loss: 0.2175827920436859\n",
      "31810 val_loss: 0.22594356536865234, train_loss: 0.21933801472187042\n",
      "31820 val_loss: 0.2264787256717682, train_loss: 0.22037890553474426\n",
      "31830 val_loss: 0.22522173821926117, train_loss: 0.21842317283153534\n",
      "31840 val_loss: 0.22716738283634186, train_loss: 0.2210039645433426\n",
      "31850 val_loss: 0.22103677690029144, train_loss: 0.21667790412902832\n",
      "31860 val_loss: 0.22039014101028442, train_loss: 0.21520179510116577\n",
      "31870 val_loss: 0.22042445838451385, train_loss: 0.21567058563232422\n",
      "31880 val_loss: 0.2252533733844757, train_loss: 0.21858416497707367\n",
      "31890 val_loss: 0.22618524730205536, train_loss: 0.22308489680290222\n",
      "31900 val_loss: 0.21846695244312286, train_loss: 0.2141939103603363\n",
      "31910 val_loss: 0.2200903594493866, train_loss: 0.21463698148727417\n",
      "31920 val_loss: 0.21944193542003632, train_loss: 0.2143154889345169\n",
      "31930 val_loss: 0.2196589708328247, train_loss: 0.21412935853004456\n",
      "31940 val_loss: 0.21605460345745087, train_loss: 0.2130020558834076\n",
      "31950 val_loss: 0.22494937479496002, train_loss: 0.22015082836151123\n",
      "31960 val_loss: 0.21952039003372192, train_loss: 0.2136262059211731\n",
      "31970 val_loss: 0.21888121962547302, train_loss: 0.21394823491573334\n",
      "31980 val_loss: 0.2182360589504242, train_loss: 0.21326258778572083\n",
      "31990 val_loss: 0.21520064771175385, train_loss: 0.2118847519159317\n",
      "32000 val_loss: 0.21957479417324066, train_loss: 0.21383461356163025\n",
      "32010 val_loss: 0.21377329528331757, train_loss: 0.21128959953784943\n",
      "32020 val_loss: 0.21693332493305206, train_loss: 0.21413910388946533\n",
      "32030 val_loss: 0.21425862610340118, train_loss: 0.21184991300106049\n",
      "32040 val_loss: 0.21362893283367157, train_loss: 0.21097895503044128\n",
      "32050 val_loss: 0.21690969169139862, train_loss: 0.21324588358402252\n",
      "32060 val_loss: 0.21713876724243164, train_loss: 0.21469758450984955\n",
      "32070 val_loss: 0.21385550498962402, train_loss: 0.20995144546031952\n",
      "32080 val_loss: 0.21822908520698547, train_loss: 0.2131831794977188\n",
      "32090 val_loss: 0.2197675108909607, train_loss: 0.2148202359676361\n",
      "32100 val_loss: 0.2121032327413559, train_loss: 0.20875896513462067\n",
      "32110 val_loss: 0.2203657627105713, train_loss: 0.21600815653800964\n",
      "32120 val_loss: 0.22805926203727722, train_loss: 0.22449038922786713\n",
      "32130 val_loss: 0.2126157432794571, train_loss: 0.209648996591568\n",
      "32140 val_loss: 0.21118533611297607, train_loss: 0.2096727192401886\n",
      "32150 val_loss: 0.21624650061130524, train_loss: 0.21222944557666779\n",
      "32160 val_loss: 0.21289414167404175, train_loss: 0.20876695215702057\n",
      "32170 val_loss: 0.21299096941947937, train_loss: 0.20911931991577148\n",
      "32180 val_loss: 0.21442586183547974, train_loss: 0.21055936813354492\n",
      "32190 val_loss: 0.21237383782863617, train_loss: 0.2087562084197998\n",
      "32200 val_loss: 0.21397019922733307, train_loss: 0.20821644365787506\n",
      "32210 val_loss: 0.21386367082595825, train_loss: 0.20954297482967377\n",
      "32220 val_loss: 0.2148103415966034, train_loss: 0.20934656262397766\n",
      "32230 val_loss: 0.21526427567005157, train_loss: 0.2100588083267212\n",
      "32240 val_loss: 0.21567167341709137, train_loss: 0.21157480776309967\n",
      "32250 val_loss: 0.21162904798984528, train_loss: 0.20721504092216492\n",
      "32260 val_loss: 0.21480560302734375, train_loss: 0.20775577425956726\n",
      "32270 val_loss: 0.21494272351264954, train_loss: 0.20832350850105286\n",
      "32280 val_loss: 0.21277248859405518, train_loss: 0.20643626153469086\n",
      "32290 val_loss: 0.2115117758512497, train_loss: 0.20589813590049744\n",
      "32300 val_loss: 0.2088959813117981, train_loss: 0.20463907718658447\n",
      "32310 val_loss: 0.21031953394412994, train_loss: 0.20620839297771454\n",
      "32320 val_loss: 0.21142220497131348, train_loss: 0.2074044644832611\n",
      "32330 val_loss: 0.2095855176448822, train_loss: 0.2063252329826355\n",
      "32340 val_loss: 0.21048395335674286, train_loss: 0.20576845109462738\n",
      "32350 val_loss: 0.20785649120807648, train_loss: 0.2050047665834427\n",
      "32360 val_loss: 0.2103596180677414, train_loss: 0.2070116251707077\n",
      "32370 val_loss: 0.2088395208120346, train_loss: 0.2043309360742569\n",
      "32380 val_loss: 0.20921282470226288, train_loss: 0.2045884132385254\n",
      "32390 val_loss: 0.20840388536453247, train_loss: 0.20448742806911469\n",
      "32400 val_loss: 0.2061263471841812, train_loss: 0.20373623073101044\n",
      "32410 val_loss: 0.2087278664112091, train_loss: 0.20599092543125153\n",
      "32420 val_loss: 0.20794528722763062, train_loss: 0.20353759825229645\n",
      "32430 val_loss: 0.20653586089611053, train_loss: 0.20270687341690063\n",
      "32440 val_loss: 0.21120142936706543, train_loss: 0.2075502872467041\n",
      "32450 val_loss: 0.20923198759555817, train_loss: 0.2068457007408142\n",
      "32460 val_loss: 0.20629771053791046, train_loss: 0.2027807980775833\n",
      "32470 val_loss: 0.20662938058376312, train_loss: 0.20259277522563934\n",
      "32480 val_loss: 0.20760729908943176, train_loss: 0.2025471329689026\n",
      "32490 val_loss: 0.2069336175918579, train_loss: 0.2023596316576004\n",
      "32500 val_loss: 0.20666314661502838, train_loss: 0.20218564569950104\n",
      "32510 val_loss: 0.2076408416032791, train_loss: 0.20302113890647888\n",
      "32520 val_loss: 0.20491695404052734, train_loss: 0.2011640965938568\n",
      "32530 val_loss: 0.20788045227527618, train_loss: 0.2039133608341217\n",
      "32540 val_loss: 0.20474949479103088, train_loss: 0.20020444691181183\n",
      "32550 val_loss: 0.2124992460012436, train_loss: 0.2082844227552414\n",
      "32560 val_loss: 0.20508086681365967, train_loss: 0.20000869035720825\n",
      "32570 val_loss: 0.20634283125400543, train_loss: 0.20146088302135468\n",
      "32580 val_loss: 0.2102661281824112, train_loss: 0.2044907510280609\n",
      "32590 val_loss: 0.20417195558547974, train_loss: 0.20013655722141266\n",
      "32600 val_loss: 0.2064192295074463, train_loss: 0.20039120316505432\n",
      "32610 val_loss: 0.20328401029109955, train_loss: 0.198319211602211\n",
      "32620 val_loss: 0.2035699039697647, train_loss: 0.19848640263080597\n",
      "32630 val_loss: 0.20765386521816254, train_loss: 0.2028549760580063\n",
      "32640 val_loss: 0.2045976221561432, train_loss: 0.20043659210205078\n",
      "32650 val_loss: 0.2053682506084442, train_loss: 0.2012747824192047\n",
      "32660 val_loss: 0.2037842571735382, train_loss: 0.19915293157100677\n",
      "32670 val_loss: 0.2027573436498642, train_loss: 0.19847629964351654\n",
      "32680 val_loss: 0.20180507004261017, train_loss: 0.19703929126262665\n",
      "32690 val_loss: 0.20043711364269257, train_loss: 0.19689258933067322\n",
      "32700 val_loss: 0.20328108966350555, train_loss: 0.19749878346920013\n",
      "32710 val_loss: 0.20392531156539917, train_loss: 0.19759869575500488\n",
      "32720 val_loss: 0.2020098716020584, train_loss: 0.19789232313632965\n",
      "32730 val_loss: 0.20309649407863617, train_loss: 0.19831760227680206\n",
      "32740 val_loss: 0.2075423151254654, train_loss: 0.20203329622745514\n",
      "32750 val_loss: 0.20242814719676971, train_loss: 0.1971380114555359\n",
      "32760 val_loss: 0.20133361220359802, train_loss: 0.19736847281455994\n",
      "32770 val_loss: 0.19845162332057953, train_loss: 0.19541479647159576\n",
      "32780 val_loss: 0.201168030500412, train_loss: 0.19819395244121552\n",
      "32790 val_loss: 0.2018997222185135, train_loss: 0.19601474702358246\n",
      "32800 val_loss: 0.2011198252439499, train_loss: 0.19747094810009003\n",
      "32810 val_loss: 0.1990043967962265, train_loss: 0.1941959410905838\n",
      "32820 val_loss: 0.20010368525981903, train_loss: 0.1964215636253357\n",
      "32830 val_loss: 0.20064175128936768, train_loss: 0.19599699974060059\n",
      "32840 val_loss: 0.19895678758621216, train_loss: 0.19399438798427582\n",
      "32850 val_loss: 0.20181629061698914, train_loss: 0.19712573289871216\n",
      "32860 val_loss: 0.1981632262468338, train_loss: 0.193906769156456\n",
      "32870 val_loss: 0.20267510414123535, train_loss: 0.19976764917373657\n",
      "32880 val_loss: 0.20042471587657928, train_loss: 0.19581635296344757\n",
      "32890 val_loss: 0.19570514559745789, train_loss: 0.1927308738231659\n",
      "32900 val_loss: 0.19845451414585114, train_loss: 0.19427594542503357\n",
      "32910 val_loss: 0.19883237779140472, train_loss: 0.19408515095710754\n",
      "32920 val_loss: 0.19657838344573975, train_loss: 0.19246256351470947\n",
      "32930 val_loss: 0.1951264590024948, train_loss: 0.1922501027584076\n",
      "32940 val_loss: 0.1969880759716034, train_loss: 0.19331619143486023\n",
      "32950 val_loss: 0.20292659103870392, train_loss: 0.19903899729251862\n",
      "32960 val_loss: 0.19792427122592926, train_loss: 0.19448187947273254\n",
      "32970 val_loss: 0.2160571664571762, train_loss: 0.21443034708499908\n",
      "32980 val_loss: 0.19348831474781036, train_loss: 0.19130264222621918\n",
      "32990 val_loss: 0.20540836453437805, train_loss: 0.20153562724590302\n",
      "33000 val_loss: 0.19374987483024597, train_loss: 0.19091036915779114\n",
      "33010 val_loss: 0.1953529268503189, train_loss: 0.1913829892873764\n",
      "33020 val_loss: 0.19796957075595856, train_loss: 0.19231724739074707\n",
      "33030 val_loss: 0.19389046728610992, train_loss: 0.18977846205234528\n",
      "33040 val_loss: 0.19641271233558655, train_loss: 0.19270652532577515\n",
      "33050 val_loss: 0.19297678768634796, train_loss: 0.18901008367538452\n",
      "33060 val_loss: 0.19429610669612885, train_loss: 0.1894960105419159\n",
      "33070 val_loss: 0.19644339382648468, train_loss: 0.1908702403306961\n",
      "33080 val_loss: 0.2072974443435669, train_loss: 0.203035369515419\n",
      "33090 val_loss: 0.19607961177825928, train_loss: 0.19002260267734528\n",
      "33100 val_loss: 0.1972770243883133, train_loss: 0.19293370842933655\n",
      "33110 val_loss: 0.19622810184955597, train_loss: 0.19016873836517334\n",
      "33120 val_loss: 0.19625943899154663, train_loss: 0.19010475277900696\n",
      "33130 val_loss: 0.19253310561180115, train_loss: 0.1894286721944809\n",
      "33140 val_loss: 0.19603382050991058, train_loss: 0.19230863451957703\n",
      "33150 val_loss: 0.19023120403289795, train_loss: 0.18708647787570953\n",
      "33160 val_loss: 0.19742073118686676, train_loss: 0.19152307510375977\n",
      "33170 val_loss: 0.19567516446113586, train_loss: 0.19117365777492523\n",
      "33180 val_loss: 0.18995699286460876, train_loss: 0.18615899980068207\n",
      "33190 val_loss: 0.19052396714687347, train_loss: 0.18650978803634644\n",
      "33200 val_loss: 0.189914733171463, train_loss: 0.18609681725502014\n",
      "33210 val_loss: 0.19040006399154663, train_loss: 0.18777447938919067\n",
      "33220 val_loss: 0.1894957423210144, train_loss: 0.18581385910511017\n",
      "33230 val_loss: 0.19377394020557404, train_loss: 0.19215507805347443\n",
      "33240 val_loss: 0.1882447898387909, train_loss: 0.1869218945503235\n",
      "33250 val_loss: 0.19247131049633026, train_loss: 0.18834026157855988\n",
      "33260 val_loss: 0.19225315749645233, train_loss: 0.18817180395126343\n",
      "33270 val_loss: 0.19526082277297974, train_loss: 0.19267825782299042\n",
      "33280 val_loss: 0.18598726391792297, train_loss: 0.18359880149364471\n",
      "33290 val_loss: 0.19042399525642395, train_loss: 0.18740211427211761\n",
      "33300 val_loss: 0.18836651742458344, train_loss: 0.18433986604213715\n",
      "33310 val_loss: 0.19114947319030762, train_loss: 0.18554694950580597\n",
      "33320 val_loss: 0.191240131855011, train_loss: 0.185758575797081\n",
      "33330 val_loss: 0.18838897347450256, train_loss: 0.18337520956993103\n",
      "33340 val_loss: 0.1878218650817871, train_loss: 0.18320205807685852\n",
      "33350 val_loss: 0.18782295286655426, train_loss: 0.1837187111377716\n",
      "33360 val_loss: 0.18420442938804626, train_loss: 0.18053823709487915\n",
      "33370 val_loss: 0.18794874846935272, train_loss: 0.18312031030654907\n",
      "33380 val_loss: 0.18961608409881592, train_loss: 0.18525224924087524\n",
      "33390 val_loss: 0.18271096050739288, train_loss: 0.18040241301059723\n",
      "33400 val_loss: 0.18331056833267212, train_loss: 0.1799270212650299\n",
      "33410 val_loss: 0.18461473286151886, train_loss: 0.18183858692646027\n",
      "33420 val_loss: 0.18310494720935822, train_loss: 0.18129661679267883\n",
      "33430 val_loss: 0.18717537820339203, train_loss: 0.18253041803836823\n",
      "33440 val_loss: 0.18199557065963745, train_loss: 0.1802833080291748\n",
      "33450 val_loss: 0.18335746228694916, train_loss: 0.1809147745370865\n",
      "33460 val_loss: 0.18264605104923248, train_loss: 0.18052895367145538\n",
      "33470 val_loss: 0.18538610637187958, train_loss: 0.18119579553604126\n",
      "33480 val_loss: 0.18289044499397278, train_loss: 0.18030166625976562\n",
      "33490 val_loss: 0.18411126732826233, train_loss: 0.18023048341274261\n",
      "33500 val_loss: 0.18604539334774017, train_loss: 0.1837794929742813\n",
      "33510 val_loss: 0.19089877605438232, train_loss: 0.1876973658800125\n",
      "33520 val_loss: 0.18464811146259308, train_loss: 0.18186256289482117\n",
      "33530 val_loss: 0.18414323031902313, train_loss: 0.18013951182365417\n",
      "33540 val_loss: 0.17954403162002563, train_loss: 0.17706507444381714\n",
      "33550 val_loss: 0.18183782696723938, train_loss: 0.1782219111919403\n",
      "33560 val_loss: 0.1802789717912674, train_loss: 0.17813877761363983\n",
      "33570 val_loss: 0.181254044175148, train_loss: 0.1783713549375534\n",
      "33580 val_loss: 0.1796882301568985, train_loss: 0.1779935657978058\n",
      "33590 val_loss: 0.17853768169879913, train_loss: 0.1762477457523346\n",
      "33600 val_loss: 0.18343444168567657, train_loss: 0.17990894615650177\n",
      "33610 val_loss: 0.17749904096126556, train_loss: 0.17560599744319916\n",
      "33620 val_loss: 0.17811979353427887, train_loss: 0.17618393898010254\n",
      "33630 val_loss: 0.1801372617483139, train_loss: 0.1772475391626358\n",
      "33640 val_loss: 0.18541410565376282, train_loss: 0.18176482617855072\n",
      "33650 val_loss: 0.1826140284538269, train_loss: 0.17799131572246552\n",
      "33660 val_loss: 0.18166093528270721, train_loss: 0.17849187552928925\n",
      "33670 val_loss: 0.18334023654460907, train_loss: 0.17871178686618805\n",
      "33680 val_loss: 0.17982839047908783, train_loss: 0.17564725875854492\n",
      "33690 val_loss: 0.17794343829154968, train_loss: 0.1744656264781952\n",
      "33700 val_loss: 0.1781570017337799, train_loss: 0.17568139731884003\n",
      "33710 val_loss: 0.1792207509279251, train_loss: 0.17688634991645813\n",
      "33720 val_loss: 0.1839168667793274, train_loss: 0.18198679387569427\n",
      "33730 val_loss: 0.18150679767131805, train_loss: 0.17726010084152222\n",
      "33740 val_loss: 0.1754682958126068, train_loss: 0.17284978926181793\n",
      "33750 val_loss: 0.18016697466373444, train_loss: 0.17751778662204742\n",
      "33760 val_loss: 0.17744332551956177, train_loss: 0.17428605258464813\n",
      "33770 val_loss: 0.17533622682094574, train_loss: 0.17241854965686798\n",
      "33780 val_loss: 0.17876651883125305, train_loss: 0.17713592946529388\n",
      "33790 val_loss: 0.17853796482086182, train_loss: 0.17577292025089264\n",
      "33800 val_loss: 0.17477047443389893, train_loss: 0.1729927808046341\n",
      "33810 val_loss: 0.17424513399600983, train_loss: 0.1719728708267212\n",
      "33820 val_loss: 0.1735115498304367, train_loss: 0.17074008285999298\n",
      "33830 val_loss: 0.17938366532325745, train_loss: 0.17599299550056458\n",
      "33840 val_loss: 0.1722116470336914, train_loss: 0.1703236997127533\n",
      "33850 val_loss: 0.1738947331905365, train_loss: 0.17190657556056976\n",
      "33860 val_loss: 0.17125378549098969, train_loss: 0.16985481977462769\n",
      "33870 val_loss: 0.17089098691940308, train_loss: 0.169764444231987\n",
      "33880 val_loss: 0.17596571147441864, train_loss: 0.17440825700759888\n",
      "33890 val_loss: 0.17393456399440765, train_loss: 0.1715269535779953\n",
      "33900 val_loss: 0.17198675870895386, train_loss: 0.17155136168003082\n",
      "33910 val_loss: 0.17458276450634003, train_loss: 0.17157454788684845\n",
      "33920 val_loss: 0.17301493883132935, train_loss: 0.17048479616641998\n",
      "33930 val_loss: 0.17494723200798035, train_loss: 0.17143481969833374\n",
      "33940 val_loss: 0.17237424850463867, train_loss: 0.16963835060596466\n",
      "33950 val_loss: 0.16932687163352966, train_loss: 0.16817906498908997\n",
      "33960 val_loss: 0.16934627294540405, train_loss: 0.16774170100688934\n",
      "33970 val_loss: 0.17833983898162842, train_loss: 0.17409227788448334\n",
      "33980 val_loss: 0.17209520936012268, train_loss: 0.16925813257694244\n",
      "33990 val_loss: 0.17221465706825256, train_loss: 0.16919822990894318\n",
      "34000 val_loss: 0.1676861196756363, train_loss: 0.16669437289237976\n",
      "34010 val_loss: 0.17156347632408142, train_loss: 0.16978339850902557\n",
      "34020 val_loss: 0.17135487496852875, train_loss: 0.16832709312438965\n",
      "34030 val_loss: 0.1693769246339798, train_loss: 0.1671299934387207\n",
      "34040 val_loss: 0.16884079575538635, train_loss: 0.16640087962150574\n",
      "34050 val_loss: 0.16765554249286652, train_loss: 0.16570132970809937\n",
      "34060 val_loss: 0.17155566811561584, train_loss: 0.16930347681045532\n",
      "34070 val_loss: 0.1703156977891922, train_loss: 0.16732969880104065\n",
      "34080 val_loss: 0.17113423347473145, train_loss: 0.16769157350063324\n",
      "34090 val_loss: 0.17267531156539917, train_loss: 0.17150411009788513\n",
      "34100 val_loss: 0.17538456618785858, train_loss: 0.17285974323749542\n",
      "34110 val_loss: 0.16912753880023956, train_loss: 0.16758766770362854\n",
      "34120 val_loss: 0.16528546810150146, train_loss: 0.16455623507499695\n",
      "34130 val_loss: 0.16725602746009827, train_loss: 0.16720522940158844\n",
      "34140 val_loss: 0.16602855920791626, train_loss: 0.16511212289333344\n",
      "34150 val_loss: 0.1724177449941635, train_loss: 0.170675590634346\n",
      "34160 val_loss: 0.16715408861637115, train_loss: 0.16522052884101868\n",
      "34170 val_loss: 0.16602100431919098, train_loss: 0.16419294476509094\n",
      "34180 val_loss: 0.16931647062301636, train_loss: 0.1696772426366806\n",
      "34190 val_loss: 0.1654289811849594, train_loss: 0.16458263993263245\n",
      "34200 val_loss: 0.16520708799362183, train_loss: 0.16637785732746124\n",
      "34210 val_loss: 0.16713069379329681, train_loss: 0.1662503331899643\n",
      "34220 val_loss: 0.1746957004070282, train_loss: 0.17290018498897552\n",
      "34230 val_loss: 0.1695922613143921, train_loss: 0.1676110178232193\n",
      "34240 val_loss: 0.16598725318908691, train_loss: 0.16426149010658264\n",
      "34250 val_loss: 0.16679570078849792, train_loss: 0.16676391661167145\n",
      "34260 val_loss: 0.16274435818195343, train_loss: 0.16376830637454987\n",
      "34270 val_loss: 0.1621127426624298, train_loss: 0.16215039789676666\n",
      "34280 val_loss: 0.16352051496505737, train_loss: 0.16377706825733185\n",
      "34290 val_loss: 0.16218294203281403, train_loss: 0.16212275624275208\n",
      "34300 val_loss: 0.1662570834159851, train_loss: 0.16565820574760437\n",
      "34310 val_loss: 0.1626499891281128, train_loss: 0.16141574084758759\n",
      "34320 val_loss: 0.16831061244010925, train_loss: 0.16782677173614502\n",
      "34330 val_loss: 0.16206224262714386, train_loss: 0.16180895268917084\n",
      "34340 val_loss: 0.1628246009349823, train_loss: 0.16163186728954315\n",
      "34350 val_loss: 0.1613083928823471, train_loss: 0.16080522537231445\n",
      "34360 val_loss: 0.16287684440612793, train_loss: 0.16153499484062195\n",
      "34370 val_loss: 0.16267184913158417, train_loss: 0.16109482944011688\n",
      "34380 val_loss: 0.16331304609775543, train_loss: 0.16160324215888977\n",
      "34390 val_loss: 0.16524434089660645, train_loss: 0.16474275290966034\n",
      "34400 val_loss: 0.15921804308891296, train_loss: 0.15959720313549042\n",
      "34410 val_loss: 0.16530488431453705, train_loss: 0.16422335803508759\n",
      "34420 val_loss: 0.15900297462940216, train_loss: 0.15878094732761383\n",
      "34430 val_loss: 0.16503259539604187, train_loss: 0.16370952129364014\n",
      "34440 val_loss: 0.16378220915794373, train_loss: 0.1619553565979004\n",
      "34450 val_loss: 0.1606515347957611, train_loss: 0.1601611226797104\n",
      "34460 val_loss: 0.15735724568367004, train_loss: 0.1588621437549591\n",
      "34470 val_loss: 0.1618899554014206, train_loss: 0.16059701144695282\n",
      "34480 val_loss: 0.1574164479970932, train_loss: 0.15761631727218628\n",
      "34490 val_loss: 0.1630033701658249, train_loss: 0.16212357580661774\n",
      "34500 val_loss: 0.15685677528381348, train_loss: 0.15728507936000824\n",
      "34510 val_loss: 0.15581335127353668, train_loss: 0.15664774179458618\n",
      "34520 val_loss: 0.15732374787330627, train_loss: 0.15698519349098206\n",
      "34530 val_loss: 0.1646222174167633, train_loss: 0.16352608799934387\n",
      "34540 val_loss: 0.15618538856506348, train_loss: 0.15610970556735992\n",
      "34550 val_loss: 0.15827617049217224, train_loss: 0.15764066576957703\n",
      "34560 val_loss: 0.15857429802417755, train_loss: 0.15752723813056946\n",
      "34570 val_loss: 0.1563408076763153, train_loss: 0.1559867411851883\n",
      "34580 val_loss: 0.15668566524982452, train_loss: 0.15660613775253296\n",
      "34590 val_loss: 0.15816697478294373, train_loss: 0.15673828125\n",
      "34600 val_loss: 0.1543940156698227, train_loss: 0.1547919064760208\n",
      "34610 val_loss: 0.1599644124507904, train_loss: 0.16020284593105316\n",
      "34620 val_loss: 0.1553007960319519, train_loss: 0.15488193929195404\n",
      "34630 val_loss: 0.15330202877521515, train_loss: 0.1542874276638031\n",
      "34640 val_loss: 0.15700726211071014, train_loss: 0.15776953101158142\n",
      "34650 val_loss: 0.15534399449825287, train_loss: 0.15522107481956482\n",
      "34660 val_loss: 0.15447837114334106, train_loss: 0.1541953682899475\n",
      "34670 val_loss: 0.1577794998884201, train_loss: 0.1576397866010666\n",
      "34680 val_loss: 0.15508249402046204, train_loss: 0.1544494330883026\n",
      "34690 val_loss: 0.1554381549358368, train_loss: 0.15488728880882263\n",
      "34700 val_loss: 0.15782330930233002, train_loss: 0.15771985054016113\n",
      "34710 val_loss: 0.1537838578224182, train_loss: 0.15389765799045563\n",
      "34720 val_loss: 0.15887434780597687, train_loss: 0.1582258641719818\n",
      "34730 val_loss: 0.15707243978977203, train_loss: 0.15570729970932007\n",
      "34740 val_loss: 0.15360277891159058, train_loss: 0.15305845439434052\n",
      "34750 val_loss: 0.15129415690898895, train_loss: 0.15305308997631073\n",
      "34760 val_loss: 0.15714314579963684, train_loss: 0.15547756850719452\n",
      "34770 val_loss: 0.152411088347435, train_loss: 0.15228873491287231\n",
      "34780 val_loss: 0.15440289676189423, train_loss: 0.1530003845691681\n",
      "34790 val_loss: 0.15817596018314362, train_loss: 0.1570628434419632\n",
      "34800 val_loss: 0.15030014514923096, train_loss: 0.15028558671474457\n",
      "34810 val_loss: 0.1535448580980301, train_loss: 0.1550527811050415\n",
      "34820 val_loss: 0.1526874452829361, train_loss: 0.15137596428394318\n",
      "34830 val_loss: 0.15016700327396393, train_loss: 0.15116633474826813\n",
      "34840 val_loss: 0.1502772718667984, train_loss: 0.15148061513900757\n",
      "34850 val_loss: 0.14940302073955536, train_loss: 0.14965297281742096\n",
      "34860 val_loss: 0.1493515521287918, train_loss: 0.15001645684242249\n",
      "34870 val_loss: 0.15164528787136078, train_loss: 0.1507820338010788\n",
      "34880 val_loss: 0.15370069444179535, train_loss: 0.1544560194015503\n",
      "34890 val_loss: 0.14903905987739563, train_loss: 0.14979133009910583\n",
      "34900 val_loss: 0.15045835077762604, train_loss: 0.15029582381248474\n",
      "34910 val_loss: 0.15089279413223267, train_loss: 0.15048368275165558\n",
      "34920 val_loss: 0.1514316350221634, train_loss: 0.1505298912525177\n",
      "34930 val_loss: 0.1498832255601883, train_loss: 0.14965985715389252\n",
      "34940 val_loss: 0.1520291566848755, train_loss: 0.15121665596961975\n",
      "34950 val_loss: 0.1506926715373993, train_loss: 0.15103283524513245\n",
      "34960 val_loss: 0.16827836632728577, train_loss: 0.16532474756240845\n",
      "34970 val_loss: 0.15031759440898895, train_loss: 0.149881049990654\n",
      "34980 val_loss: 0.1487317532300949, train_loss: 0.14890247583389282\n",
      "34990 val_loss: 0.1472296416759491, train_loss: 0.1484469622373581\n",
      "35000 val_loss: 0.14910472929477692, train_loss: 0.14932359755039215\n",
      "35010 val_loss: 0.15080885589122772, train_loss: 0.15121592581272125\n",
      "35020 val_loss: 0.15017759799957275, train_loss: 0.15205563604831696\n",
      "35030 val_loss: 0.14687350392341614, train_loss: 0.1472969502210617\n",
      "35040 val_loss: 0.14710067212581635, train_loss: 0.14774809777736664\n",
      "35050 val_loss: 0.1513950675725937, train_loss: 0.1509736180305481\n",
      "35060 val_loss: 0.15046744048595428, train_loss: 0.14976057410240173\n",
      "35070 val_loss: 0.1467791050672531, train_loss: 0.14734433591365814\n",
      "35080 val_loss: 0.1501489281654358, train_loss: 0.14878062903881073\n",
      "35090 val_loss: 0.1467965841293335, train_loss: 0.14739537239074707\n",
      "35100 val_loss: 0.14984765648841858, train_loss: 0.15266834199428558\n",
      "35110 val_loss: 0.15184076130390167, train_loss: 0.15051321685314178\n",
      "35120 val_loss: 0.14847944676876068, train_loss: 0.14764504134655\n",
      "35130 val_loss: 0.151993066072464, train_loss: 0.15041518211364746\n",
      "35140 val_loss: 0.15068528056144714, train_loss: 0.1495611071586609\n",
      "35150 val_loss: 0.14968149363994598, train_loss: 0.14915744960308075\n",
      "35160 val_loss: 0.14640691876411438, train_loss: 0.14653633534908295\n",
      "35170 val_loss: 0.15409761667251587, train_loss: 0.15144461393356323\n",
      "35180 val_loss: 0.14628757536411285, train_loss: 0.14651158452033997\n",
      "35190 val_loss: 0.14531321823596954, train_loss: 0.14651764929294586\n",
      "35200 val_loss: 0.15011410415172577, train_loss: 0.14815135300159454\n",
      "35210 val_loss: 0.15538541972637177, train_loss: 0.1534852534532547\n",
      "35220 val_loss: 0.1452433466911316, train_loss: 0.14550334215164185\n",
      "35230 val_loss: 0.1490395963191986, train_loss: 0.14792250096797943\n",
      "35240 val_loss: 0.15004011988639832, train_loss: 0.14766839146614075\n",
      "35250 val_loss: 0.14519697427749634, train_loss: 0.1460048407316208\n",
      "35260 val_loss: 0.1477486938238144, train_loss: 0.1485700160264969\n",
      "35270 val_loss: 0.15975485742092133, train_loss: 0.15647730231285095\n",
      "35280 val_loss: 0.14638331532478333, train_loss: 0.14615941047668457\n",
      "35290 val_loss: 0.16563987731933594, train_loss: 0.16271059215068817\n",
      "35300 val_loss: 0.15206019580364227, train_loss: 0.14982204139232635\n",
      "35310 val_loss: 0.1510237157344818, train_loss: 0.14921709895133972\n",
      "35320 val_loss: 0.14580638706684113, train_loss: 0.14469978213310242\n",
      "35330 val_loss: 0.1515396386384964, train_loss: 0.15058796107769012\n",
      "35340 val_loss: 0.1427478790283203, train_loss: 0.14306959509849548\n",
      "35350 val_loss: 0.1433539092540741, train_loss: 0.14452014863491058\n",
      "35360 val_loss: 0.14372976124286652, train_loss: 0.1435881406068802\n",
      "35370 val_loss: 0.14250008761882782, train_loss: 0.1424950659275055\n",
      "35380 val_loss: 0.14140178263187408, train_loss: 0.14216114580631256\n",
      "35390 val_loss: 0.14330677688121796, train_loss: 0.1454145312309265\n",
      "35400 val_loss: 0.14235757291316986, train_loss: 0.14430545270442963\n",
      "35410 val_loss: 0.14288094639778137, train_loss: 0.1426009237766266\n",
      "35420 val_loss: 0.14260226488113403, train_loss: 0.14380677044391632\n",
      "35430 val_loss: 0.14935754239559174, train_loss: 0.14808200299739838\n",
      "35440 val_loss: 0.14284269511699677, train_loss: 0.14331066608428955\n",
      "35450 val_loss: 0.1417212188243866, train_loss: 0.14326702058315277\n",
      "35460 val_loss: 0.14411035180091858, train_loss: 0.1429530680179596\n",
      "35470 val_loss: 0.14579886198043823, train_loss: 0.14420637488365173\n",
      "35480 val_loss: 0.14188836514949799, train_loss: 0.14156542718410492\n",
      "35490 val_loss: 0.14291664958000183, train_loss: 0.14202426373958588\n",
      "35500 val_loss: 0.143273264169693, train_loss: 0.14212268590927124\n",
      "35510 val_loss: 0.14271150529384613, train_loss: 0.14148551225662231\n",
      "35520 val_loss: 0.14126946032047272, train_loss: 0.14081700146198273\n",
      "35530 val_loss: 0.14410188794136047, train_loss: 0.1423949897289276\n",
      "35540 val_loss: 0.14126694202423096, train_loss: 0.14044833183288574\n",
      "35550 val_loss: 0.14189870655536652, train_loss: 0.14084996283054352\n",
      "35560 val_loss: 0.13965368270874023, train_loss: 0.13948164880275726\n",
      "35570 val_loss: 0.14388467371463776, train_loss: 0.1450054794549942\n",
      "35580 val_loss: 0.14022187888622284, train_loss: 0.1397169828414917\n",
      "35590 val_loss: 0.1398227959871292, train_loss: 0.13953833281993866\n",
      "35600 val_loss: 0.1443967968225479, train_loss: 0.1430700272321701\n",
      "35610 val_loss: 0.14281290769577026, train_loss: 0.14179643988609314\n",
      "35620 val_loss: 0.14067548513412476, train_loss: 0.14003024995326996\n",
      "35630 val_loss: 0.14561717212200165, train_loss: 0.14435237646102905\n",
      "35640 val_loss: 0.1412631869316101, train_loss: 0.1395813524723053\n",
      "35650 val_loss: 0.14891928434371948, train_loss: 0.1468202918767929\n",
      "35660 val_loss: 0.1428360939025879, train_loss: 0.14101675152778625\n",
      "35670 val_loss: 0.1438407599925995, train_loss: 0.1437324434518814\n",
      "35680 val_loss: 0.13806089758872986, train_loss: 0.1383419781923294\n",
      "35690 val_loss: 0.1450832337141037, train_loss: 0.1460627317428589\n",
      "35700 val_loss: 0.14191387593746185, train_loss: 0.1400069296360016\n",
      "35710 val_loss: 0.14405857026576996, train_loss: 0.14193762838840485\n",
      "35720 val_loss: 0.14716263115406036, train_loss: 0.14497195184230804\n",
      "35730 val_loss: 0.1454962193965912, train_loss: 0.14262981712818146\n",
      "35740 val_loss: 0.13857094943523407, train_loss: 0.13920371234416962\n",
      "35750 val_loss: 0.1427605003118515, train_loss: 0.14133712649345398\n",
      "35760 val_loss: 0.14350764453411102, train_loss: 0.14069496095180511\n",
      "35770 val_loss: 0.14556856453418732, train_loss: 0.14288507401943207\n",
      "35780 val_loss: 0.1391589492559433, train_loss: 0.1373656839132309\n",
      "35790 val_loss: 0.14335371553897858, train_loss: 0.14069516956806183\n",
      "35800 val_loss: 0.14287987351417542, train_loss: 0.14039891958236694\n",
      "35810 val_loss: 0.14025378227233887, train_loss: 0.14191748201847076\n",
      "35820 val_loss: 0.14403654634952545, train_loss: 0.1407880038022995\n",
      "35830 val_loss: 0.14053869247436523, train_loss: 0.1378544420003891\n",
      "35840 val_loss: 0.1420631855726242, train_loss: 0.1404956877231598\n",
      "35850 val_loss: 0.1421731412410736, train_loss: 0.1392831802368164\n",
      "35860 val_loss: 0.1418398916721344, train_loss: 0.13906808197498322\n",
      "35870 val_loss: 0.1358603835105896, train_loss: 0.13547401130199432\n",
      "35880 val_loss: 0.1357875019311905, train_loss: 0.13569001853466034\n",
      "35890 val_loss: 0.14152203500270844, train_loss: 0.1391925811767578\n",
      "35900 val_loss: 0.14092665910720825, train_loss: 0.13774342834949493\n",
      "35910 val_loss: 0.14014776051044464, train_loss: 0.13758696615695953\n",
      "35920 val_loss: 0.14479702711105347, train_loss: 0.14102448523044586\n",
      "35930 val_loss: 0.13907180726528168, train_loss: 0.1386183351278305\n",
      "35940 val_loss: 0.14217697083950043, train_loss: 0.1431589126586914\n",
      "35950 val_loss: 0.13636919856071472, train_loss: 0.13529258966445923\n",
      "35960 val_loss: 0.13570654392242432, train_loss: 0.13732194900512695\n",
      "35970 val_loss: 0.138121098279953, train_loss: 0.13649989664554596\n",
      "35980 val_loss: 0.13474926352500916, train_loss: 0.1347857117652893\n",
      "35990 val_loss: 0.13728973269462585, train_loss: 0.13673867285251617\n",
      "36000 val_loss: 0.1390015184879303, train_loss: 0.1384698450565338\n",
      "36010 val_loss: 0.13900786638259888, train_loss: 0.13693419098854065\n",
      "36020 val_loss: 0.13987046480178833, train_loss: 0.13678370416164398\n",
      "36030 val_loss: 0.13491986691951752, train_loss: 0.1348503679037094\n",
      "36040 val_loss: 0.13527752459049225, train_loss: 0.13472025096416473\n",
      "36050 val_loss: 0.13718321919441223, train_loss: 0.13544084131717682\n",
      "36060 val_loss: 0.1409565955400467, train_loss: 0.13980329036712646\n",
      "36070 val_loss: 0.1386088728904724, train_loss: 0.13671915233135223\n",
      "36080 val_loss: 0.13398632407188416, train_loss: 0.1361079066991806\n",
      "36090 val_loss: 0.14048077166080475, train_loss: 0.13773490488529205\n",
      "36100 val_loss: 0.14289924502372742, train_loss: 0.14198890328407288\n",
      "36110 val_loss: 0.13218531012535095, train_loss: 0.13291329145431519\n",
      "36120 val_loss: 0.14068569242954254, train_loss: 0.1382773071527481\n",
      "36130 val_loss: 0.14885295927524567, train_loss: 0.14667333662509918\n",
      "36140 val_loss: 0.1356225460767746, train_loss: 0.1344139128923416\n",
      "36150 val_loss: 0.14231286942958832, train_loss: 0.13948577642440796\n",
      "36160 val_loss: 0.1384640634059906, train_loss: 0.13620023429393768\n",
      "36170 val_loss: 0.1405622810125351, train_loss: 0.13863719999790192\n",
      "36180 val_loss: 0.13575918972492218, train_loss: 0.13433288037776947\n",
      "36190 val_loss: 0.13267938792705536, train_loss: 0.13343927264213562\n",
      "36200 val_loss: 0.14425231516361237, train_loss: 0.14108337461948395\n",
      "36210 val_loss: 0.13276517391204834, train_loss: 0.13342523574829102\n",
      "36220 val_loss: 0.13242989778518677, train_loss: 0.13288719952106476\n",
      "36230 val_loss: 0.130404993891716, train_loss: 0.13147906959056854\n",
      "36240 val_loss: 0.13274922966957092, train_loss: 0.13208475708961487\n",
      "36250 val_loss: 0.1328548640012741, train_loss: 0.13191388547420502\n",
      "36260 val_loss: 0.13180595636367798, train_loss: 0.13116657733917236\n",
      "36270 val_loss: 0.13157114386558533, train_loss: 0.13114790618419647\n",
      "36280 val_loss: 0.139555424451828, train_loss: 0.1372651755809784\n",
      "36290 val_loss: 0.14127874374389648, train_loss: 0.14021806418895721\n",
      "36300 val_loss: 0.13709743320941925, train_loss: 0.13571806252002716\n",
      "36310 val_loss: 0.13939833641052246, train_loss: 0.13673190772533417\n",
      "36320 val_loss: 0.1340373158454895, train_loss: 0.1325937658548355\n",
      "36330 val_loss: 0.14501766860485077, train_loss: 0.14241226017475128\n",
      "36340 val_loss: 0.1316368132829666, train_loss: 0.13041731715202332\n",
      "36350 val_loss: 0.14099779725074768, train_loss: 0.1451394259929657\n",
      "36360 val_loss: 0.12963230907917023, train_loss: 0.12949518859386444\n",
      "36370 val_loss: 0.133548304438591, train_loss: 0.13328377902507782\n",
      "36380 val_loss: 0.13828228414058685, train_loss: 0.13535639643669128\n",
      "36390 val_loss: 0.13190147280693054, train_loss: 0.13165415823459625\n",
      "36400 val_loss: 0.1376398503780365, train_loss: 0.1365603506565094\n",
      "36410 val_loss: 0.12956376373767853, train_loss: 0.1292654424905777\n",
      "36420 val_loss: 0.12910763919353485, train_loss: 0.129615917801857\n",
      "36430 val_loss: 0.13878539204597473, train_loss: 0.13648350536823273\n",
      "36440 val_loss: 0.133395716547966, train_loss: 0.13190285861492157\n",
      "36450 val_loss: 0.131266787648201, train_loss: 0.13039392232894897\n",
      "36460 val_loss: 0.1297948956489563, train_loss: 0.12937785685062408\n",
      "36470 val_loss: 0.1361667960882187, train_loss: 0.1342768669128418\n",
      "36480 val_loss: 0.12947078049182892, train_loss: 0.12872149050235748\n",
      "36490 val_loss: 0.12895897030830383, train_loss: 0.12916767597198486\n",
      "36500 val_loss: 0.12809552252292633, train_loss: 0.12780050933361053\n",
      "36510 val_loss: 0.13474972546100616, train_loss: 0.13170424103736877\n",
      "36520 val_loss: 0.13280801475048065, train_loss: 0.13087274134159088\n",
      "36530 val_loss: 0.1336677074432373, train_loss: 0.13104979693889618\n",
      "36540 val_loss: 0.12957854568958282, train_loss: 0.1291137933731079\n",
      "36550 val_loss: 0.1277351826429367, train_loss: 0.12940116226673126\n",
      "36560 val_loss: 0.13476723432540894, train_loss: 0.13236747682094574\n",
      "36570 val_loss: 0.13494005799293518, train_loss: 0.13460612297058105\n",
      "36580 val_loss: 0.1372862607240677, train_loss: 0.13473495841026306\n",
      "36590 val_loss: 0.14472301304340363, train_loss: 0.14885221421718597\n",
      "36600 val_loss: 0.13004110753536224, train_loss: 0.1289755403995514\n",
      "36610 val_loss: 0.1285526305437088, train_loss: 0.1279059648513794\n",
      "36620 val_loss: 0.135421484708786, train_loss: 0.1331958770751953\n",
      "36630 val_loss: 0.1292155385017395, train_loss: 0.1287117898464203\n",
      "36640 val_loss: 0.1273743212223053, train_loss: 0.12708468735218048\n",
      "36650 val_loss: 0.13603165745735168, train_loss: 0.13781581819057465\n",
      "36660 val_loss: 0.13587327301502228, train_loss: 0.13475337624549866\n",
      "36670 val_loss: 0.12822720408439636, train_loss: 0.12699440121650696\n",
      "36680 val_loss: 0.15488742291927338, train_loss: 0.1521407812833786\n",
      "36690 val_loss: 0.12696127593517303, train_loss: 0.1270013004541397\n",
      "36700 val_loss: 0.1268652081489563, train_loss: 0.12644392251968384\n",
      "36710 val_loss: 0.13284499943256378, train_loss: 0.1315874308347702\n",
      "36720 val_loss: 0.13248802721500397, train_loss: 0.13059812784194946\n",
      "36730 val_loss: 0.1346556842327118, train_loss: 0.13215698301792145\n",
      "36740 val_loss: 0.14114047586917877, train_loss: 0.13903455436229706\n",
      "36750 val_loss: 0.1401885449886322, train_loss: 0.13951419293880463\n",
      "36760 val_loss: 0.12595783174037933, train_loss: 0.12549853324890137\n",
      "36770 val_loss: 0.1277722716331482, train_loss: 0.12891267240047455\n",
      "36780 val_loss: 0.1252250373363495, train_loss: 0.12480850517749786\n",
      "36790 val_loss: 0.1342507302761078, train_loss: 0.13196678459644318\n",
      "36800 val_loss: 0.12625473737716675, train_loss: 0.1260305494070053\n",
      "36810 val_loss: 0.12654165923595428, train_loss: 0.12598057091236115\n",
      "36820 val_loss: 0.13465622067451477, train_loss: 0.131423681974411\n",
      "36830 val_loss: 0.12901820242404938, train_loss: 0.12795020639896393\n",
      "36840 val_loss: 0.12578091025352478, train_loss: 0.12493261694908142\n",
      "36850 val_loss: 0.1309742033481598, train_loss: 0.12785407900810242\n",
      "36860 val_loss: 0.12983816862106323, train_loss: 0.12695583701133728\n",
      "36870 val_loss: 0.12607312202453613, train_loss: 0.12466862797737122\n",
      "36880 val_loss: 0.12983526289463043, train_loss: 0.12681905925273895\n",
      "36890 val_loss: 0.12957921624183655, train_loss: 0.1269790530204773\n",
      "36900 val_loss: 0.1322355568408966, train_loss: 0.13005013763904572\n",
      "36910 val_loss: 0.1364353597164154, train_loss: 0.1332784742116928\n",
      "36920 val_loss: 0.1313401162624359, train_loss: 0.12910842895507812\n",
      "36930 val_loss: 0.12937436997890472, train_loss: 0.1319943517446518\n",
      "36940 val_loss: 0.12679935991764069, train_loss: 0.12497870624065399\n",
      "36950 val_loss: 0.1299971342086792, train_loss: 0.12699590623378754\n",
      "36960 val_loss: 0.138412207365036, train_loss: 0.1364063322544098\n",
      "36970 val_loss: 0.12911798059940338, train_loss: 0.12685821950435638\n",
      "36980 val_loss: 0.12683500349521637, train_loss: 0.1254599541425705\n",
      "36990 val_loss: 0.12365256994962692, train_loss: 0.12370327115058899\n",
      "37000 val_loss: 0.12419941276311874, train_loss: 0.12358949333429337\n",
      "37010 val_loss: 0.12516237795352936, train_loss: 0.12402235716581345\n",
      "37020 val_loss: 0.13648146390914917, train_loss: 0.13349895179271698\n",
      "37030 val_loss: 0.1253833770751953, train_loss: 0.1238098293542862\n",
      "37040 val_loss: 0.12280398607254028, train_loss: 0.12252599000930786\n",
      "37050 val_loss: 0.12343758344650269, train_loss: 0.12260027974843979\n",
      "37060 val_loss: 0.12303924560546875, train_loss: 0.12287713587284088\n",
      "37070 val_loss: 0.12452876567840576, train_loss: 0.1229947879910469\n",
      "37080 val_loss: 0.12233912199735641, train_loss: 0.12224338948726654\n",
      "37090 val_loss: 0.12442149966955185, train_loss: 0.12231352180242538\n",
      "37100 val_loss: 0.12281158566474915, train_loss: 0.12314866483211517\n",
      "37110 val_loss: 0.12833619117736816, train_loss: 0.12522052228450775\n",
      "37120 val_loss: 0.1245003342628479, train_loss: 0.122608482837677\n",
      "37130 val_loss: 0.12346073240041733, train_loss: 0.12182159721851349\n",
      "37140 val_loss: 0.12223117798566818, train_loss: 0.12382500618696213\n",
      "37150 val_loss: 0.13017341494560242, train_loss: 0.1316962093114853\n",
      "37160 val_loss: 0.12581239640712738, train_loss: 0.12389340996742249\n",
      "37170 val_loss: 0.12571296095848083, train_loss: 0.12373027950525284\n",
      "37180 val_loss: 0.136857271194458, train_loss: 0.13782954216003418\n",
      "37190 val_loss: 0.12489145249128342, train_loss: 0.12367047369480133\n",
      "37200 val_loss: 0.12354094535112381, train_loss: 0.12149292230606079\n",
      "37210 val_loss: 0.12452215701341629, train_loss: 0.12300359457731247\n",
      "37220 val_loss: 0.12282557040452957, train_loss: 0.1211191937327385\n",
      "37230 val_loss: 0.1269591897726059, train_loss: 0.12692596018314362\n",
      "37240 val_loss: 0.14600178599357605, train_loss: 0.14110635221004486\n",
      "37250 val_loss: 0.12526488304138184, train_loss: 0.12365053594112396\n",
      "37260 val_loss: 0.12282434850931168, train_loss: 0.12133879959583282\n",
      "37270 val_loss: 0.12539155781269073, train_loss: 0.12195522338151932\n",
      "37280 val_loss: 0.12233243882656097, train_loss: 0.120525062084198\n",
      "37290 val_loss: 0.12808656692504883, train_loss: 0.1268647164106369\n",
      "37300 val_loss: 0.12574563920497894, train_loss: 0.12315361946821213\n",
      "37310 val_loss: 0.14144334197044373, train_loss: 0.14374946057796478\n",
      "37320 val_loss: 0.1291976124048233, train_loss: 0.12616154551506042\n",
      "37330 val_loss: 0.12474380433559418, train_loss: 0.12149294465780258\n",
      "37340 val_loss: 0.12287827581167221, train_loss: 0.12043776363134384\n",
      "37350 val_loss: 0.12655527889728546, train_loss: 0.12277662009000778\n",
      "37360 val_loss: 0.12009190022945404, train_loss: 0.11913613975048065\n",
      "37370 val_loss: 0.11991197615861893, train_loss: 0.119180828332901\n",
      "37380 val_loss: 0.12372233718633652, train_loss: 0.12074283510446548\n",
      "37390 val_loss: 0.12792427837848663, train_loss: 0.12477295100688934\n",
      "37400 val_loss: 0.12224189937114716, train_loss: 0.11944304406642914\n",
      "37410 val_loss: 0.136040598154068, train_loss: 0.1321524977684021\n",
      "37420 val_loss: 0.12500488758087158, train_loss: 0.12112592160701752\n",
      "37430 val_loss: 0.13091923296451569, train_loss: 0.12794044613838196\n",
      "37440 val_loss: 0.1300659030675888, train_loss: 0.12559328973293304\n",
      "37450 val_loss: 0.12179423123598099, train_loss: 0.12381891161203384\n",
      "37460 val_loss: 0.12547694146633148, train_loss: 0.12299960106611252\n",
      "37470 val_loss: 0.12011979520320892, train_loss: 0.12035204470157623\n",
      "37480 val_loss: 0.12015006691217422, train_loss: 0.11905604600906372\n",
      "37490 val_loss: 0.12783199548721313, train_loss: 0.1238776296377182\n",
      "37500 val_loss: 0.12358015775680542, train_loss: 0.1216132789850235\n",
      "37510 val_loss: 0.11959050595760345, train_loss: 0.11864381283521652\n",
      "37520 val_loss: 0.11907557398080826, train_loss: 0.11844874173402786\n",
      "37530 val_loss: 0.12084703892469406, train_loss: 0.11842982470989227\n",
      "37540 val_loss: 0.12457554787397385, train_loss: 0.12138407677412033\n",
      "37550 val_loss: 0.12278430163860321, train_loss: 0.1208193451166153\n",
      "37560 val_loss: 0.12157078832387924, train_loss: 0.11931435763835907\n",
      "37570 val_loss: 0.1334412693977356, train_loss: 0.13059334456920624\n",
      "37580 val_loss: 0.1217414066195488, train_loss: 0.11922837048768997\n",
      "37590 val_loss: 0.11868736892938614, train_loss: 0.117234967648983\n",
      "37600 val_loss: 0.12492306530475616, train_loss: 0.12242865562438965\n",
      "37610 val_loss: 0.12682801485061646, train_loss: 0.12378069758415222\n",
      "37620 val_loss: 0.1273026466369629, train_loss: 0.12545093894004822\n",
      "37630 val_loss: 0.12049804627895355, train_loss: 0.12201911211013794\n",
      "37640 val_loss: 0.11965540796518326, train_loss: 0.11747312545776367\n",
      "37650 val_loss: 0.11829980462789536, train_loss: 0.11748401820659637\n",
      "37660 val_loss: 0.1271762251853943, train_loss: 0.12383311241865158\n",
      "37670 val_loss: 0.11694605648517609, train_loss: 0.11648671329021454\n",
      "37680 val_loss: 0.12710845470428467, train_loss: 0.12478238344192505\n",
      "37690 val_loss: 0.12079760432243347, train_loss: 0.11848772317171097\n",
      "37700 val_loss: 0.13702093064785004, train_loss: 0.13311783969402313\n",
      "37710 val_loss: 0.12793470919132233, train_loss: 0.12440565973520279\n",
      "37720 val_loss: 0.1250133514404297, train_loss: 0.12200892716646194\n",
      "37730 val_loss: 0.1188620999455452, train_loss: 0.11825419962406158\n",
      "37740 val_loss: 0.13030558824539185, train_loss: 0.1268414407968521\n",
      "37750 val_loss: 0.12700329720973969, train_loss: 0.12426578253507614\n",
      "37760 val_loss: 0.11653178930282593, train_loss: 0.11544053256511688\n",
      "37770 val_loss: 0.11723325401544571, train_loss: 0.11544876545667648\n",
      "37780 val_loss: 0.11751063913106918, train_loss: 0.11612694710493088\n",
      "37790 val_loss: 0.11637315154075623, train_loss: 0.11504372209310532\n",
      "37800 val_loss: 0.1237187385559082, train_loss: 0.12160585820674896\n",
      "37810 val_loss: 0.12107490748167038, train_loss: 0.12217581272125244\n",
      "37820 val_loss: 0.11861789971590042, train_loss: 0.11869692802429199\n",
      "37830 val_loss: 0.1152999997138977, train_loss: 0.11424063891172409\n",
      "37840 val_loss: 0.12136639654636383, train_loss: 0.11888274550437927\n",
      "37850 val_loss: 0.11718697100877762, train_loss: 0.11502721160650253\n",
      "37860 val_loss: 0.1207813024520874, train_loss: 0.11821494251489639\n",
      "37870 val_loss: 0.11567765474319458, train_loss: 0.11719349771738052\n",
      "37880 val_loss: 0.11598861962556839, train_loss: 0.1141878142952919\n",
      "37890 val_loss: 0.13214071094989777, train_loss: 0.12945294380187988\n",
      "37900 val_loss: 0.11925128847360611, train_loss: 0.12090716511011124\n",
      "37910 val_loss: 0.11994358152151108, train_loss: 0.11845967918634415\n",
      "37920 val_loss: 0.11725352704524994, train_loss: 0.11550267785787582\n",
      "37930 val_loss: 0.11550107598304749, train_loss: 0.11372210830450058\n",
      "37940 val_loss: 0.1160692572593689, train_loss: 0.11511041224002838\n",
      "37950 val_loss: 0.12807002663612366, train_loss: 0.12423669546842575\n",
      "37960 val_loss: 0.11788851022720337, train_loss: 0.11581457406282425\n",
      "37970 val_loss: 0.122026726603508, train_loss: 0.11912774294614792\n",
      "37980 val_loss: 0.11976255476474762, train_loss: 0.11887014657258987\n",
      "37990 val_loss: 0.11867927014827728, train_loss: 0.11659690737724304\n",
      "38000 val_loss: 0.11622344702482224, train_loss: 0.11458218842744827\n",
      "38010 val_loss: 0.11581392586231232, train_loss: 0.11519788205623627\n",
      "38020 val_loss: 0.11858995258808136, train_loss: 0.11635621637105942\n",
      "38030 val_loss: 0.11837512999773026, train_loss: 0.11700302362442017\n",
      "38040 val_loss: 0.12101815640926361, train_loss: 0.1216561421751976\n",
      "38050 val_loss: 0.1165815219283104, train_loss: 0.1141132041811943\n",
      "38060 val_loss: 0.11818429827690125, train_loss: 0.11515340209007263\n",
      "38070 val_loss: 0.11907695233821869, train_loss: 0.11545389890670776\n",
      "38080 val_loss: 0.11604384332895279, train_loss: 0.11421743035316467\n",
      "38090 val_loss: 0.11549744009971619, train_loss: 0.11626280099153519\n",
      "38100 val_loss: 0.12024299800395966, train_loss: 0.11688042432069778\n",
      "38110 val_loss: 0.11741141974925995, train_loss: 0.1185399517416954\n",
      "38120 val_loss: 0.11482063680887222, train_loss: 0.11472460627555847\n",
      "38130 val_loss: 0.1183004379272461, train_loss: 0.11493753641843796\n",
      "38140 val_loss: 0.13237032294273376, train_loss: 0.1278541386127472\n",
      "38150 val_loss: 0.11478345096111298, train_loss: 0.11239384114742279\n",
      "38160 val_loss: 0.11542138457298279, train_loss: 0.11312209069728851\n",
      "38170 val_loss: 0.12039966881275177, train_loss: 0.11721264570951462\n",
      "38180 val_loss: 0.11453425139188766, train_loss: 0.11289093643426895\n",
      "38190 val_loss: 0.12756943702697754, train_loss: 0.12140373140573502\n",
      "38200 val_loss: 0.11263032257556915, train_loss: 0.1118549033999443\n",
      "38210 val_loss: 0.11792529374361038, train_loss: 0.11437205970287323\n",
      "38220 val_loss: 0.11977342516183853, train_loss: 0.11571693420410156\n",
      "38230 val_loss: 0.1140003427863121, train_loss: 0.11167298257350922\n",
      "38240 val_loss: 0.12100564688444138, train_loss: 0.11665458232164383\n",
      "38250 val_loss: 0.12289062142372131, train_loss: 0.11754990369081497\n",
      "38260 val_loss: 0.12018819153308868, train_loss: 0.11778132617473602\n",
      "38270 val_loss: 0.11387994140386581, train_loss: 0.11079145222902298\n",
      "38280 val_loss: 0.1139213964343071, train_loss: 0.11062264442443848\n",
      "38290 val_loss: 0.11163273453712463, train_loss: 0.11144184321165085\n",
      "38300 val_loss: 0.1204494908452034, train_loss: 0.11780081689357758\n",
      "38310 val_loss: 0.11288882791996002, train_loss: 0.11058710515499115\n",
      "38320 val_loss: 0.11329127848148346, train_loss: 0.11076585203409195\n",
      "38330 val_loss: 0.1170874834060669, train_loss: 0.1181536540389061\n",
      "38340 val_loss: 0.11117175221443176, train_loss: 0.11025118827819824\n",
      "38350 val_loss: 0.11622845381498337, train_loss: 0.11253275722265244\n",
      "38360 val_loss: 0.11637166142463684, train_loss: 0.11360112577676773\n",
      "38370 val_loss: 0.12396468967199326, train_loss: 0.12121325731277466\n",
      "38380 val_loss: 0.11204912513494492, train_loss: 0.10980936139822006\n",
      "38390 val_loss: 0.1190456748008728, train_loss: 0.11453279107809067\n",
      "38400 val_loss: 0.12336103618144989, train_loss: 0.1244911178946495\n",
      "38410 val_loss: 0.11158370226621628, train_loss: 0.11026037484407425\n",
      "38420 val_loss: 0.12779924273490906, train_loss: 0.12860973179340363\n",
      "38430 val_loss: 0.11240378022193909, train_loss: 0.1110270619392395\n",
      "38440 val_loss: 0.12713496387004852, train_loss: 0.1228378415107727\n",
      "38450 val_loss: 0.11355000734329224, train_loss: 0.11048771440982819\n",
      "38460 val_loss: 0.11092128604650497, train_loss: 0.10963552445173264\n",
      "38470 val_loss: 0.11266232281923294, train_loss: 0.10929334908723831\n",
      "38480 val_loss: 0.11199308931827545, train_loss: 0.11078126728534698\n",
      "38490 val_loss: 0.11627707630395889, train_loss: 0.11331108957529068\n",
      "38500 val_loss: 0.11867884546518326, train_loss: 0.11694229394197464\n",
      "38510 val_loss: 0.11592603474855423, train_loss: 0.11422263085842133\n",
      "38520 val_loss: 0.11694692075252533, train_loss: 0.11435171961784363\n",
      "38530 val_loss: 0.11381158232688904, train_loss: 0.11079538613557816\n",
      "38540 val_loss: 0.12055306136608124, train_loss: 0.11838477104902267\n",
      "38550 val_loss: 0.1233544647693634, train_loss: 0.11930442601442337\n",
      "38560 val_loss: 0.115071602165699, train_loss: 0.11186174303293228\n",
      "38570 val_loss: 0.11175350099802017, train_loss: 0.11089882999658585\n",
      "38580 val_loss: 0.11226361244916916, train_loss: 0.10985910147428513\n",
      "38590 val_loss: 0.11838790029287338, train_loss: 0.11507599800825119\n",
      "38600 val_loss: 0.1194557473063469, train_loss: 0.11615471541881561\n",
      "38610 val_loss: 0.11324867606163025, train_loss: 0.11181478202342987\n",
      "38620 val_loss: 0.11206294596195221, train_loss: 0.10960549861192703\n",
      "38630 val_loss: 0.11355766654014587, train_loss: 0.11056610196828842\n",
      "38640 val_loss: 0.11853069812059402, train_loss: 0.11305742710828781\n",
      "38650 val_loss: 0.12192196398973465, train_loss: 0.11867570877075195\n",
      "38660 val_loss: 0.11101721227169037, train_loss: 0.10901074856519699\n",
      "38670 val_loss: 0.11239240318536758, train_loss: 0.11242730170488358\n",
      "38680 val_loss: 0.12035892903804779, train_loss: 0.11871115863323212\n",
      "38690 val_loss: 0.1241903156042099, train_loss: 0.12192746996879578\n",
      "38700 val_loss: 0.11627661436796188, train_loss: 0.11315111070871353\n",
      "38710 val_loss: 0.11453691869974136, train_loss: 0.11006616055965424\n",
      "38720 val_loss: 0.11643998324871063, train_loss: 0.11061222851276398\n",
      "38730 val_loss: 0.11154159903526306, train_loss: 0.10732851177453995\n",
      "38740 val_loss: 0.11018569767475128, train_loss: 0.10693421959877014\n",
      "38750 val_loss: 0.11132211238145828, train_loss: 0.10724320262670517\n",
      "38760 val_loss: 0.12026674300432205, train_loss: 0.11534494161605835\n",
      "38770 val_loss: 0.11076667159795761, train_loss: 0.10742161422967911\n",
      "38780 val_loss: 0.11489573121070862, train_loss: 0.1088194027543068\n",
      "38790 val_loss: 0.10956932604312897, train_loss: 0.10740301758050919\n",
      "38800 val_loss: 0.10833019763231277, train_loss: 0.10792826861143112\n",
      "38810 val_loss: 0.1151127815246582, train_loss: 0.11286880820989609\n",
      "38820 val_loss: 0.10940033942461014, train_loss: 0.10772182792425156\n",
      "38830 val_loss: 0.1106865406036377, train_loss: 0.10985611379146576\n",
      "38840 val_loss: 0.11572906374931335, train_loss: 0.11262547224760056\n",
      "38850 val_loss: 0.11307530850172043, train_loss: 0.10956241190433502\n",
      "38860 val_loss: 0.11164955794811249, train_loss: 0.10692275315523148\n",
      "38870 val_loss: 0.11101667582988739, train_loss: 0.10718346387147903\n",
      "38880 val_loss: 0.12742337584495544, train_loss: 0.12370993196964264\n",
      "38890 val_loss: 0.11225944757461548, train_loss: 0.107322558760643\n",
      "38900 val_loss: 0.12748973071575165, train_loss: 0.12806275486946106\n",
      "38910 val_loss: 0.10954583436250687, train_loss: 0.10721532255411148\n",
      "38920 val_loss: 0.10792694240808487, train_loss: 0.10445617884397507\n",
      "38930 val_loss: 0.10755770653486252, train_loss: 0.1046152263879776\n",
      "38940 val_loss: 0.10767519474029541, train_loss: 0.10499676316976547\n",
      "38950 val_loss: 0.10706382244825363, train_loss: 0.10437777638435364\n",
      "38960 val_loss: 0.12168806791305542, train_loss: 0.11772994697093964\n",
      "38970 val_loss: 0.11001025140285492, train_loss: 0.10599375516176224\n",
      "38980 val_loss: 0.11673937737941742, train_loss: 0.11280333250761032\n",
      "38990 val_loss: 0.11684496700763702, train_loss: 0.11185398697853088\n",
      "39000 val_loss: 0.10640305280685425, train_loss: 0.10440374910831451\n",
      "39010 val_loss: 0.10847379267215729, train_loss: 0.10796687006950378\n",
      "39020 val_loss: 0.11473045498132706, train_loss: 0.11518164724111557\n",
      "39030 val_loss: 0.107062429189682, train_loss: 0.10530024766921997\n",
      "39040 val_loss: 0.11179693788290024, train_loss: 0.11061196774244308\n",
      "39050 val_loss: 0.11428575962781906, train_loss: 0.1152055487036705\n",
      "39060 val_loss: 0.10608654469251633, train_loss: 0.10366294533014297\n",
      "39070 val_loss: 0.10869209468364716, train_loss: 0.10628969222307205\n",
      "39080 val_loss: 0.10729874670505524, train_loss: 0.1068788394331932\n",
      "39090 val_loss: 0.10764139145612717, train_loss: 0.10404282808303833\n",
      "39100 val_loss: 0.10962577164173126, train_loss: 0.10812995582818985\n",
      "39110 val_loss: 0.11488988995552063, train_loss: 0.11051087081432343\n",
      "39120 val_loss: 0.11027849465608597, train_loss: 0.10544543713331223\n",
      "39130 val_loss: 0.11085882782936096, train_loss: 0.10997450351715088\n",
      "39140 val_loss: 0.11771904677152634, train_loss: 0.11260359734296799\n",
      "39150 val_loss: 0.11037662625312805, train_loss: 0.1063210740685463\n",
      "39160 val_loss: 0.11102912575006485, train_loss: 0.10638181865215302\n",
      "39170 val_loss: 0.11300107836723328, train_loss: 0.11290591210126877\n",
      "39180 val_loss: 0.11213891953229904, train_loss: 0.10971664637327194\n",
      "39190 val_loss: 0.1378612369298935, train_loss: 0.13854964077472687\n",
      "39200 val_loss: 0.10638201981782913, train_loss: 0.10601530969142914\n",
      "39210 val_loss: 0.11097364127635956, train_loss: 0.10953561216592789\n",
      "39220 val_loss: 0.11698910593986511, train_loss: 0.11494408547878265\n",
      "39230 val_loss: 0.11818396300077438, train_loss: 0.11562398821115494\n",
      "39240 val_loss: 0.12825612723827362, train_loss: 0.12449390441179276\n",
      "39250 val_loss: 0.10503243654966354, train_loss: 0.10383006185293198\n",
      "39260 val_loss: 0.11893338710069656, train_loss: 0.11592675000429153\n",
      "39270 val_loss: 0.1247779130935669, train_loss: 0.12121099978685379\n",
      "39280 val_loss: 0.1253853291273117, train_loss: 0.12168450653553009\n",
      "39290 val_loss: 0.10599561780691147, train_loss: 0.10356929898262024\n",
      "39300 val_loss: 0.10494357347488403, train_loss: 0.10412120819091797\n",
      "39310 val_loss: 0.12035946547985077, train_loss: 0.11831095814704895\n",
      "39320 val_loss: 0.1054743155837059, train_loss: 0.10268765687942505\n",
      "39330 val_loss: 0.10490840673446655, train_loss: 0.10276852548122406\n",
      "39340 val_loss: 0.10540342330932617, train_loss: 0.10567964613437653\n",
      "39350 val_loss: 0.10483532398939133, train_loss: 0.1027340292930603\n",
      "39360 val_loss: 0.11465637385845184, train_loss: 0.11102616786956787\n",
      "39370 val_loss: 0.10659327358007431, train_loss: 0.10320807993412018\n",
      "39380 val_loss: 0.11199724674224854, train_loss: 0.10786101967096329\n",
      "39390 val_loss: 0.10871187597513199, train_loss: 0.10426729172468185\n",
      "39400 val_loss: 0.14665570855140686, train_loss: 0.14524902403354645\n",
      "39410 val_loss: 0.10712238401174545, train_loss: 0.10531030595302582\n",
      "39420 val_loss: 0.11948657035827637, train_loss: 0.11937902867794037\n",
      "39430 val_loss: 0.10928993672132492, train_loss: 0.10847898572683334\n",
      "39440 val_loss: 0.10427038371562958, train_loss: 0.10151002556085587\n",
      "39450 val_loss: 0.10755698382854462, train_loss: 0.1052270159125328\n",
      "39460 val_loss: 0.10514446347951889, train_loss: 0.1023869663476944\n",
      "39470 val_loss: 0.10735580325126648, train_loss: 0.10317311435937881\n",
      "39480 val_loss: 0.10589078813791275, train_loss: 0.10554228723049164\n",
      "39490 val_loss: 0.10282602906227112, train_loss: 0.10149077326059341\n",
      "39500 val_loss: 0.13912472128868103, train_loss: 0.13887794315814972\n",
      "39510 val_loss: 0.11437971144914627, train_loss: 0.11075279116630554\n",
      "39520 val_loss: 0.10537874698638916, train_loss: 0.1028277799487114\n",
      "39530 val_loss: 0.10330221801996231, train_loss: 0.10026519000530243\n",
      "39540 val_loss: 0.10596488416194916, train_loss: 0.1030602678656578\n",
      "39550 val_loss: 0.10298388451337814, train_loss: 0.1004650667309761\n",
      "39560 val_loss: 0.10461429506540298, train_loss: 0.10237794369459152\n",
      "39570 val_loss: 0.10731640458106995, train_loss: 0.10437476634979248\n",
      "39580 val_loss: 0.1040419340133667, train_loss: 0.10075291246175766\n",
      "39590 val_loss: 0.10670984536409378, train_loss: 0.10407993197441101\n",
      "39600 val_loss: 0.10463739931583405, train_loss: 0.10202795267105103\n",
      "39610 val_loss: 0.11497411131858826, train_loss: 0.1130237951874733\n",
      "39620 val_loss: 0.11091454327106476, train_loss: 0.1104355975985527\n",
      "39630 val_loss: 0.10623814165592194, train_loss: 0.10298720002174377\n",
      "39640 val_loss: 0.10144341737031937, train_loss: 0.10204135626554489\n",
      "39650 val_loss: 0.10660181939601898, train_loss: 0.10510250926017761\n",
      "39660 val_loss: 0.10309544205665588, train_loss: 0.10091209411621094\n",
      "39670 val_loss: 0.10681382566690445, train_loss: 0.10483545809984207\n",
      "39680 val_loss: 0.12010767310857773, train_loss: 0.11833091825246811\n",
      "39690 val_loss: 0.1012115478515625, train_loss: 0.09910548478364944\n",
      "39700 val_loss: 0.10423837602138519, train_loss: 0.10053400695323944\n",
      "39710 val_loss: 0.10803690552711487, train_loss: 0.10564165562391281\n",
      "39720 val_loss: 0.10334359854459763, train_loss: 0.10172022134065628\n",
      "39730 val_loss: 0.10210621356964111, train_loss: 0.10004881024360657\n",
      "39740 val_loss: 0.10633760690689087, train_loss: 0.10272077471017838\n",
      "39750 val_loss: 0.10862508416175842, train_loss: 0.10698410123586655\n",
      "39760 val_loss: 0.10095497965812683, train_loss: 0.09999994188547134\n",
      "39770 val_loss: 0.11048485338687897, train_loss: 0.10891583561897278\n",
      "39780 val_loss: 0.10044364631175995, train_loss: 0.09914059937000275\n",
      "39790 val_loss: 0.10309077799320221, train_loss: 0.10158390551805496\n",
      "39800 val_loss: 0.10359615087509155, train_loss: 0.10104122757911682\n",
      "39810 val_loss: 0.10035834461450577, train_loss: 0.09838169813156128\n",
      "39820 val_loss: 0.1087096780538559, train_loss: 0.10773792117834091\n",
      "39830 val_loss: 0.11902738362550735, train_loss: 0.11922912299633026\n",
      "39840 val_loss: 0.10347341001033783, train_loss: 0.10117998719215393\n",
      "39850 val_loss: 0.1025739461183548, train_loss: 0.10209726542234421\n",
      "39860 val_loss: 0.09975335001945496, train_loss: 0.09851628541946411\n",
      "39870 val_loss: 0.10131945461034775, train_loss: 0.10031969845294952\n",
      "39880 val_loss: 0.1070702001452446, train_loss: 0.10398264974355698\n",
      "39890 val_loss: 0.11114351451396942, train_loss: 0.10789456963539124\n",
      "39900 val_loss: 0.10476319491863251, train_loss: 0.1003030315041542\n",
      "39910 val_loss: 0.10828235000371933, train_loss: 0.10322869569063187\n",
      "39920 val_loss: 0.10056332498788834, train_loss: 0.09849921613931656\n",
      "39930 val_loss: 0.10583321005105972, train_loss: 0.10257606208324432\n",
      "39940 val_loss: 0.1037115678191185, train_loss: 0.10018240660429001\n",
      "39950 val_loss: 0.1018124595284462, train_loss: 0.1013108342885971\n",
      "39960 val_loss: 0.10016077011823654, train_loss: 0.09977325797080994\n",
      "39970 val_loss: 0.10327499359846115, train_loss: 0.10229498147964478\n",
      "39980 val_loss: 0.10093360394239426, train_loss: 0.0999046117067337\n",
      "39990 val_loss: 0.10399243235588074, train_loss: 0.10041201859712601\n",
      "40000 val_loss: 0.10155842453241348, train_loss: 0.0982445701956749\n",
      "40010 val_loss: 0.09887019544839859, train_loss: 0.09812282025814056\n",
      "40020 val_loss: 0.10511055588722229, train_loss: 0.1030169129371643\n",
      "40030 val_loss: 0.108406201004982, train_loss: 0.10533782839775085\n",
      "40040 val_loss: 0.10374730080366135, train_loss: 0.10209792107343674\n",
      "40050 val_loss: 0.09971270710229874, train_loss: 0.09704982489347458\n",
      "40060 val_loss: 0.09897150844335556, train_loss: 0.09747850149869919\n",
      "40070 val_loss: 0.10505785793066025, train_loss: 0.1024339571595192\n",
      "40080 val_loss: 0.09970656037330627, train_loss: 0.09705466032028198\n",
      "40090 val_loss: 0.10596348345279694, train_loss: 0.10222405195236206\n",
      "40100 val_loss: 0.102748341858387, train_loss: 0.09892892092466354\n",
      "40110 val_loss: 0.1029401421546936, train_loss: 0.09906278550624847\n",
      "40120 val_loss: 0.09870652109384537, train_loss: 0.09566348791122437\n",
      "40130 val_loss: 0.09848066419363022, train_loss: 0.09590364992618561\n",
      "40140 val_loss: 0.10421590507030487, train_loss: 0.1027657762169838\n",
      "40150 val_loss: 0.11563453078269958, train_loss: 0.11477059870958328\n",
      "40160 val_loss: 0.11332669109106064, train_loss: 0.11440283060073853\n",
      "40170 val_loss: 0.09773413091897964, train_loss: 0.09781426936388016\n",
      "40180 val_loss: 0.09942077845335007, train_loss: 0.09771892428398132\n",
      "40190 val_loss: 0.10787122696638107, train_loss: 0.1069992333650589\n",
      "40200 val_loss: 0.1056659147143364, train_loss: 0.10566142946481705\n",
      "40210 val_loss: 0.10668440908193588, train_loss: 0.1066497191786766\n",
      "40220 val_loss: 0.09858037531375885, train_loss: 0.09603539109230042\n",
      "40230 val_loss: 0.10691752284765244, train_loss: 0.10598070919513702\n",
      "40240 val_loss: 0.10077342391014099, train_loss: 0.09697340428829193\n",
      "40250 val_loss: 0.09621655941009521, train_loss: 0.09628874808549881\n",
      "40260 val_loss: 0.10074027627706528, train_loss: 0.09754820168018341\n",
      "40270 val_loss: 0.09864312410354614, train_loss: 0.09568997472524643\n",
      "40280 val_loss: 0.10065783560276031, train_loss: 0.09838376194238663\n",
      "40290 val_loss: 0.09975840896368027, train_loss: 0.09953619539737701\n",
      "40300 val_loss: 0.10259056836366653, train_loss: 0.0996929183602333\n",
      "40310 val_loss: 0.09963538497686386, train_loss: 0.09765732288360596\n",
      "40320 val_loss: 0.09837698191404343, train_loss: 0.09646457433700562\n",
      "40330 val_loss: 0.10048101842403412, train_loss: 0.09978342801332474\n",
      "40340 val_loss: 0.09966351091861725, train_loss: 0.09931227564811707\n",
      "40350 val_loss: 0.09739714860916138, train_loss: 0.0954715758562088\n",
      "40360 val_loss: 0.1004721000790596, train_loss: 0.09647710621356964\n",
      "40370 val_loss: 0.10403633862733841, train_loss: 0.09973898530006409\n",
      "40380 val_loss: 0.10085699707269669, train_loss: 0.09775902330875397\n",
      "40390 val_loss: 0.09970349073410034, train_loss: 0.09634600579738617\n",
      "40400 val_loss: 0.10367263853549957, train_loss: 0.09857920557260513\n",
      "40410 val_loss: 0.09826921671628952, train_loss: 0.09458860009908676\n",
      "40420 val_loss: 0.09707474708557129, train_loss: 0.09444016963243484\n",
      "40430 val_loss: 0.09695568680763245, train_loss: 0.09576268494129181\n",
      "40440 val_loss: 0.10626115649938583, train_loss: 0.10291428864002228\n",
      "40450 val_loss: 0.09912491589784622, train_loss: 0.09730121493339539\n",
      "40460 val_loss: 0.0976286306977272, train_loss: 0.09708943217992783\n",
      "40470 val_loss: 0.09674815088510513, train_loss: 0.09495124220848083\n",
      "40480 val_loss: 0.09742775559425354, train_loss: 0.09635500609874725\n",
      "40490 val_loss: 0.09801784157752991, train_loss: 0.09533040970563889\n",
      "40500 val_loss: 0.10435936599969864, train_loss: 0.09986807405948639\n",
      "40510 val_loss: 0.09830532968044281, train_loss: 0.09497381746768951\n",
      "40520 val_loss: 0.1198960393667221, train_loss: 0.1156022846698761\n",
      "40530 val_loss: 0.1058037206530571, train_loss: 0.1059848815202713\n",
      "40540 val_loss: 0.09955596923828125, train_loss: 0.09849713742733002\n",
      "40550 val_loss: 0.09662383794784546, train_loss: 0.09497188031673431\n",
      "40560 val_loss: 0.10235487669706345, train_loss: 0.10031620413064957\n",
      "40570 val_loss: 0.13233543932437897, train_loss: 0.13362285494804382\n",
      "40580 val_loss: 0.11055818945169449, train_loss: 0.11175107210874557\n",
      "40590 val_loss: 0.09490905702114105, train_loss: 0.09341524541378021\n",
      "40600 val_loss: 0.11214890331029892, train_loss: 0.11225441098213196\n",
      "40610 val_loss: 0.09802838414907455, train_loss: 0.0956193059682846\n",
      "40620 val_loss: 0.09678672254085541, train_loss: 0.09380856156349182\n",
      "40630 val_loss: 0.09642937034368515, train_loss: 0.09593132138252258\n",
      "40640 val_loss: 0.09531400352716446, train_loss: 0.0937468409538269\n",
      "40650 val_loss: 0.10077474266290665, train_loss: 0.10061260312795639\n",
      "40660 val_loss: 0.10192573815584183, train_loss: 0.09610677510499954\n",
      "40670 val_loss: 0.09755829721689224, train_loss: 0.0947488322854042\n",
      "40680 val_loss: 0.09702298790216446, train_loss: 0.09518767148256302\n",
      "40690 val_loss: 0.09585265070199966, train_loss: 0.09331880509853363\n",
      "40700 val_loss: 0.09441458433866501, train_loss: 0.09395696222782135\n",
      "40710 val_loss: 0.09546007961034775, train_loss: 0.09437432140111923\n",
      "40720 val_loss: 0.09666518867015839, train_loss: 0.0953909382224083\n",
      "40730 val_loss: 0.11383869498968124, train_loss: 0.11082552373409271\n",
      "40740 val_loss: 0.11763234436511993, train_loss: 0.11681903898715973\n",
      "40750 val_loss: 0.09667227417230606, train_loss: 0.09434249252080917\n",
      "40760 val_loss: 0.10215549916028976, train_loss: 0.09942737966775894\n",
      "40770 val_loss: 0.10607414692640305, train_loss: 0.10642284899950027\n",
      "40780 val_loss: 0.10708333551883698, train_loss: 0.10495813935995102\n",
      "40790 val_loss: 0.09617770463228226, train_loss: 0.09390360116958618\n",
      "40800 val_loss: 0.09969492256641388, train_loss: 0.09724811464548111\n",
      "40810 val_loss: 0.10375414788722992, train_loss: 0.10323235392570496\n",
      "40820 val_loss: 0.09731941670179367, train_loss: 0.09489952027797699\n",
      "40830 val_loss: 0.10267012566328049, train_loss: 0.10057041794061661\n",
      "40840 val_loss: 0.10913071781396866, train_loss: 0.10623083263635635\n",
      "40850 val_loss: 0.11135648936033249, train_loss: 0.10617934167385101\n",
      "40860 val_loss: 0.09555210173130035, train_loss: 0.0927247405052185\n",
      "40870 val_loss: 0.12595953047275543, train_loss: 0.12186448276042938\n",
      "40880 val_loss: 0.13127031922340393, train_loss: 0.1281159520149231\n",
      "40890 val_loss: 0.0953330248594284, train_loss: 0.09545297175645828\n",
      "40900 val_loss: 0.09584134072065353, train_loss: 0.09372448921203613\n",
      "40910 val_loss: 0.094130739569664, train_loss: 0.09221191704273224\n",
      "40920 val_loss: 0.09804024547338486, train_loss: 0.09391871094703674\n",
      "40930 val_loss: 0.11024405807256699, train_loss: 0.10842572152614594\n",
      "40940 val_loss: 0.11846645176410675, train_loss: 0.1166643351316452\n",
      "40950 val_loss: 0.09800360351800919, train_loss: 0.09334421902894974\n",
      "40960 val_loss: 0.09930548071861267, train_loss: 0.09853679686784744\n",
      "40970 val_loss: 0.11608093976974487, train_loss: 0.11755770444869995\n",
      "40980 val_loss: 0.09300548583269119, train_loss: 0.09270036220550537\n",
      "40990 val_loss: 0.09786845743656158, train_loss: 0.0954132229089737\n",
      "41000 val_loss: 0.10155414044857025, train_loss: 0.09727907180786133\n",
      "41010 val_loss: 0.11973836272954941, train_loss: 0.11872058361768723\n",
      "41020 val_loss: 0.09569215774536133, train_loss: 0.094310462474823\n",
      "41030 val_loss: 0.09880199283361435, train_loss: 0.0943814292550087\n",
      "41040 val_loss: 0.09884053468704224, train_loss: 0.09645040333271027\n",
      "41050 val_loss: 0.10299184173345566, train_loss: 0.0987834557890892\n",
      "41060 val_loss: 0.0996580570936203, train_loss: 0.09810730069875717\n",
      "41070 val_loss: 0.10631335526704788, train_loss: 0.10671402513980865\n",
      "41080 val_loss: 0.09438243508338928, train_loss: 0.09140153229236603\n",
      "41090 val_loss: 0.0963100790977478, train_loss: 0.09456408023834229\n",
      "41100 val_loss: 0.11133567988872528, train_loss: 0.10991816222667694\n",
      "41110 val_loss: 0.10185826569795609, train_loss: 0.0974140390753746\n",
      "41120 val_loss: 0.1075325608253479, train_loss: 0.10549359768629074\n",
      "41130 val_loss: 0.11393211036920547, train_loss: 0.11266905814409256\n",
      "41140 val_loss: 0.09392466396093369, train_loss: 0.09232411533594131\n",
      "41150 val_loss: 0.09536895900964737, train_loss: 0.09585785865783691\n",
      "41160 val_loss: 0.0965353474020958, train_loss: 0.09495184570550919\n",
      "41170 val_loss: 0.0959014967083931, train_loss: 0.09635300934314728\n",
      "41180 val_loss: 0.09279055893421173, train_loss: 0.09184304624795914\n",
      "41190 val_loss: 0.10034407675266266, train_loss: 0.09658295661211014\n",
      "41200 val_loss: 0.09111759811639786, train_loss: 0.09055580198764801\n",
      "41210 val_loss: 0.09796833246946335, train_loss: 0.09498798847198486\n",
      "41220 val_loss: 0.09158970415592194, train_loss: 0.09165960550308228\n",
      "41230 val_loss: 0.0919816792011261, train_loss: 0.0928821861743927\n",
      "41240 val_loss: 0.10038652271032333, train_loss: 0.0997110977768898\n",
      "41250 val_loss: 0.09197914600372314, train_loss: 0.09055846929550171\n",
      "41260 val_loss: 0.09762980788946152, train_loss: 0.09359939396381378\n",
      "41270 val_loss: 0.10601450502872467, train_loss: 0.10248325765132904\n",
      "41280 val_loss: 0.09485919028520584, train_loss: 0.09272903949022293\n",
      "41290 val_loss: 0.0930105522274971, train_loss: 0.09072749316692352\n",
      "41300 val_loss: 0.0937640368938446, train_loss: 0.09054950624704361\n",
      "41310 val_loss: 0.10747446864843369, train_loss: 0.10146832466125488\n",
      "41320 val_loss: 0.09434088319540024, train_loss: 0.09153365343809128\n",
      "41330 val_loss: 0.09472063183784485, train_loss: 0.09080276638269424\n",
      "41340 val_loss: 0.09398216754198074, train_loss: 0.09121157974004745\n",
      "41350 val_loss: 0.09457327425479889, train_loss: 0.09359945356845856\n",
      "41360 val_loss: 0.11194053292274475, train_loss: 0.10774044692516327\n",
      "41370 val_loss: 0.09866698086261749, train_loss: 0.09247636795043945\n",
      "41380 val_loss: 0.09487784653902054, train_loss: 0.09066054970026016\n",
      "41390 val_loss: 0.09276869893074036, train_loss: 0.09044735878705978\n",
      "41400 val_loss: 0.10994333773851395, train_loss: 0.10632907599210739\n",
      "41410 val_loss: 0.09916350990533829, train_loss: 0.09659218043088913\n",
      "41420 val_loss: 0.096729576587677, train_loss: 0.09583283960819244\n",
      "41430 val_loss: 0.09091676026582718, train_loss: 0.0887853279709816\n",
      "41440 val_loss: 0.10826396942138672, train_loss: 0.10564935952425003\n",
      "41450 val_loss: 0.09209831058979034, train_loss: 0.08884858340024948\n",
      "41460 val_loss: 0.09093181043863297, train_loss: 0.08857645094394684\n",
      "41470 val_loss: 0.09359793365001678, train_loss: 0.08947008103132248\n",
      "41480 val_loss: 0.09260588884353638, train_loss: 0.08949998021125793\n",
      "41490 val_loss: 0.09599904716014862, train_loss: 0.09227479249238968\n",
      "41500 val_loss: 0.09311392903327942, train_loss: 0.08910948783159256\n",
      "41510 val_loss: 0.0950608104467392, train_loss: 0.09194747358560562\n",
      "41520 val_loss: 0.09299881011247635, train_loss: 0.09045885503292084\n",
      "41530 val_loss: 0.0936356633901596, train_loss: 0.08974025398492813\n",
      "41540 val_loss: 0.09615997225046158, train_loss: 0.09631576389074326\n",
      "41550 val_loss: 0.08994666486978531, train_loss: 0.0890062153339386\n",
      "41560 val_loss: 0.10716009885072708, train_loss: 0.10213658213615417\n",
      "41570 val_loss: 0.10073697566986084, train_loss: 0.09484955668449402\n",
      "41580 val_loss: 0.09164117276668549, train_loss: 0.08954135328531265\n",
      "41590 val_loss: 0.09108632057905197, train_loss: 0.08813509345054626\n",
      "41600 val_loss: 0.10271944105625153, train_loss: 0.09899769723415375\n",
      "41610 val_loss: 0.09533516317605972, train_loss: 0.09041529148817062\n",
      "41620 val_loss: 0.09258673340082169, train_loss: 0.08883775025606155\n",
      "41630 val_loss: 0.10044081509113312, train_loss: 0.09915832430124283\n",
      "41640 val_loss: 0.09946726262569427, train_loss: 0.09491227567195892\n",
      "41650 val_loss: 0.09345701336860657, train_loss: 0.08893696963787079\n",
      "41660 val_loss: 0.10059893131256104, train_loss: 0.09569825232028961\n",
      "41670 val_loss: 0.09962021559476852, train_loss: 0.09493895620107651\n",
      "41680 val_loss: 0.0915512889623642, train_loss: 0.08958014100790024\n",
      "41690 val_loss: 0.10253667086362839, train_loss: 0.10087668150663376\n",
      "41700 val_loss: 0.09382172673940659, train_loss: 0.09097123146057129\n",
      "41710 val_loss: 0.09569941461086273, train_loss: 0.09000272303819656\n",
      "41720 val_loss: 0.09006968140602112, train_loss: 0.08775191754102707\n",
      "41730 val_loss: 0.10190194845199585, train_loss: 0.10257633030414581\n",
      "41740 val_loss: 0.10482771694660187, train_loss: 0.09958037734031677\n",
      "41750 val_loss: 0.08910776674747467, train_loss: 0.08674709498882294\n",
      "41760 val_loss: 0.10657883435487747, train_loss: 0.10010585188865662\n",
      "41770 val_loss: 0.09419727325439453, train_loss: 0.08863711357116699\n",
      "41780 val_loss: 0.09291569143533707, train_loss: 0.0878761038184166\n",
      "41790 val_loss: 0.09657590836286545, train_loss: 0.09649738669395447\n",
      "41800 val_loss: 0.09239224344491959, train_loss: 0.08855459839105606\n",
      "41810 val_loss: 0.09738031774759293, train_loss: 0.09290318191051483\n",
      "41820 val_loss: 0.09568967670202255, train_loss: 0.09085037559270859\n",
      "41830 val_loss: 0.09648904204368591, train_loss: 0.09150189161300659\n",
      "41840 val_loss: 0.09685085713863373, train_loss: 0.09098932892084122\n",
      "41850 val_loss: 0.09715557098388672, train_loss: 0.09370804578065872\n",
      "41860 val_loss: 0.09406771510839462, train_loss: 0.0937492847442627\n",
      "41870 val_loss: 0.08940385282039642, train_loss: 0.08635114133358002\n",
      "41880 val_loss: 0.08930348604917526, train_loss: 0.08639785647392273\n",
      "41890 val_loss: 0.08979605883359909, train_loss: 0.08577577769756317\n",
      "41900 val_loss: 0.11021808534860611, train_loss: 0.10890886932611465\n",
      "41910 val_loss: 0.08881880342960358, train_loss: 0.08702129125595093\n",
      "41920 val_loss: 0.09706834703683853, train_loss: 0.09295884519815445\n",
      "41930 val_loss: 0.15589290857315063, train_loss: 0.15379159152507782\n",
      "41940 val_loss: 0.0945412889122963, train_loss: 0.09105069190263748\n",
      "41950 val_loss: 0.09536631405353546, train_loss: 0.0917704701423645\n",
      "41960 val_loss: 0.0896758958697319, train_loss: 0.08662768453359604\n",
      "41970 val_loss: 0.09044302254915237, train_loss: 0.08649171888828278\n",
      "41980 val_loss: 0.08810939639806747, train_loss: 0.08526097983121872\n",
      "41990 val_loss: 0.09282203018665314, train_loss: 0.08983352780342102\n",
      "42000 val_loss: 0.0971200168132782, train_loss: 0.09195560216903687\n",
      "42010 val_loss: 0.0990879014134407, train_loss: 0.0963231697678566\n",
      "42020 val_loss: 0.09516484290361404, train_loss: 0.09088926762342453\n",
      "42030 val_loss: 0.10036725550889969, train_loss: 0.09586873650550842\n",
      "42040 val_loss: 0.09059334546327591, train_loss: 0.08824388682842255\n",
      "42050 val_loss: 0.10554496943950653, train_loss: 0.10042242705821991\n",
      "42060 val_loss: 0.14860978722572327, train_loss: 0.14281557500362396\n",
      "42070 val_loss: 0.09192958474159241, train_loss: 0.09004376828670502\n",
      "42080 val_loss: 0.08934655785560608, train_loss: 0.08809179812669754\n",
      "42090 val_loss: 0.0937802717089653, train_loss: 0.08977510035037994\n",
      "42100 val_loss: 0.09117652475833893, train_loss: 0.09117406606674194\n",
      "42110 val_loss: 0.0985497459769249, train_loss: 0.09495939314365387\n",
      "42120 val_loss: 0.09407273679971695, train_loss: 0.09047244489192963\n",
      "42130 val_loss: 0.09095902740955353, train_loss: 0.08772708475589752\n",
      "42140 val_loss: 0.09849771112203598, train_loss: 0.09535662829875946\n",
      "42150 val_loss: 0.10475729405879974, train_loss: 0.10546837747097015\n",
      "42160 val_loss: 0.08844354003667831, train_loss: 0.08548007905483246\n",
      "42170 val_loss: 0.0954703763127327, train_loss: 0.09198646992444992\n",
      "42180 val_loss: 0.09614526480436325, train_loss: 0.09200167655944824\n",
      "42190 val_loss: 0.10988875478506088, train_loss: 0.10722756385803223\n",
      "42200 val_loss: 0.09775926917791367, train_loss: 0.09269396960735321\n",
      "42210 val_loss: 0.09489186853170395, train_loss: 0.0944632887840271\n",
      "42220 val_loss: 0.0974331945180893, train_loss: 0.09362304955720901\n",
      "42230 val_loss: 0.09162941575050354, train_loss: 0.08811965584754944\n",
      "42240 val_loss: 0.09160163253545761, train_loss: 0.08769916743040085\n",
      "42250 val_loss: 0.0934700146317482, train_loss: 0.08857420086860657\n",
      "42260 val_loss: 0.08758964389562607, train_loss: 0.08500804007053375\n",
      "42270 val_loss: 0.10018192231655121, train_loss: 0.09710737317800522\n",
      "42280 val_loss: 0.09168348461389542, train_loss: 0.08642381429672241\n",
      "42290 val_loss: 0.08796330541372299, train_loss: 0.08547995984554291\n",
      "42300 val_loss: 0.09012342244386673, train_loss: 0.08998963236808777\n",
      "42310 val_loss: 0.0886102169752121, train_loss: 0.0849379375576973\n",
      "42320 val_loss: 0.09795401990413666, train_loss: 0.09281229227781296\n",
      "42330 val_loss: 0.09390099346637726, train_loss: 0.09169800579547882\n",
      "42340 val_loss: 0.09056715667247772, train_loss: 0.08717197924852371\n",
      "42350 val_loss: 0.0921698585152626, train_loss: 0.08624114096164703\n",
      "42360 val_loss: 0.0888226181268692, train_loss: 0.0852934867143631\n",
      "42370 val_loss: 0.09229584038257599, train_loss: 0.08815960586071014\n",
      "42380 val_loss: 0.09050214290618896, train_loss: 0.08622296154499054\n",
      "42390 val_loss: 0.09120366722345352, train_loss: 0.0855797529220581\n",
      "42400 val_loss: 0.08899814635515213, train_loss: 0.08492349833250046\n",
      "42410 val_loss: 0.08908278495073318, train_loss: 0.08475837111473083\n",
      "42420 val_loss: 0.08945159614086151, train_loss: 0.08465676754713058\n",
      "42430 val_loss: 0.10811043530702591, train_loss: 0.1026649922132492\n",
      "42440 val_loss: 0.08899758011102676, train_loss: 0.0850645899772644\n",
      "42450 val_loss: 0.0914359763264656, train_loss: 0.08602817356586456\n",
      "42460 val_loss: 0.09832153469324112, train_loss: 0.09391546994447708\n",
      "42470 val_loss: 0.08755643665790558, train_loss: 0.08696155995130539\n",
      "42480 val_loss: 0.10391265153884888, train_loss: 0.10273858904838562\n",
      "42490 val_loss: 0.10671047121286392, train_loss: 0.10351066291332245\n",
      "42500 val_loss: 0.089655302464962, train_loss: 0.08729623258113861\n",
      "42510 val_loss: 0.11765685677528381, train_loss: 0.1165342926979065\n",
      "42520 val_loss: 0.10261400043964386, train_loss: 0.09711334109306335\n",
      "42530 val_loss: 0.08862906694412231, train_loss: 0.08470431715250015\n",
      "42540 val_loss: 0.08826930820941925, train_loss: 0.08367855101823807\n",
      "42550 val_loss: 0.09207891672849655, train_loss: 0.08596844226121902\n",
      "42560 val_loss: 0.09226538985967636, train_loss: 0.08892822265625\n",
      "42570 val_loss: 0.08609108626842499, train_loss: 0.08480792492628098\n",
      "42580 val_loss: 0.0890897586941719, train_loss: 0.08521951735019684\n",
      "42590 val_loss: 0.0888291597366333, train_loss: 0.08332105726003647\n",
      "42600 val_loss: 0.08988546580076218, train_loss: 0.08509499579668045\n",
      "42610 val_loss: 0.08971065282821655, train_loss: 0.08665516972541809\n",
      "42620 val_loss: 0.08822854608297348, train_loss: 0.0849236249923706\n",
      "42630 val_loss: 0.08991689234972, train_loss: 0.08525864779949188\n",
      "42640 val_loss: 0.09405865520238876, train_loss: 0.09361715614795685\n",
      "42650 val_loss: 0.0868443101644516, train_loss: 0.08262911438941956\n",
      "42660 val_loss: 0.09122540056705475, train_loss: 0.08840014040470123\n",
      "42670 val_loss: 0.09029223769903183, train_loss: 0.08570291846990585\n",
      "42680 val_loss: 0.08512140810489655, train_loss: 0.08196552097797394\n",
      "42690 val_loss: 0.10193255543708801, train_loss: 0.09774964302778244\n",
      "42700 val_loss: 0.09631116688251495, train_loss: 0.09661302715539932\n",
      "42710 val_loss: 0.0890527069568634, train_loss: 0.08432537317276001\n",
      "42720 val_loss: 0.0901920348405838, train_loss: 0.0848127231001854\n",
      "42730 val_loss: 0.1036888137459755, train_loss: 0.09924516081809998\n",
      "42740 val_loss: 0.08732185512781143, train_loss: 0.08217885345220566\n",
      "42750 val_loss: 0.08798098564147949, train_loss: 0.08415284007787704\n",
      "42760 val_loss: 0.08600959926843643, train_loss: 0.08166257292032242\n",
      "42770 val_loss: 0.08955680578947067, train_loss: 0.08518056571483612\n",
      "42780 val_loss: 0.1052127406001091, train_loss: 0.1046835333108902\n",
      "42790 val_loss: 0.09630822390317917, train_loss: 0.09000173211097717\n",
      "42800 val_loss: 0.09432588517665863, train_loss: 0.08950968831777573\n",
      "42810 val_loss: 0.09391529113054276, train_loss: 0.08937449753284454\n",
      "42820 val_loss: 0.09735290706157684, train_loss: 0.09358808398246765\n",
      "42830 val_loss: 0.08398256450891495, train_loss: 0.08299322426319122\n",
      "42840 val_loss: 0.08321304619312286, train_loss: 0.0820687934756279\n",
      "42850 val_loss: 0.09628338366746902, train_loss: 0.09571204334497452\n",
      "42860 val_loss: 0.09831562638282776, train_loss: 0.09274277836084366\n",
      "42870 val_loss: 0.09752971678972244, train_loss: 0.09415561705827713\n",
      "42880 val_loss: 0.08906446397304535, train_loss: 0.08895250409841537\n",
      "42890 val_loss: 0.0905974954366684, train_loss: 0.08606088161468506\n",
      "42900 val_loss: 0.09024439752101898, train_loss: 0.08624722808599472\n",
      "42910 val_loss: 0.0910472422838211, train_loss: 0.09005880355834961\n",
      "42920 val_loss: 0.1788882613182068, train_loss: 0.17752818763256073\n",
      "42930 val_loss: 0.08491426706314087, train_loss: 0.08256813138723373\n",
      "42940 val_loss: 0.09084522724151611, train_loss: 0.08753357082605362\n",
      "42950 val_loss: 0.0842735767364502, train_loss: 0.08143872022628784\n",
      "42960 val_loss: 0.1109626442193985, train_loss: 0.10629048198461533\n",
      "42970 val_loss: 0.08622954040765762, train_loss: 0.08246216177940369\n",
      "42980 val_loss: 0.0892239585518837, train_loss: 0.08648774027824402\n",
      "42990 val_loss: 0.08319000154733658, train_loss: 0.08280380815267563\n",
      "43000 val_loss: 0.0950256735086441, train_loss: 0.09199213236570358\n",
      "43010 val_loss: 0.08356216549873352, train_loss: 0.08176577836275101\n",
      "43020 val_loss: 0.08800534904003143, train_loss: 0.08526044338941574\n",
      "43030 val_loss: 0.0923655778169632, train_loss: 0.08633130043745041\n",
      "43040 val_loss: 0.09214993566274643, train_loss: 0.08718579262495041\n",
      "43050 val_loss: 0.0944632738828659, train_loss: 0.08968661725521088\n",
      "43060 val_loss: 0.09333989769220352, train_loss: 0.08963663876056671\n",
      "43070 val_loss: 0.08833075314760208, train_loss: 0.08338617533445358\n",
      "43080 val_loss: 0.11762769520282745, train_loss: 0.11379217356443405\n",
      "43090 val_loss: 0.08571096509695053, train_loss: 0.08120957016944885\n",
      "43100 val_loss: 0.09752264618873596, train_loss: 0.09435601532459259\n",
      "43110 val_loss: 0.08563827723264694, train_loss: 0.08302078396081924\n",
      "43120 val_loss: 0.08727925270795822, train_loss: 0.0839807465672493\n",
      "43130 val_loss: 0.08392364531755447, train_loss: 0.08416840434074402\n",
      "43140 val_loss: 0.09063437581062317, train_loss: 0.08692512661218643\n",
      "43150 val_loss: 0.08444193005561829, train_loss: 0.08330252766609192\n",
      "43160 val_loss: 0.0934731513261795, train_loss: 0.08900654315948486\n",
      "43170 val_loss: 0.08309362083673477, train_loss: 0.08248867094516754\n",
      "43180 val_loss: 0.08962662518024445, train_loss: 0.08793452382087708\n",
      "43190 val_loss: 0.08712483942508698, train_loss: 0.08536643534898758\n",
      "43200 val_loss: 0.09035427123308182, train_loss: 0.08681675791740417\n",
      "43210 val_loss: 0.08967996388673782, train_loss: 0.08393252640962601\n",
      "43220 val_loss: 0.10443115234375, train_loss: 0.1038946583867073\n",
      "43230 val_loss: 0.08774226158857346, train_loss: 0.08373086899518967\n",
      "43240 val_loss: 0.08821476250886917, train_loss: 0.08327031880617142\n",
      "43250 val_loss: 0.08696603029966354, train_loss: 0.08357682824134827\n",
      "43260 val_loss: 0.08620654046535492, train_loss: 0.08123579621315002\n",
      "43270 val_loss: 0.09491371363401413, train_loss: 0.0898490697145462\n",
      "43280 val_loss: 0.08681512624025345, train_loss: 0.08240456134080887\n",
      "43290 val_loss: 0.0960434228181839, train_loss: 0.08970801532268524\n",
      "43300 val_loss: 0.08526159077882767, train_loss: 0.0806119292974472\n",
      "43310 val_loss: 0.08708903193473816, train_loss: 0.08185283839702606\n",
      "43320 val_loss: 0.08271578699350357, train_loss: 0.08102474361658096\n",
      "43330 val_loss: 0.08792509883642197, train_loss: 0.08381786942481995\n",
      "43340 val_loss: 0.08672767132520676, train_loss: 0.08573026210069656\n",
      "43350 val_loss: 0.09055659919977188, train_loss: 0.08667968958616257\n",
      "43360 val_loss: 0.10420006513595581, train_loss: 0.09944388270378113\n",
      "43370 val_loss: 0.08915131539106369, train_loss: 0.08910804986953735\n",
      "43380 val_loss: 0.09262844175100327, train_loss: 0.09427937865257263\n",
      "43390 val_loss: 0.0920679122209549, train_loss: 0.08767303824424744\n",
      "43400 val_loss: 0.0899694636464119, train_loss: 0.08521023392677307\n",
      "43410 val_loss: 0.09354088455438614, train_loss: 0.09149813652038574\n",
      "43420 val_loss: 0.08246998488903046, train_loss: 0.08009681105613708\n",
      "43430 val_loss: 0.09138201922178268, train_loss: 0.09151270985603333\n",
      "43440 val_loss: 0.10398490726947784, train_loss: 0.09965484589338303\n",
      "43450 val_loss: 0.08503679186105728, train_loss: 0.07951773703098297\n",
      "43460 val_loss: 0.08492530137300491, train_loss: 0.08059078454971313\n",
      "43470 val_loss: 0.08784931153059006, train_loss: 0.08376552164554596\n",
      "43480 val_loss: 0.08958817273378372, train_loss: 0.08706074953079224\n",
      "43490 val_loss: 0.08454243093729019, train_loss: 0.08041393756866455\n",
      "43500 val_loss: 0.09637950360774994, train_loss: 0.09008488804101944\n",
      "43510 val_loss: 0.08937924355268478, train_loss: 0.08797771483659744\n",
      "43520 val_loss: 0.08424916863441467, train_loss: 0.07957175374031067\n",
      "43530 val_loss: 0.08619483560323715, train_loss: 0.08036810904741287\n",
      "43540 val_loss: 0.0984506830573082, train_loss: 0.09400586783885956\n",
      "43550 val_loss: 0.08304457366466522, train_loss: 0.07839738577604294\n",
      "43560 val_loss: 0.08698830008506775, train_loss: 0.08476437628269196\n",
      "43570 val_loss: 0.08142831176519394, train_loss: 0.07943326234817505\n",
      "43580 val_loss: 0.08337100595235825, train_loss: 0.07933052629232407\n",
      "43590 val_loss: 0.09436031430959702, train_loss: 0.09180561453104019\n",
      "43600 val_loss: 0.09357812255620956, train_loss: 0.08747085928916931\n",
      "43610 val_loss: 0.08417593687772751, train_loss: 0.07900699973106384\n",
      "43620 val_loss: 0.09372852742671967, train_loss: 0.08787399530410767\n",
      "43630 val_loss: 0.09012606739997864, train_loss: 0.08609319478273392\n",
      "43640 val_loss: 0.0812433660030365, train_loss: 0.07986948639154434\n",
      "43650 val_loss: 0.08444979041814804, train_loss: 0.07963693141937256\n",
      "43660 val_loss: 0.08343151956796646, train_loss: 0.07902087271213531\n",
      "43670 val_loss: 0.08644933998584747, train_loss: 0.08140726387500763\n",
      "43680 val_loss: 0.08846620470285416, train_loss: 0.08257235586643219\n",
      "43690 val_loss: 0.09003851562738419, train_loss: 0.0897144004702568\n",
      "43700 val_loss: 0.0853702500462532, train_loss: 0.08223960548639297\n",
      "43710 val_loss: 0.08148019015789032, train_loss: 0.07881439477205276\n",
      "43720 val_loss: 0.08596629649400711, train_loss: 0.08524330705404282\n",
      "43730 val_loss: 0.09327621757984161, train_loss: 0.0911695659160614\n",
      "43740 val_loss: 0.08409027755260468, train_loss: 0.08017811924219131\n",
      "43750 val_loss: 0.08235502988100052, train_loss: 0.078513965010643\n",
      "43760 val_loss: 0.08560657501220703, train_loss: 0.08326500654220581\n",
      "43770 val_loss: 0.09457531571388245, train_loss: 0.09026443213224411\n",
      "43780 val_loss: 0.08276568353176117, train_loss: 0.07944153994321823\n",
      "43790 val_loss: 0.08458957821130753, train_loss: 0.08010417222976685\n",
      "43800 val_loss: 0.09479881078004837, train_loss: 0.09112977236509323\n",
      "43810 val_loss: 0.08410965651273727, train_loss: 0.08151550590991974\n",
      "43820 val_loss: 0.08234075456857681, train_loss: 0.08078818768262863\n",
      "43830 val_loss: 0.08870293945074081, train_loss: 0.08368932455778122\n",
      "43840 val_loss: 0.08525949716567993, train_loss: 0.0830288752913475\n",
      "43850 val_loss: 0.08308687061071396, train_loss: 0.08121076226234436\n",
      "43860 val_loss: 0.08471084386110306, train_loss: 0.08104052394628525\n",
      "43870 val_loss: 0.08284889906644821, train_loss: 0.08138611167669296\n",
      "43880 val_loss: 0.08316905051469803, train_loss: 0.07986190170049667\n",
      "43890 val_loss: 0.09338098019361496, train_loss: 0.09150911122560501\n",
      "43900 val_loss: 0.08294330537319183, train_loss: 0.07982365041971207\n",
      "43910 val_loss: 0.0931708812713623, train_loss: 0.08833435922861099\n",
      "43920 val_loss: 0.08316785842180252, train_loss: 0.08270388096570969\n",
      "43930 val_loss: 0.08334051817655563, train_loss: 0.07849705219268799\n",
      "43940 val_loss: 0.081544890999794, train_loss: 0.0780109390616417\n",
      "43950 val_loss: 0.08486796915531158, train_loss: 0.07928980141878128\n",
      "43960 val_loss: 0.0816395953297615, train_loss: 0.07797355949878693\n",
      "43970 val_loss: 0.08349166810512543, train_loss: 0.07901748269796371\n",
      "43980 val_loss: 0.08991123735904694, train_loss: 0.0879381075501442\n",
      "43990 val_loss: 0.08277682214975357, train_loss: 0.0788724422454834\n",
      "44000 val_loss: 0.08155499398708344, train_loss: 0.07787808775901794\n",
      "44010 val_loss: 0.08569970726966858, train_loss: 0.081325463950634\n",
      "44020 val_loss: 0.08782298117876053, train_loss: 0.08547035604715347\n",
      "44030 val_loss: 0.08125299215316772, train_loss: 0.07885345816612244\n",
      "44040 val_loss: 0.08901971578598022, train_loss: 0.08684270083904266\n",
      "44050 val_loss: 0.08651817589998245, train_loss: 0.08166533708572388\n",
      "44060 val_loss: 0.08547119796276093, train_loss: 0.08089450001716614\n",
      "44070 val_loss: 0.09810560941696167, train_loss: 0.09430847316980362\n",
      "44080 val_loss: 0.08613552153110504, train_loss: 0.0804283395409584\n",
      "44090 val_loss: 0.08578137308359146, train_loss: 0.08186236768960953\n",
      "44100 val_loss: 0.32896527647972107, train_loss: 0.31902170181274414\n",
      "44110 val_loss: 0.08356867730617523, train_loss: 0.08031477779150009\n",
      "44120 val_loss: 0.09273319691419601, train_loss: 0.08995155245065689\n",
      "44130 val_loss: 0.08558588474988937, train_loss: 0.08033762872219086\n",
      "44140 val_loss: 0.0841311365365982, train_loss: 0.08016788214445114\n",
      "44150 val_loss: 0.08170606195926666, train_loss: 0.07923182100057602\n",
      "44160 val_loss: 0.09011152386665344, train_loss: 0.08756804466247559\n",
      "44170 val_loss: 0.0907377079129219, train_loss: 0.08539554476737976\n",
      "44180 val_loss: 0.09056450426578522, train_loss: 0.08733069896697998\n",
      "44190 val_loss: 0.0966143012046814, train_loss: 0.09081744402647018\n",
      "44200 val_loss: 0.10664582997560501, train_loss: 0.10189773142337799\n",
      "44210 val_loss: 0.08198016881942749, train_loss: 0.07738089561462402\n",
      "44220 val_loss: 0.08467091619968414, train_loss: 0.08336818963289261\n",
      "44230 val_loss: 0.0804857686161995, train_loss: 0.07993504405021667\n",
      "44240 val_loss: 0.08716504275798798, train_loss: 0.08333650976419449\n",
      "44250 val_loss: 0.09286913275718689, train_loss: 0.08888625353574753\n",
      "44260 val_loss: 0.08001326769590378, train_loss: 0.07773123681545258\n",
      "44270 val_loss: 0.08464685082435608, train_loss: 0.07910328358411789\n",
      "44280 val_loss: 0.07969980686903, train_loss: 0.07759382575750351\n",
      "44290 val_loss: 0.0854276642203331, train_loss: 0.08083797246217728\n",
      "44300 val_loss: 0.08026161044836044, train_loss: 0.07884683459997177\n",
      "44310 val_loss: 0.07998593151569366, train_loss: 0.07664864510297775\n",
      "44320 val_loss: 0.08323503285646439, train_loss: 0.07760065793991089\n",
      "44330 val_loss: 0.08455191552639008, train_loss: 0.08067894726991653\n",
      "44340 val_loss: 0.08169160783290863, train_loss: 0.07936806231737137\n",
      "44350 val_loss: 0.08844632655382156, train_loss: 0.08401425927877426\n",
      "44360 val_loss: 0.09252399951219559, train_loss: 0.08790379017591476\n",
      "44370 val_loss: 0.08367206156253815, train_loss: 0.0799293965101242\n",
      "44380 val_loss: 0.08325082063674927, train_loss: 0.08259319514036179\n",
      "44390 val_loss: 0.07991313934326172, train_loss: 0.07863549888134003\n",
      "44400 val_loss: 0.0868656188249588, train_loss: 0.08532167971134186\n",
      "44410 val_loss: 0.09995350986719131, train_loss: 0.09727831184864044\n",
      "44420 val_loss: 0.07987887412309647, train_loss: 0.07931646704673767\n",
      "44430 val_loss: 0.08471857011318207, train_loss: 0.07878343015909195\n",
      "44440 val_loss: 0.0854310542345047, train_loss: 0.08235010504722595\n",
      "44450 val_loss: 0.08141326904296875, train_loss: 0.07792729884386063\n",
      "44460 val_loss: 0.08100222051143646, train_loss: 0.0799156054854393\n",
      "44470 val_loss: 0.08641523122787476, train_loss: 0.08256751298904419\n",
      "44480 val_loss: 0.08459669351577759, train_loss: 0.08510982990264893\n",
      "44490 val_loss: 0.08791626244783401, train_loss: 0.08270413428544998\n",
      "44500 val_loss: 0.09957172721624374, train_loss: 0.09526445716619492\n",
      "44510 val_loss: 0.09131403267383575, train_loss: 0.0853288546204567\n",
      "44520 val_loss: 0.09552614390850067, train_loss: 0.09348446130752563\n",
      "44530 val_loss: 0.08363241702318192, train_loss: 0.07845462113618851\n",
      "44540 val_loss: 0.10240858793258667, train_loss: 0.1008535847067833\n",
      "44550 val_loss: 0.08781252056360245, train_loss: 0.08403756469488144\n",
      "44560 val_loss: 0.08538881689310074, train_loss: 0.08052168786525726\n",
      "44570 val_loss: 0.07890509068965912, train_loss: 0.07605583965778351\n",
      "44580 val_loss: 0.08645134419202805, train_loss: 0.08344187587499619\n",
      "44590 val_loss: 0.08002202212810516, train_loss: 0.07665365934371948\n",
      "44600 val_loss: 0.08923978358507156, train_loss: 0.08413685113191605\n",
      "44610 val_loss: 0.09728089720010757, train_loss: 0.09741906076669693\n",
      "44620 val_loss: 0.09006344527006149, train_loss: 0.08613608777523041\n",
      "44630 val_loss: 0.07911927998065948, train_loss: 0.07695049792528152\n",
      "44640 val_loss: 0.08169159293174744, train_loss: 0.0764111876487732\n",
      "44650 val_loss: 0.08267924189567566, train_loss: 0.07754520326852798\n",
      "44660 val_loss: 0.0856657475233078, train_loss: 0.07856006175279617\n",
      "44670 val_loss: 0.08234091848134995, train_loss: 0.07900292426347733\n",
      "44680 val_loss: 0.08313050866127014, train_loss: 0.0828159898519516\n",
      "44690 val_loss: 0.08128577470779419, train_loss: 0.07635501772165298\n",
      "44700 val_loss: 0.0804869532585144, train_loss: 0.07718074321746826\n",
      "44710 val_loss: 0.09327910095453262, train_loss: 0.09497560560703278\n",
      "44720 val_loss: 0.08091139793395996, train_loss: 0.07583673298358917\n",
      "44730 val_loss: 0.08030783385038376, train_loss: 0.07750861346721649\n",
      "44740 val_loss: 0.07884605973958969, train_loss: 0.07706980407238007\n",
      "44750 val_loss: 0.08693123608827591, train_loss: 0.08115509897470474\n",
      "44760 val_loss: 0.07943294942378998, train_loss: 0.07564646005630493\n",
      "44770 val_loss: 0.07900527119636536, train_loss: 0.07757936418056488\n",
      "44780 val_loss: 0.08675292134284973, train_loss: 0.08241444826126099\n",
      "44790 val_loss: 0.08298094570636749, train_loss: 0.08027899265289307\n",
      "44800 val_loss: 0.0889071449637413, train_loss: 0.08425267040729523\n",
      "44810 val_loss: 0.07931477576494217, train_loss: 0.07767103612422943\n",
      "44820 val_loss: 0.08634506165981293, train_loss: 0.08431291580200195\n",
      "44830 val_loss: 0.08751990646123886, train_loss: 0.08538925647735596\n",
      "44840 val_loss: 0.08652693778276443, train_loss: 0.08284062147140503\n",
      "44850 val_loss: 0.08309494704008102, train_loss: 0.08004561811685562\n",
      "44860 val_loss: 0.08213592320680618, train_loss: 0.07680504769086838\n",
      "44870 val_loss: 0.08026835322380066, train_loss: 0.07613838464021683\n",
      "44880 val_loss: 0.08272553235292435, train_loss: 0.07935013622045517\n",
      "44890 val_loss: 0.08645494282245636, train_loss: 0.08414662629365921\n",
      "44900 val_loss: 0.0784948542714119, train_loss: 0.07601440697908401\n",
      "44910 val_loss: 0.08176802843809128, train_loss: 0.07706797868013382\n",
      "44920 val_loss: 0.07796996831893921, train_loss: 0.07468221336603165\n",
      "44930 val_loss: 0.08054617047309875, train_loss: 0.07792511582374573\n",
      "44940 val_loss: 0.09660497307777405, train_loss: 0.09750092774629593\n",
      "44950 val_loss: 0.07937493175268173, train_loss: 0.07737108319997787\n",
      "44960 val_loss: 0.07943692803382874, train_loss: 0.07619418948888779\n",
      "44970 val_loss: 0.08005303144454956, train_loss: 0.0781097561120987\n",
      "44980 val_loss: 0.08466728776693344, train_loss: 0.08320604264736176\n",
      "44990 val_loss: 0.08651908487081528, train_loss: 0.08581692725419998\n",
      "45000 val_loss: 0.0963674932718277, train_loss: 0.09418818354606628\n",
      "45010 val_loss: 0.08045031875371933, train_loss: 0.07687099277973175\n",
      "45020 val_loss: 0.08324587345123291, train_loss: 0.08132585883140564\n",
      "45030 val_loss: 0.0851401686668396, train_loss: 0.08149915933609009\n",
      "45040 val_loss: 0.0837869867682457, train_loss: 0.07920105010271072\n",
      "45050 val_loss: 0.0815737247467041, train_loss: 0.07572455704212189\n",
      "45060 val_loss: 0.08060535788536072, train_loss: 0.07629754394292831\n",
      "45070 val_loss: 0.08047422021627426, train_loss: 0.07493032515048981\n",
      "45080 val_loss: 0.08611366897821426, train_loss: 0.0820588693022728\n",
      "45090 val_loss: 0.08394204825162888, train_loss: 0.07741434872150421\n",
      "45100 val_loss: 0.08207514137029648, train_loss: 0.07659702748060226\n",
      "45110 val_loss: 0.0842876210808754, train_loss: 0.08094187825918198\n",
      "45120 val_loss: 0.08048813045024872, train_loss: 0.07554955780506134\n",
      "45130 val_loss: 0.10603547096252441, train_loss: 0.10307708382606506\n",
      "45140 val_loss: 0.09478157758712769, train_loss: 0.09133578836917877\n",
      "45150 val_loss: 0.09372483193874359, train_loss: 0.0879477858543396\n",
      "45160 val_loss: 0.08052778989076614, train_loss: 0.07536821812391281\n",
      "45170 val_loss: 0.07989215850830078, train_loss: 0.07499115914106369\n",
      "45180 val_loss: 0.147248774766922, train_loss: 0.14523278176784515\n",
      "45190 val_loss: 0.08906780183315277, train_loss: 0.08518490940332413\n",
      "45200 val_loss: 0.08494323492050171, train_loss: 0.08095800131559372\n",
      "45210 val_loss: 0.08486692607402802, train_loss: 0.0806032195687294\n",
      "45220 val_loss: 0.07708904147148132, train_loss: 0.07485686242580414\n",
      "45230 val_loss: 0.08671090751886368, train_loss: 0.08260282874107361\n",
      "45240 val_loss: 0.07934772968292236, train_loss: 0.07516975700855255\n",
      "45250 val_loss: 0.07956942915916443, train_loss: 0.07612582296133041\n",
      "45260 val_loss: 0.0775485709309578, train_loss: 0.07447721064090729\n",
      "45270 val_loss: 0.07762183994054794, train_loss: 0.07505199313163757\n",
      "45280 val_loss: 0.08096524327993393, train_loss: 0.07620905339717865\n",
      "45290 val_loss: 0.08067137748003006, train_loss: 0.07569209486246109\n",
      "45300 val_loss: 0.08340581506490707, train_loss: 0.08068007230758667\n",
      "45310 val_loss: 0.08238980919122696, train_loss: 0.07989860326051712\n",
      "45320 val_loss: 0.0895916149020195, train_loss: 0.08625389635562897\n",
      "45330 val_loss: 0.08814634382724762, train_loss: 0.08320698142051697\n",
      "45340 val_loss: 0.09544222801923752, train_loss: 0.09324079006910324\n",
      "45350 val_loss: 0.08731507509946823, train_loss: 0.08671872317790985\n",
      "45360 val_loss: 0.0809113159775734, train_loss: 0.07632484287023544\n",
      "45370 val_loss: 0.08697595447301865, train_loss: 0.08245795220136642\n",
      "45380 val_loss: 0.0830804631114006, train_loss: 0.07786454260349274\n",
      "45390 val_loss: 0.0807327851653099, train_loss: 0.0760093480348587\n",
      "45400 val_loss: 0.07750866562128067, train_loss: 0.07616817951202393\n",
      "45410 val_loss: 0.1455562561750412, train_loss: 0.1457168459892273\n",
      "45420 val_loss: 0.08030200004577637, train_loss: 0.07682882249355316\n",
      "45430 val_loss: 0.095087431371212, train_loss: 0.0942986011505127\n",
      "45440 val_loss: 0.07872021198272705, train_loss: 0.07656046003103256\n",
      "45450 val_loss: 0.07782141864299774, train_loss: 0.07586690783500671\n",
      "45460 val_loss: 0.08796349912881851, train_loss: 0.08389952778816223\n",
      "45470 val_loss: 0.08039765805006027, train_loss: 0.07696496695280075\n",
      "45480 val_loss: 0.08749420195817947, train_loss: 0.08389649540185928\n",
      "45490 val_loss: 0.07737630605697632, train_loss: 0.07523171603679657\n",
      "45500 val_loss: 0.07862246036529541, train_loss: 0.0746607854962349\n",
      "45510 val_loss: 0.079752117395401, train_loss: 0.0782214030623436\n",
      "45520 val_loss: 0.10087335109710693, train_loss: 0.10131484270095825\n",
      "45530 val_loss: 0.07720644026994705, train_loss: 0.0740048885345459\n",
      "45540 val_loss: 0.09725331515073776, train_loss: 0.09500911086797714\n",
      "45550 val_loss: 0.0796278715133667, train_loss: 0.08009213954210281\n",
      "45560 val_loss: 0.0986112430691719, train_loss: 0.09529207646846771\n",
      "45570 val_loss: 0.07679717242717743, train_loss: 0.07722435146570206\n",
      "45580 val_loss: 0.07810454070568085, train_loss: 0.07560960948467255\n",
      "45590 val_loss: 0.08868703246116638, train_loss: 0.0853731632232666\n",
      "45600 val_loss: 0.08316470682621002, train_loss: 0.07937513291835785\n",
      "45610 val_loss: 0.0834377333521843, train_loss: 0.08095992356538773\n",
      "45620 val_loss: 0.0784294605255127, train_loss: 0.07812006771564484\n",
      "45630 val_loss: 0.08324810862541199, train_loss: 0.0803142562508583\n",
      "45640 val_loss: 0.07964115589857101, train_loss: 0.07474953681230545\n",
      "45650 val_loss: 0.07694078236818314, train_loss: 0.07319308817386627\n",
      "45660 val_loss: 0.17401650547981262, train_loss: 0.1760498434305191\n",
      "45670 val_loss: 0.08062145859003067, train_loss: 0.07723487168550491\n",
      "45680 val_loss: 0.0850842297077179, train_loss: 0.07884151488542557\n",
      "45690 val_loss: 0.08655340224504471, train_loss: 0.08369085192680359\n",
      "45700 val_loss: 0.07899610698223114, train_loss: 0.07475551217794418\n",
      "45710 val_loss: 0.07836434990167618, train_loss: 0.07413763552904129\n",
      "45720 val_loss: 0.07881512492895126, train_loss: 0.07481877505779266\n",
      "45730 val_loss: 0.11239451169967651, train_loss: 0.11015049368143082\n",
      "45740 val_loss: 0.08097700029611588, train_loss: 0.07616065442562103\n",
      "45750 val_loss: 0.08396725356578827, train_loss: 0.07986509799957275\n",
      "45760 val_loss: 0.07697353512048721, train_loss: 0.07467887550592422\n",
      "45770 val_loss: 0.08013954013586044, train_loss: 0.0757707878947258\n",
      "45780 val_loss: 0.08137298375368118, train_loss: 0.07690781354904175\n",
      "45790 val_loss: 0.08574865013360977, train_loss: 0.08040696382522583\n",
      "45800 val_loss: 0.09327783435583115, train_loss: 0.09363089501857758\n",
      "45810 val_loss: 0.07660742104053497, train_loss: 0.0741218775510788\n",
      "45820 val_loss: 0.08605001121759415, train_loss: 0.08338509500026703\n",
      "45830 val_loss: 0.09028538316488266, train_loss: 0.09207229316234589\n",
      "45840 val_loss: 0.11298136413097382, train_loss: 0.11143011599779129\n",
      "45850 val_loss: 0.07743503153324127, train_loss: 0.07379233837127686\n",
      "45860 val_loss: 0.08036116510629654, train_loss: 0.07502251863479614\n",
      "45870 val_loss: 0.08821255713701248, train_loss: 0.08325710892677307\n",
      "45880 val_loss: 0.08207568526268005, train_loss: 0.07858972996473312\n",
      "45890 val_loss: 0.09017713367938995, train_loss: 0.08640023320913315\n",
      "45900 val_loss: 0.08533227443695068, train_loss: 0.08129487186670303\n",
      "45910 val_loss: 0.0905618965625763, train_loss: 0.08886381983757019\n",
      "45920 val_loss: 0.07792868465185165, train_loss: 0.07417639344930649\n",
      "45930 val_loss: 0.07733310759067535, train_loss: 0.07303334772586823\n",
      "45940 val_loss: 0.0900152400135994, train_loss: 0.08554784953594208\n",
      "45950 val_loss: 0.09617406129837036, train_loss: 0.09397660940885544\n",
      "45960 val_loss: 0.08014489710330963, train_loss: 0.0744185596704483\n",
      "45970 val_loss: 0.08769626170396805, train_loss: 0.08381570875644684\n",
      "45980 val_loss: 0.07831259071826935, train_loss: 0.07436279952526093\n",
      "45990 val_loss: 0.07664251327514648, train_loss: 0.07367724925279617\n",
      "46000 val_loss: 0.0793500691652298, train_loss: 0.07359166443347931\n",
      "46010 val_loss: 0.08265096694231033, train_loss: 0.07878831028938293\n",
      "46020 val_loss: 0.08088363707065582, train_loss: 0.07887319475412369\n",
      "46030 val_loss: 0.08453720808029175, train_loss: 0.08363794535398483\n",
      "46040 val_loss: 0.08457855135202408, train_loss: 0.07813002914190292\n",
      "46050 val_loss: 0.0795198306441307, train_loss: 0.07535974681377411\n",
      "46060 val_loss: 0.08365640044212341, train_loss: 0.07997459173202515\n",
      "46070 val_loss: 0.08027908951044083, train_loss: 0.07765331864356995\n",
      "46080 val_loss: 0.0822020024061203, train_loss: 0.08042232692241669\n",
      "46090 val_loss: 0.08401152491569519, train_loss: 0.08175120502710342\n",
      "46100 val_loss: 0.0975988432765007, train_loss: 0.09605666995048523\n",
      "46110 val_loss: 0.08387608081102371, train_loss: 0.083060123026371\n",
      "46120 val_loss: 0.07713795453310013, train_loss: 0.07381785660982132\n",
      "46130 val_loss: 0.07973028719425201, train_loss: 0.07821009308099747\n",
      "46140 val_loss: 0.07886767387390137, train_loss: 0.07871020585298538\n",
      "46150 val_loss: 0.0799175277352333, train_loss: 0.07554873824119568\n",
      "46160 val_loss: 0.08018030971288681, train_loss: 0.07536312192678452\n",
      "46170 val_loss: 0.08269264549016953, train_loss: 0.07882539927959442\n",
      "46180 val_loss: 0.08987900614738464, train_loss: 0.08483170717954636\n",
      "46190 val_loss: 0.08082304894924164, train_loss: 0.0770423486828804\n",
      "46200 val_loss: 0.0766986608505249, train_loss: 0.07518375664949417\n",
      "46210 val_loss: 0.0784040093421936, train_loss: 0.07386825233697891\n",
      "46220 val_loss: 0.07990396022796631, train_loss: 0.07607019692659378\n",
      "46230 val_loss: 0.07863052189350128, train_loss: 0.07521378248929977\n",
      "46240 val_loss: 0.09122822433710098, train_loss: 0.09082446992397308\n",
      "46250 val_loss: 0.08172263950109482, train_loss: 0.0796302855014801\n",
      "46260 val_loss: 0.08476123213768005, train_loss: 0.08071170747280121\n",
      "46270 val_loss: 0.07776766270399094, train_loss: 0.07336724549531937\n",
      "46280 val_loss: 0.08441975712776184, train_loss: 0.07970239967107773\n",
      "46290 val_loss: 0.0756717100739479, train_loss: 0.07251372933387756\n",
      "46300 val_loss: 0.07733709365129471, train_loss: 0.07350640743970871\n",
      "46310 val_loss: 0.07949710637331009, train_loss: 0.07538992911577225\n",
      "46320 val_loss: 0.07837822288274765, train_loss: 0.07401499897241592\n",
      "46330 val_loss: 0.07932543754577637, train_loss: 0.07359294593334198\n",
      "46340 val_loss: 0.08700253069400787, train_loss: 0.081599660217762\n",
      "46350 val_loss: 0.09661266207695007, train_loss: 0.09770721197128296\n",
      "46360 val_loss: 0.0816163718700409, train_loss: 0.07705961912870407\n",
      "46370 val_loss: 0.07696037739515305, train_loss: 0.07273923605680466\n",
      "46380 val_loss: 0.07950098812580109, train_loss: 0.07513715326786041\n",
      "46390 val_loss: 0.08498817682266235, train_loss: 0.07892691344022751\n",
      "46400 val_loss: 0.13404908776283264, train_loss: 0.1342480331659317\n",
      "46410 val_loss: 0.07648175209760666, train_loss: 0.07604073733091354\n",
      "46420 val_loss: 0.0825621709227562, train_loss: 0.0795188918709755\n",
      "46430 val_loss: 0.07865487039089203, train_loss: 0.0775119960308075\n",
      "46440 val_loss: 0.07666489481925964, train_loss: 0.077046237885952\n",
      "46450 val_loss: 0.0759551152586937, train_loss: 0.07433204352855682\n",
      "46460 val_loss: 0.08045166730880737, train_loss: 0.07603232562541962\n",
      "46470 val_loss: 0.09749316424131393, train_loss: 0.09832391142845154\n",
      "46480 val_loss: 0.07514961063861847, train_loss: 0.07453746348619461\n",
      "46490 val_loss: 0.07608254998922348, train_loss: 0.07636075466871262\n",
      "46500 val_loss: 0.10024057328701019, train_loss: 0.09797759354114532\n",
      "46510 val_loss: 0.08486273139715195, train_loss: 0.08074332028627396\n",
      "46520 val_loss: 0.08585447072982788, train_loss: 0.08349766582250595\n",
      "46530 val_loss: 0.07498238235712051, train_loss: 0.07294824719429016\n",
      "46540 val_loss: 0.18931205570697784, train_loss: 0.19457590579986572\n",
      "46550 val_loss: 0.0815829262137413, train_loss: 0.0778469443321228\n",
      "46560 val_loss: 0.07710307836532593, train_loss: 0.07409051805734634\n",
      "46570 val_loss: 0.0760238766670227, train_loss: 0.07283548265695572\n",
      "46580 val_loss: 0.07669907808303833, train_loss: 0.07477870583534241\n",
      "46590 val_loss: 0.08132486045360565, train_loss: 0.07588142901659012\n",
      "46600 val_loss: 0.08729404956102371, train_loss: 0.08399118483066559\n",
      "46610 val_loss: 0.08015062659978867, train_loss: 0.07921450585126877\n",
      "46620 val_loss: 0.0770307183265686, train_loss: 0.07286673039197922\n",
      "46630 val_loss: 0.07830889523029327, train_loss: 0.07910707592964172\n",
      "46640 val_loss: 0.08517647534608841, train_loss: 0.08142970502376556\n",
      "46650 val_loss: 0.08123834431171417, train_loss: 0.07713032513856888\n",
      "46660 val_loss: 0.08747727423906326, train_loss: 0.08171066641807556\n",
      "46670 val_loss: 0.07774337381124496, train_loss: 0.07407846301794052\n",
      "46680 val_loss: 0.08367197960615158, train_loss: 0.0791718140244484\n",
      "46690 val_loss: 0.08287430554628372, train_loss: 0.0789949968457222\n",
      "46700 val_loss: 0.08668994158506393, train_loss: 0.08380948007106781\n",
      "46710 val_loss: 0.0793808177113533, train_loss: 0.07361576706171036\n",
      "46720 val_loss: 0.0792090967297554, train_loss: 0.07565201073884964\n",
      "46730 val_loss: 0.07860749214887619, train_loss: 0.07362761348485947\n",
      "46740 val_loss: 0.07887636125087738, train_loss: 0.07321714609861374\n",
      "46750 val_loss: 0.07659848779439926, train_loss: 0.07484007626771927\n",
      "46760 val_loss: 0.07789228111505508, train_loss: 0.07454809546470642\n",
      "46770 val_loss: 0.07682483643293381, train_loss: 0.07276748865842819\n",
      "46780 val_loss: 0.07964396476745605, train_loss: 0.07808844745159149\n",
      "46790 val_loss: 0.0829010084271431, train_loss: 0.08049808442592621\n",
      "46800 val_loss: 0.0782865509390831, train_loss: 0.07400386780500412\n",
      "46810 val_loss: 0.07675734162330627, train_loss: 0.0734907016158104\n",
      "46820 val_loss: 0.09006363898515701, train_loss: 0.090609110891819\n",
      "46830 val_loss: 0.07989660650491714, train_loss: 0.07518251985311508\n",
      "46840 val_loss: 0.08391421288251877, train_loss: 0.0768386572599411\n",
      "46850 val_loss: 0.08139851689338684, train_loss: 0.07474647462368011\n",
      "46860 val_loss: 0.07688671350479126, train_loss: 0.07236064225435257\n",
      "46870 val_loss: 0.0961313247680664, train_loss: 0.09407234936952591\n",
      "46880 val_loss: 0.07549785077571869, train_loss: 0.07300747185945511\n",
      "46890 val_loss: 0.07755137979984283, train_loss: 0.07222088426351547\n",
      "46900 val_loss: 0.08591801673173904, train_loss: 0.07904842495918274\n",
      "46910 val_loss: 0.23235838115215302, train_loss: 0.23014330863952637\n",
      "46920 val_loss: 0.08239500969648361, train_loss: 0.07652676850557327\n",
      "46930 val_loss: 0.0869787186384201, train_loss: 0.08238435536623001\n",
      "46940 val_loss: 0.08205567300319672, train_loss: 0.07628049701452255\n",
      "46950 val_loss: 0.08749531954526901, train_loss: 0.08648129552602768\n",
      "46960 val_loss: 0.08601731061935425, train_loss: 0.08615749329328537\n",
      "46970 val_loss: 0.14620371162891388, train_loss: 0.14723677933216095\n",
      "46980 val_loss: 0.0814206674695015, train_loss: 0.07557180523872375\n",
      "46990 val_loss: 0.08749450743198395, train_loss: 0.0843256339430809\n",
      "47000 val_loss: 0.09034250676631927, train_loss: 0.08779226988554001\n",
      "47010 val_loss: 0.08859416842460632, train_loss: 0.08587568998336792\n",
      "47020 val_loss: 0.07614513486623764, train_loss: 0.07414889335632324\n",
      "47030 val_loss: 0.07952012866735458, train_loss: 0.07735755294561386\n",
      "47040 val_loss: 0.09210586547851562, train_loss: 0.08855334669351578\n",
      "47050 val_loss: 0.12191391736268997, train_loss: 0.1205754205584526\n",
      "47060 val_loss: 0.0758761316537857, train_loss: 0.07476375997066498\n",
      "47070 val_loss: 0.07764264941215515, train_loss: 0.07477795332670212\n",
      "47080 val_loss: 0.09385577589273453, train_loss: 0.091572105884552\n",
      "47090 val_loss: 0.08736094832420349, train_loss: 0.08325003832578659\n",
      "47100 val_loss: 0.09811420738697052, train_loss: 0.09558931738138199\n",
      "47110 val_loss: 0.07738398015499115, train_loss: 0.07378176599740982\n",
      "47120 val_loss: 0.08312253654003143, train_loss: 0.0776781365275383\n",
      "47130 val_loss: 0.07887232303619385, train_loss: 0.07190638035535812\n",
      "47140 val_loss: 0.08050569891929626, train_loss: 0.07711229473352432\n",
      "47150 val_loss: 0.07578596472740173, train_loss: 0.07238706201314926\n",
      "47160 val_loss: 0.07787115126848221, train_loss: 0.0761718675494194\n",
      "47170 val_loss: 0.07696052640676498, train_loss: 0.07123380899429321\n",
      "47180 val_loss: 0.07881331443786621, train_loss: 0.07319460809230804\n",
      "47190 val_loss: 0.13591668009757996, train_loss: 0.13690169155597687\n",
      "47200 val_loss: 0.08660729974508286, train_loss: 0.08312296867370605\n",
      "47210 val_loss: 0.07790730148553848, train_loss: 0.07448980957269669\n",
      "47220 val_loss: 0.07540108263492584, train_loss: 0.07174182683229446\n",
      "47230 val_loss: 0.07857022434473038, train_loss: 0.07688001543283463\n",
      "47240 val_loss: 0.07884065806865692, train_loss: 0.07578795403242111\n",
      "47250 val_loss: 0.08793725818395615, train_loss: 0.08469637483358383\n",
      "47260 val_loss: 0.07606484740972519, train_loss: 0.07251732796430588\n",
      "47270 val_loss: 0.07669906318187714, train_loss: 0.07414069771766663\n",
      "47280 val_loss: 0.07424212992191315, train_loss: 0.0730430856347084\n",
      "47290 val_loss: 0.08229240775108337, train_loss: 0.07884132862091064\n",
      "47300 val_loss: 0.07699314504861832, train_loss: 0.07279086112976074\n",
      "47310 val_loss: 0.0780259370803833, train_loss: 0.07292307913303375\n",
      "47320 val_loss: 0.07645706087350845, train_loss: 0.07149004191160202\n",
      "47330 val_loss: 0.0758635401725769, train_loss: 0.07120069861412048\n",
      "47340 val_loss: 0.07526278495788574, train_loss: 0.07110228389501572\n",
      "47350 val_loss: 0.07474914193153381, train_loss: 0.07127691060304642\n",
      "47360 val_loss: 0.08250684291124344, train_loss: 0.07771216332912445\n",
      "47370 val_loss: 0.07828899472951889, train_loss: 0.07367730140686035\n",
      "47380 val_loss: 0.08007799088954926, train_loss: 0.0761517658829689\n",
      "47390 val_loss: 0.0733381062746048, train_loss: 0.07068294286727905\n",
      "47400 val_loss: 0.07727780938148499, train_loss: 0.07146123796701431\n",
      "47410 val_loss: 0.08275876939296722, train_loss: 0.07939798384904861\n",
      "47420 val_loss: 0.07430773228406906, train_loss: 0.07253558188676834\n",
      "47430 val_loss: 0.07500036060810089, train_loss: 0.07223977893590927\n",
      "47440 val_loss: 0.08138833940029144, train_loss: 0.07704705744981766\n",
      "47450 val_loss: 0.07768772542476654, train_loss: 0.0732610747218132\n",
      "47460 val_loss: 0.08285021036863327, train_loss: 0.08208323270082474\n",
      "47470 val_loss: 0.07576354593038559, train_loss: 0.07037945836782455\n",
      "47480 val_loss: 0.07653706520795822, train_loss: 0.07257615774869919\n",
      "47490 val_loss: 0.0812450498342514, train_loss: 0.07638044655323029\n",
      "47500 val_loss: 0.07491250336170197, train_loss: 0.07185341417789459\n",
      "47510 val_loss: 0.07926483452320099, train_loss: 0.07998855412006378\n",
      "47520 val_loss: 0.10050036758184433, train_loss: 0.09691431373357773\n",
      "47530 val_loss: 0.08034002035856247, train_loss: 0.07544417679309845\n",
      "47540 val_loss: 0.07704950869083405, train_loss: 0.07176916301250458\n",
      "47550 val_loss: 0.08260354399681091, train_loss: 0.07892204821109772\n",
      "47560 val_loss: 0.09085232764482498, train_loss: 0.08584901690483093\n",
      "47570 val_loss: 0.0778975784778595, train_loss: 0.07322312891483307\n",
      "47580 val_loss: 0.07635148614645004, train_loss: 0.07454285770654678\n",
      "47590 val_loss: 0.0791555792093277, train_loss: 0.07443155348300934\n",
      "47600 val_loss: 0.08697956055402756, train_loss: 0.08173240721225739\n",
      "47610 val_loss: 0.08621404320001602, train_loss: 0.08022157847881317\n",
      "47620 val_loss: 0.07497556507587433, train_loss: 0.07008017599582672\n",
      "47630 val_loss: 0.10503081977367401, train_loss: 0.09743737429380417\n",
      "47640 val_loss: 0.0756392553448677, train_loss: 0.07209381461143494\n",
      "47650 val_loss: 0.07899658381938934, train_loss: 0.0751049742102623\n",
      "47660 val_loss: 0.08538941293954849, train_loss: 0.0812319740653038\n",
      "47670 val_loss: 0.08835627138614655, train_loss: 0.08781206607818604\n",
      "47680 val_loss: 0.08523064106702805, train_loss: 0.08456666022539139\n",
      "47690 val_loss: 0.08231373876333237, train_loss: 0.07941053807735443\n",
      "47700 val_loss: 0.08091746270656586, train_loss: 0.07567576318979263\n",
      "47710 val_loss: 0.09926553070545197, train_loss: 0.1004839837551117\n",
      "47720 val_loss: 0.07564759254455566, train_loss: 0.07211028784513474\n",
      "47730 val_loss: 0.07544972747564316, train_loss: 0.07215964794158936\n",
      "47740 val_loss: 0.08229748159646988, train_loss: 0.07992225140333176\n",
      "47750 val_loss: 0.08340910822153091, train_loss: 0.08056487143039703\n",
      "47760 val_loss: 0.07553563266992569, train_loss: 0.0709046870470047\n",
      "47770 val_loss: 0.0774407833814621, train_loss: 0.07409705221652985\n",
      "47780 val_loss: 0.07766678929328918, train_loss: 0.07644827663898468\n",
      "47790 val_loss: 0.0840739905834198, train_loss: 0.08247724175453186\n",
      "47800 val_loss: 0.07695788145065308, train_loss: 0.07265268266201019\n",
      "47810 val_loss: 0.07837993651628494, train_loss: 0.07519282400608063\n",
      "47820 val_loss: 0.07606029510498047, train_loss: 0.07084527611732483\n",
      "47830 val_loss: 0.12438797950744629, train_loss: 0.12229757010936737\n",
      "47840 val_loss: 0.07923468947410583, train_loss: 0.0725373774766922\n",
      "47850 val_loss: 0.09979550540447235, train_loss: 0.09690917283296585\n",
      "47860 val_loss: 0.07980826497077942, train_loss: 0.07308121025562286\n",
      "47870 val_loss: 0.07505027949810028, train_loss: 0.07120798528194427\n",
      "47880 val_loss: 0.07286512106657028, train_loss: 0.07070864737033844\n",
      "47890 val_loss: 0.07688981294631958, train_loss: 0.07581984251737595\n",
      "47900 val_loss: 0.07617729902267456, train_loss: 0.07100872695446014\n",
      "47910 val_loss: 0.0761716440320015, train_loss: 0.07125283032655716\n",
      "47920 val_loss: 0.0760512575507164, train_loss: 0.07038457691669464\n",
      "47930 val_loss: 0.09065454453229904, train_loss: 0.0851711705327034\n",
      "47940 val_loss: 0.08857616037130356, train_loss: 0.08256996423006058\n",
      "47950 val_loss: 0.07487959414720535, train_loss: 0.07110314071178436\n",
      "47960 val_loss: 0.08315867185592651, train_loss: 0.07810527831315994\n",
      "47970 val_loss: 0.07432685047388077, train_loss: 0.07241838425397873\n",
      "47980 val_loss: 0.07694076746702194, train_loss: 0.07163911312818527\n",
      "47990 val_loss: 0.08118027448654175, train_loss: 0.08315159380435944\n",
      "48000 val_loss: 0.0836673229932785, train_loss: 0.08496637642383575\n",
      "48010 val_loss: 0.07686854153871536, train_loss: 0.07260163128376007\n",
      "48020 val_loss: 0.07802662998437881, train_loss: 0.07270143181085587\n",
      "48030 val_loss: 0.0744197815656662, train_loss: 0.07218655198812485\n",
      "48040 val_loss: 0.07682966440916061, train_loss: 0.07213738560676575\n",
      "48050 val_loss: 0.07373082637786865, train_loss: 0.07129254937171936\n",
      "48060 val_loss: 0.1519516557455063, train_loss: 0.15143077075481415\n",
      "48070 val_loss: 0.08429563790559769, train_loss: 0.07996977120637894\n",
      "48080 val_loss: 0.08497046679258347, train_loss: 0.08045094460248947\n",
      "48090 val_loss: 0.0766054093837738, train_loss: 0.07524248212575912\n",
      "48100 val_loss: 0.07383415848016739, train_loss: 0.07175622880458832\n",
      "48110 val_loss: 0.07644755393266678, train_loss: 0.07566514611244202\n",
      "48120 val_loss: 0.07468762248754501, train_loss: 0.07004570960998535\n",
      "48130 val_loss: 0.07510946691036224, train_loss: 0.07201672345399857\n",
      "48140 val_loss: 0.08712957054376602, train_loss: 0.08236605674028397\n",
      "48150 val_loss: 0.07435540109872818, train_loss: 0.07136839628219604\n",
      "48160 val_loss: 0.07655856758356094, train_loss: 0.07240547239780426\n",
      "48170 val_loss: 0.08326206356287003, train_loss: 0.07937151938676834\n",
      "48180 val_loss: 0.07561016082763672, train_loss: 0.07158513367176056\n",
      "48190 val_loss: 0.0773019790649414, train_loss: 0.071205273270607\n",
      "48200 val_loss: 0.07517717033624649, train_loss: 0.07128246873617172\n",
      "48210 val_loss: 0.07527286559343338, train_loss: 0.07059638202190399\n",
      "48220 val_loss: 0.09971323609352112, train_loss: 0.10135713964700699\n",
      "48230 val_loss: 0.10729221254587173, train_loss: 0.1062985211610794\n",
      "48240 val_loss: 0.08593529462814331, train_loss: 0.08077507466077805\n",
      "48250 val_loss: 0.0841115191578865, train_loss: 0.07987289130687714\n",
      "48260 val_loss: 0.0830627828836441, train_loss: 0.07932918518781662\n",
      "48270 val_loss: 0.08123871684074402, train_loss: 0.07435981929302216\n",
      "48280 val_loss: 0.08093941956758499, train_loss: 0.07685037702322006\n",
      "48290 val_loss: 0.07816147804260254, train_loss: 0.07400540262460709\n",
      "48300 val_loss: 0.07468648999929428, train_loss: 0.07165796309709549\n",
      "48310 val_loss: 0.0826159343123436, train_loss: 0.07889491319656372\n",
      "48320 val_loss: 0.08428499102592468, train_loss: 0.07956740260124207\n",
      "48330 val_loss: 0.0969746932387352, train_loss: 0.09588776528835297\n",
      "48340 val_loss: 0.09731019288301468, train_loss: 0.09595058113336563\n",
      "48350 val_loss: 0.08059907704591751, train_loss: 0.07602836191654205\n",
      "48360 val_loss: 0.08835851401090622, train_loss: 0.0832863450050354\n",
      "48370 val_loss: 0.07662557810544968, train_loss: 0.07119961827993393\n",
      "48380 val_loss: 0.07875265926122665, train_loss: 0.07807741314172745\n",
      "48390 val_loss: 0.07486437261104584, train_loss: 0.07173717021942139\n",
      "48400 val_loss: 0.09323728084564209, train_loss: 0.09052395075559616\n",
      "48410 val_loss: 0.1195034310221672, train_loss: 0.11770505458116531\n",
      "48420 val_loss: 0.07779095321893692, train_loss: 0.07534800469875336\n",
      "48430 val_loss: 0.0755799263715744, train_loss: 0.07150346785783768\n",
      "48440 val_loss: 0.07974646985530853, train_loss: 0.07531237602233887\n",
      "48450 val_loss: 0.08791425824165344, train_loss: 0.08514423668384552\n",
      "48460 val_loss: 0.09010753035545349, train_loss: 0.08507829159498215\n",
      "48470 val_loss: 0.08451873809099197, train_loss: 0.08477134257555008\n",
      "48480 val_loss: 0.0732458308339119, train_loss: 0.0702277272939682\n",
      "48490 val_loss: 0.07582495361566544, train_loss: 0.07037103176116943\n",
      "48500 val_loss: 0.07835246622562408, train_loss: 0.07406143099069595\n",
      "48510 val_loss: 0.07679464668035507, train_loss: 0.07259037345647812\n",
      "48520 val_loss: 0.08104557543992996, train_loss: 0.07499008625745773\n",
      "48530 val_loss: 0.0778815820813179, train_loss: 0.07203350216150284\n",
      "48540 val_loss: 0.08013149350881577, train_loss: 0.07531149685382843\n",
      "48550 val_loss: 0.12320906668901443, train_loss: 0.12509015202522278\n",
      "48560 val_loss: 0.07936225086450577, train_loss: 0.07370230555534363\n",
      "48570 val_loss: 0.07554035633802414, train_loss: 0.07084592431783676\n",
      "48580 val_loss: 0.17731836438179016, train_loss: 0.17589256167411804\n",
      "48590 val_loss: 0.07425790280103683, train_loss: 0.07062354683876038\n",
      "48600 val_loss: 0.0792478397488594, train_loss: 0.07670184969902039\n",
      "48610 val_loss: 0.1001223549246788, train_loss: 0.09826630353927612\n",
      "48620 val_loss: 0.07606475800275803, train_loss: 0.07037054747343063\n",
      "48630 val_loss: 0.07971969246864319, train_loss: 0.07369682192802429\n",
      "48640 val_loss: 0.0824362188577652, train_loss: 0.0770900622010231\n",
      "48650 val_loss: 0.07706859707832336, train_loss: 0.07688796520233154\n",
      "48660 val_loss: 0.08215374499559402, train_loss: 0.07702775299549103\n",
      "48670 val_loss: 0.07393971085548401, train_loss: 0.07071685791015625\n",
      "48680 val_loss: 0.07547678798437119, train_loss: 0.0719674751162529\n",
      "48690 val_loss: 0.07461189478635788, train_loss: 0.07256288081407547\n",
      "48700 val_loss: 0.08204696327447891, train_loss: 0.07761335372924805\n",
      "48710 val_loss: 0.08640461415052414, train_loss: 0.08446543663740158\n",
      "48720 val_loss: 0.07529514282941818, train_loss: 0.07077007740736008\n",
      "48730 val_loss: 0.08367970585823059, train_loss: 0.08285493403673172\n",
      "48740 val_loss: 0.07753133028745651, train_loss: 0.07535465806722641\n",
      "48750 val_loss: 0.08393578976392746, train_loss: 0.08238863945007324\n",
      "48760 val_loss: 0.07666373252868652, train_loss: 0.07200958579778671\n",
      "48770 val_loss: 0.07967334240674973, train_loss: 0.07812582701444626\n",
      "48780 val_loss: 0.07331670075654984, train_loss: 0.07157501578330994\n",
      "48790 val_loss: 0.07304316759109497, train_loss: 0.07033339887857437\n",
      "48800 val_loss: 0.07352151721715927, train_loss: 0.07445146888494492\n",
      "48810 val_loss: 0.07728122174739838, train_loss: 0.07398255914449692\n",
      "48820 val_loss: 0.07478834688663483, train_loss: 0.07138825953006744\n",
      "48830 val_loss: 0.07726860046386719, train_loss: 0.07150670886039734\n",
      "48840 val_loss: 0.07849383354187012, train_loss: 0.07466355711221695\n",
      "48850 val_loss: 0.07664120197296143, train_loss: 0.07210712134838104\n",
      "48860 val_loss: 0.07942871004343033, train_loss: 0.07579486817121506\n",
      "48870 val_loss: 0.07630088180303574, train_loss: 0.07368776947259903\n",
      "48880 val_loss: 0.07722332328557968, train_loss: 0.07456336170434952\n",
      "48890 val_loss: 0.07408230751752853, train_loss: 0.07097487896680832\n",
      "48900 val_loss: 0.07766702771186829, train_loss: 0.07260849326848984\n",
      "48910 val_loss: 0.08488643169403076, train_loss: 0.07961860299110413\n",
      "48920 val_loss: 0.07679098099470139, train_loss: 0.07340046763420105\n",
      "48930 val_loss: 0.07372172176837921, train_loss: 0.06970655918121338\n",
      "48940 val_loss: 0.07870463281869888, train_loss: 0.07641039043664932\n",
      "48950 val_loss: 0.08204779028892517, train_loss: 0.07888185232877731\n",
      "48960 val_loss: 0.07191142439842224, train_loss: 0.06947876513004303\n",
      "48970 val_loss: 0.07341106981039047, train_loss: 0.07191558182239532\n",
      "48980 val_loss: 0.20927898585796356, train_loss: 0.20946535468101501\n",
      "48990 val_loss: 0.07705630362033844, train_loss: 0.07295887172222137\n",
      "49000 val_loss: 0.07520139217376709, train_loss: 0.07261736690998077\n",
      "49010 val_loss: 0.07523045688867569, train_loss: 0.07292424887418747\n",
      "49020 val_loss: 0.08314438909292221, train_loss: 0.08231647312641144\n",
      "49030 val_loss: 0.08535885810852051, train_loss: 0.08454275131225586\n",
      "49040 val_loss: 0.0870436578989029, train_loss: 0.0846899002790451\n",
      "49050 val_loss: 0.08144417405128479, train_loss: 0.0774075835943222\n",
      "49060 val_loss: 0.1044265627861023, train_loss: 0.10020498931407928\n",
      "49070 val_loss: 0.07775119692087173, train_loss: 0.07133270055055618\n",
      "49080 val_loss: 0.08451881259679794, train_loss: 0.0837482362985611\n",
      "49090 val_loss: 0.07705666869878769, train_loss: 0.07119178771972656\n",
      "49100 val_loss: 0.0917421281337738, train_loss: 0.09227198362350464\n",
      "49110 val_loss: 0.07221005856990814, train_loss: 0.07119658589363098\n",
      "49120 val_loss: 0.07606613636016846, train_loss: 0.07201921194791794\n",
      "49130 val_loss: 0.07120665907859802, train_loss: 0.07082658261060715\n",
      "49140 val_loss: 0.082515187561512, train_loss: 0.07701046019792557\n",
      "49150 val_loss: 0.07507770508527756, train_loss: 0.07067622244358063\n",
      "49160 val_loss: 0.07124234735965729, train_loss: 0.06930418312549591\n",
      "49170 val_loss: 0.07635759562253952, train_loss: 0.07386104017496109\n",
      "49180 val_loss: 0.07981174439191818, train_loss: 0.0770038440823555\n",
      "49190 val_loss: 0.07290889322757721, train_loss: 0.07087972015142441\n",
      "49200 val_loss: 0.07339681684970856, train_loss: 0.07039616256952286\n",
      "49210 val_loss: 0.10296361148357391, train_loss: 0.10129866749048233\n",
      "49220 val_loss: 0.08986735343933105, train_loss: 0.08817736804485321\n",
      "49230 val_loss: 0.08898387849330902, train_loss: 0.08986469358205795\n",
      "49240 val_loss: 0.07602384686470032, train_loss: 0.07297906279563904\n",
      "49250 val_loss: 0.07291705161333084, train_loss: 0.07235301285982132\n",
      "49260 val_loss: 0.0798993781208992, train_loss: 0.07825696468353271\n",
      "49270 val_loss: 0.07412327826023102, train_loss: 0.071013443171978\n",
      "49280 val_loss: 0.07231129705905914, train_loss: 0.06984109431505203\n",
      "49290 val_loss: 0.07197336852550507, train_loss: 0.06894214451313019\n",
      "49300 val_loss: 0.08245717734098434, train_loss: 0.08369201421737671\n",
      "49310 val_loss: 0.08016606420278549, train_loss: 0.07847942411899567\n",
      "49320 val_loss: 0.0764981061220169, train_loss: 0.0720181092619896\n",
      "49330 val_loss: 0.07456862181425095, train_loss: 0.07218033820390701\n",
      "49340 val_loss: 0.07477501779794693, train_loss: 0.07299457490444183\n",
      "49350 val_loss: 0.07186346501111984, train_loss: 0.06989620625972748\n",
      "49360 val_loss: 0.07442481815814972, train_loss: 0.07033289223909378\n",
      "49370 val_loss: 0.08480505645275116, train_loss: 0.08354786783456802\n",
      "49380 val_loss: 0.0735134407877922, train_loss: 0.06927921622991562\n",
      "49390 val_loss: 0.07586389034986496, train_loss: 0.0705052986741066\n",
      "49400 val_loss: 0.5100604295730591, train_loss: 0.5021364688873291\n",
      "49410 val_loss: 0.07575641572475433, train_loss: 0.07121721655130386\n",
      "49420 val_loss: 0.07132507115602493, train_loss: 0.07090268284082413\n",
      "49430 val_loss: 0.07666118443012238, train_loss: 0.07175183296203613\n",
      "49440 val_loss: 0.08763760328292847, train_loss: 0.08610565215349197\n",
      "49450 val_loss: 0.0793175920844078, train_loss: 0.07745577394962311\n",
      "49460 val_loss: 0.07783140242099762, train_loss: 0.07351823896169662\n",
      "49470 val_loss: 0.083249531686306, train_loss: 0.0798954963684082\n",
      "49480 val_loss: 0.07974962145090103, train_loss: 0.07663154602050781\n",
      "49490 val_loss: 0.0828382596373558, train_loss: 0.08071842044591904\n",
      "49500 val_loss: 0.08319895714521408, train_loss: 0.08018586784601212\n",
      "49510 val_loss: 0.0780961737036705, train_loss: 0.07501313835382462\n",
      "49520 val_loss: 0.07538145780563354, train_loss: 0.06945411115884781\n",
      "49530 val_loss: 0.08077080547809601, train_loss: 0.07577503472566605\n",
      "49540 val_loss: 0.08261699229478836, train_loss: 0.07635766267776489\n",
      "49550 val_loss: 0.0814259722828865, train_loss: 0.07460867613554001\n",
      "49560 val_loss: 0.07457274198532104, train_loss: 0.06989773362874985\n",
      "49570 val_loss: 0.07964479923248291, train_loss: 0.07495269179344177\n",
      "49580 val_loss: 0.07729487121105194, train_loss: 0.07292737811803818\n",
      "49590 val_loss: 0.07907287776470184, train_loss: 0.07321600615978241\n",
      "49600 val_loss: 0.07544398307800293, train_loss: 0.06944819539785385\n",
      "49610 val_loss: 0.08343185484409332, train_loss: 0.0823061540722847\n",
      "49620 val_loss: 0.07886692136526108, train_loss: 0.07525129616260529\n",
      "49630 val_loss: 0.07734838873147964, train_loss: 0.07347280532121658\n",
      "49640 val_loss: 0.07256671041250229, train_loss: 0.0687912255525589\n",
      "49650 val_loss: 0.07507981359958649, train_loss: 0.0723421573638916\n",
      "49660 val_loss: 0.07785779982805252, train_loss: 0.07528682053089142\n",
      "49670 val_loss: 0.07289525121450424, train_loss: 0.06914094090461731\n",
      "49680 val_loss: 0.07594586908817291, train_loss: 0.07332293689250946\n",
      "49690 val_loss: 0.08018592745065689, train_loss: 0.07642050087451935\n",
      "49700 val_loss: 0.07207222282886505, train_loss: 0.06968534737825394\n",
      "49710 val_loss: 0.07356689125299454, train_loss: 0.07276779413223267\n",
      "49720 val_loss: 0.07534509152173996, train_loss: 0.07130087167024612\n",
      "49730 val_loss: 0.07292597740888596, train_loss: 0.07044338434934616\n",
      "49740 val_loss: 0.07625726610422134, train_loss: 0.07710250467061996\n",
      "49750 val_loss: 0.07112042605876923, train_loss: 0.07097184658050537\n",
      "49760 val_loss: 0.0741114541888237, train_loss: 0.07143671810626984\n",
      "49770 val_loss: 0.07579541206359863, train_loss: 0.07209321111440659\n",
      "49780 val_loss: 0.15440133213996887, train_loss: 0.15704162418842316\n",
      "49790 val_loss: 0.07667732983827591, train_loss: 0.07105787098407745\n",
      "49800 val_loss: 0.08264260739088058, train_loss: 0.07877124100923538\n",
      "49810 val_loss: 0.09352204203605652, train_loss: 0.0921405628323555\n",
      "49820 val_loss: 0.07665761560201645, train_loss: 0.0749790146946907\n",
      "49830 val_loss: 0.0766030102968216, train_loss: 0.07365655153989792\n",
      "49840 val_loss: 0.07714007794857025, train_loss: 0.07504328340291977\n",
      "49850 val_loss: 0.08020057529211044, train_loss: 0.07677804678678513\n",
      "49860 val_loss: 0.07159179449081421, train_loss: 0.06961482763290405\n",
      "49870 val_loss: 0.07903838902711868, train_loss: 0.07455934584140778\n",
      "49880 val_loss: 0.07551944255828857, train_loss: 0.07061263918876648\n",
      "49890 val_loss: 0.07553951442241669, train_loss: 0.07008358091115952\n",
      "49900 val_loss: 0.07637784630060196, train_loss: 0.0737914890050888\n",
      "49910 val_loss: 0.08063803613185883, train_loss: 0.08232395350933075\n",
      "49920 val_loss: 0.07177945971488953, train_loss: 0.06879303604364395\n",
      "49930 val_loss: 0.10328128188848495, train_loss: 0.10122735798358917\n",
      "49940 val_loss: 0.08355268836021423, train_loss: 0.08480464667081833\n",
      "49950 val_loss: 0.0818195566534996, train_loss: 0.07521231472492218\n",
      "49960 val_loss: 0.10024063289165497, train_loss: 0.09763255715370178\n",
      "49970 val_loss: 0.08329091221094131, train_loss: 0.07716625183820724\n",
      "49980 val_loss: 0.07685684412717819, train_loss: 0.0719272643327713\n",
      "49990 val_loss: 0.07805781811475754, train_loss: 0.07789933681488037\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "\n",
    "g.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super().__init__()\n",
    "\n",
    "    self.seq_model = nn.Sequential(\n",
    "      nn.Linear(input_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(hidden_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(hidden_size, output_size)\n",
    "    )\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    return self.seq_model(x)\n",
    "  \n",
    "\n",
    "net = Net(2, 16, 1)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for steps in range(50000):\n",
    "  net.train()\n",
    "  data_batch, label_batch = get_batch(train_data, train_labels, 256)\n",
    "  output = net(data_batch)\n",
    "  \n",
    "  loss = loss_fn(output, label_batch)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "  \n",
    "\n",
    "  if steps % 10 == 0:\n",
    "    net.eval()\n",
    "    output = net(val_data)\n",
    "    val_loss = loss_fn(output, val_labels)\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "    output = net(train_data)\n",
    "    train_loss = loss_fn(output, train_labels)\n",
    "    train_losses.append(train_loss.item())\n",
    "    print(f\"{steps} val_loss: {val_loss.item()}, train_loss: {train_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f343ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB390lEQVR4nO3dd3gU1dvG8e9uekijJgRCEnrvgjQBgdAtWBCRoqCiAqL4KogUQSkqxQaCClhoKuIPFZCINA1I70UUQiiJ9AQIqTvvH5GFJYUkJNmU+3Nde7lzzpkzzw6L+3DmzBmTYRgGIiIiIoWE2d4BiIiIiOQkJTciIiJSqCi5ERERkUJFyY2IiIgUKkpuREREpFBRciMiIiKFipIbERERKVSU3IiIiEihouRGREREChUlN1KomUymTL3WrVt3R8cZN24cJpMpW/uuW7cuR2LI7/r3709QUFC69WfPnsXZ2ZnHHnss3TYxMTG4u7tz3333Zfq48+fPx2QyER4enulYbmYymRg3blymj3fd6dOnGTduHLt27UpVdyfflzsVFBREt27d7HJskbziaO8ARHLTpk2bbLYnTJjA2rVr+e2332zKa9aseUfHGThwIJ06dcrWvg0bNmTTpk13HENBV7p0ae677z5++OEHLl68SPHixVO1Wbx4MdeuXWPAgAF3dKzRo0fz4osv3lEft3P69GnefPNNgoKCqF+/vk3dnXxfROT2lNxIoXb33XfbbJcuXRqz2Zyq/FaxsbG4u7tn+jjly5enfPny2YrRy8vrtvEUFQMGDGDp0qUsWLCAwYMHp6qfO3cuvr6+dO3a9Y6OU6lSpTva/07dyfdFRG5Pl6WkyGvTpg21a9dmw4YNNG/eHHd3d5566ikAlixZQkhICGXLlsXNzY0aNWowYsQIrl69atNHWpcZrg//r1q1ioYNG+Lm5kb16tWZO3euTbu0Lkv1798fDw8P/v77b7p06YKHhwcBAQEMHz6c+Ph4m/1PnjzJww8/jKenJz4+PvTu3ZutW7diMpmYP39+hp/97NmzPP/889SsWRMPDw/KlCnDvffey8aNG23ahYeHYzKZeO+995g2bRrBwcF4eHjQrFkzNm/enKrf+fPnU61aNVxcXKhRowZffvllhnFc17FjR8qXL8+8efNS1R08eJA///yTvn374ujoSGhoKPfffz/ly5fH1dWVypUr8+yzz3Lu3LnbHiety1IxMTE8/fTTlCxZEg8PDzp16sRff/2Vat+///6bJ598kipVquDu7k65cuXo3r07e/futbZZt24dd911FwBPPvmk9fLn9ctbaX1fLBYL77zzDtWrV8fFxYUyZcrQt29fTp48adPu+vd169attGrVCnd3dypWrMjkyZOxWCy3/eyZERcXx8iRIwkODsbZ2Zly5crxwgsvcOnSJZt2v/32G23atKFkyZK4ublRoUIFHnroIWJjY61tZs2aRb169fDw8MDT05Pq1avz+uuv2/QTFRXFs88+S/ny5XF2diY4OJg333yTpKQkm3aZ6UsENHIjAkBkZCRPPPEEr776KhMnTsRsTsn7jxw5QpcuXRg2bBjFihXj0KFDTJkyhS1btqS6tJWW3bt3M3z4cEaMGIGvry+fffYZAwYMoHLlytxzzz0Z7puYmMh9993HgAEDGD58OBs2bGDChAl4e3szZswYAK5evUrbtm25cOECU6ZMoXLlyqxatYqePXtm6nNfuHABgLFjx+Ln58eVK1dYtmwZbdq0Yc2aNbRp08am/ccff0z16tWZMWMGkHJ5p0uXLhw7dgxvb28gJbF58sknuf/++5k6dSrR0dGMGzeO+Ph463lNj9lspn///rz11lvs3r2bevXqWeuuJzzXE89//vmHZs2aMXDgQLy9vQkPD2fatGm0bNmSvXv34uTklKlzAGAYBg888ABhYWGMGTOGu+66iz/++IPOnTunanv69GlKlizJ5MmTKV26NBcuXOCLL76gadOm7Ny5k2rVqtGwYUPmzZvHk08+yRtvvGEdacpotOa5555jzpw5DB48mG7duhEeHs7o0aNZt24dO3bsoFSpUta2UVFR9O7dm+HDhzN27FiWLVvGyJEj8ff3p2/fvpn+3BmdizVr1jBy5EhatWrFnj17GDt2LJs2bWLTpk24uLgQHh5O165dadWqFXPnzsXHx4dTp06xatUqEhIScHd3Z/HixTz//PMMGTKE9957D7PZzN9//82BAwdsPkuTJk0wm82MGTOGSpUqsWnTJt566y3Cw8Otf+6Z6UvEyhApQvr162cUK1bMpqx169YGYKxZsybDfS0Wi5GYmGisX7/eAIzdu3db68aOHWvc+tcpMDDQcHV1NY4fP24tu3btmlGiRAnj2WeftZatXbvWAIy1a9faxAkY33zzjU2fXbp0MapVq2bd/vjjjw3AWLlypU27Z5991gCMefPmZfiZbpWUlGQkJiYa7dq1Mx588EFr+bFjxwzAqFOnjpGUlGQt37JliwEYixYtMgzDMJKTkw1/f3+jYcOGhsVisbYLDw83nJycjMDAwNvGcPToUcNkMhlDhw61liUmJhp+fn5GixYt0tzn+p/N8ePHDcD43//+Z62bN2+eARjHjh2zlvXr188mlpUrVxqA8f7779v0+/bbbxuAMXbs2HTjTUpKMhISEowqVaoYL730krV869at6f4Z3Pp9OXjwoAEYzz//vE27P//80wCM119/3Vp2/fv6559/2rStWbOm0bFjx3TjvC4wMNDo2rVruvWrVq0yAOOdd96xKV+yZIkBGHPmzDEMwzC+++47AzB27dqVbl+DBw82fHx8Mozn2WefNTw8PGz+nhiGYbz33nsGYOzfvz/TfYlcp8tSIkDx4sW59957U5UfPXqUxx9/HD8/PxwcHHBycqJ169ZAymWS26lfvz4VKlSwbru6ulK1alWOHz9+231NJhPdu3e3Katbt67NvuvXr8fT0zPV5NRevXrdtv/rPvnkExo2bIirqyuOjo44OTmxZs2aND9f165dcXBwsIkHsMZ0+PBhTp8+zeOPP25z2SUwMJDmzZtnKp7g4GDatm3LggULSEhIAGDlypVERUVZR20Azpw5w6BBgwgICLDGHRgYCGTuz+Zma9euBaB379425Y8//niqtklJSUycOJGaNWvi7OyMo6Mjzs7OHDlyJMvHvfX4/fv3tylv0qQJNWrUYM2aNTblfn5+NGnSxKbs1u9Gdl0fkbw1lkceeYRixYpZY6lfvz7Ozs4888wzfPHFFxw9ejRVX02aNOHSpUv06tWL//3vf2leMvzpp59o27Yt/v7+JCUlWV/XR83Wr1+f6b5ErlNyIwKULVs2VdmVK1do1aoVf/75J2+99Rbr1q1j69atfP/99wBcu3bttv2WLFkyVZmLi0um9nV3d8fV1TXVvnFxcdbt8+fP4+vrm2rftMrSMm3aNJ577jmaNm3K0qVL2bx5M1u3bqVTp05pxnjr53FxcQFunIvz588DKT++t0qrLD0DBgzg/PnzLF++HEi5JOXh4cGjjz4KpMxPCQkJ4fvvv+fVV19lzZo1bNmyxTr/JzPn92bnz5/H0dEx1edLK+aXX36Z0aNH88ADD/Djjz/y559/snXrVurVq5fl4958fEj7e+jv72+tv+5OvleZicXR0ZHSpUvblJtMJvz8/KyxVKpUiV9//ZUyZcrwwgsvUKlSJSpVqsT7779v3adPnz7MnTuX48eP89BDD1GmTBmaNm1KaGiotc2///7Ljz/+iJOTk82rVq1aANYkJjN9iVynOTcikOaaI7/99hunT59m3bp11tEaINWkSnsqWbIkW7ZsSVUeFRWVqf2//vpr2rRpw6xZs2zKL1++nO140jt+ZmMC6NGjB8WLF2fu3Lm0bt2an376ib59++Lh4QHAvn372L17N/Pnz6dfv37W/f7+++9sx52UlMT58+dtEoe0Yv7666/p27cvEydOtCk/d+4cPj4+2T4+pMz9unVezunTp23m2+S26+fi7NmzNgmOYRhERUVZJ0oDtGrVilatWpGcnMy2bdv48MMPGTZsGL6+vtb1ip588kmefPJJrl69yoYNGxg7dizdunXjr7/+IjAwkFKlSlG3bl3efvvtNOPx9/e3vr9dXyLXaeRGJB3XE57roxPXzZ492x7hpKl169ZcvnyZlStX2pQvXrw4U/ubTKZUn2/Pnj2p1gfKrGrVqlG2bFkWLVqEYRjW8uPHjxMWFpbpflxdXXn88cdZvXo1U6ZMITEx0eaSVE7/2bRt2xaABQsW2JQvXLgwVdu0ztnPP//MqVOnbMpuHdXKyPVLol9//bVN+datWzl48CDt2rW7bR855fqxbo1l6dKlXL16Nc1YHBwcaNq0KR9//DEAO3bsSNWmWLFidO7cmVGjRpGQkMD+/fsB6NatG/v27aNSpUo0btw41evm5OZ2fYlcp5EbkXQ0b96c4sWLM2jQIMaOHYuTkxMLFixg9+7d9g7Nql+/fkyfPp0nnniCt956i8qVK7Ny5Up++eUXgNvendStWzcmTJjA2LFjad26NYcPH2b8+PEEBwenug03M8xmMxMmTGDgwIE8+OCDPP3001y6dIlx48Zl6bIUpFya+vjjj5k2bRrVq1e3mbNTvXp1KlWqxIgRIzAMgxIlSvDjjz9m+xJFSEgI99xzD6+++ipXr16lcePG/PHHH3z11Vep2nbr1o358+dTvXp16taty/bt23n33XdTjbhUqlQJNzc3FixYQI0aNfDw8MDf3z/NH+tq1arxzDPP8OGHH2I2m+ncubP1bqmAgABeeumlbH2u9ERFRfHdd9+lKg8KCqJDhw507NiR1157jZiYGFq0aGG9W6pBgwb06dMHSJmr9dtvv9G1a1cqVKhAXFycdZmD9u3bA/D000/j5uZGixYtKFu2LFFRUUyaNAlvb2/rCND48eMJDQ2lefPmDB06lGrVqhEXF0d4eDgrVqzgk08+oXz58pnqS8TKzhOaRfJUendL1apVK832YWFhRrNmzQx3d3ejdOnSxsCBA40dO3akugsmvbul0rorpXXr1kbr1q2t2+ndLXVrnOkdJyIiwujRo4fh4eFheHp6Gg899JCxYsWKVHcNpSU+Pt545ZVXjHLlyhmurq5Gw4YNjR9++CHV3UTX75Z69913U/VBGncTffbZZ0aVKlUMZ2dno2rVqsbcuXNT9ZkZDRo0SPPOHcMwjAMHDhgdOnQwPD09jeLFixuPPPKIERERkSqezNwtZRiGcenSJeOpp54yfHx8DHd3d6NDhw7GoUOHUvV38eJFY8CAAUaZMmUMd3d3o2XLlsbGjRtT/bkahmEsWrTIqF69uuHk5GTTT1p/jsnJycaUKVOMqlWrGk5OTkapUqWMJ554wjhx4oRNu/S+r5k9v4GBgQaQ5qtfv36GYaTc1ffaa68ZgYGBhpOTk1G2bFnjueeeMy5evGjtZ9OmTcaDDz5oBAYGGi4uLkbJkiWN1q1bG8uXL7e2+eKLL4y2bdsavr6+hrOzs+Hv7288+uijxp49e2xiOnv2rDF06FAjODjYcHJyMkqUKGE0atTIGDVqlHHlypUs9SViGIZhMoybxo5FpFCYOHEib7zxBhEREVoJV0SKHF2WEingPvroIyDlUk1iYiK//fYbH3zwAU888YQSGxEpkpTciBRw7u7uTJ8+nfDwcOLj46lQoQKvvfYab7zxhr1DExGxC12WEhERkUJFt4KLiIhIoaLkRkRERAoVJTciIiJSqBS5CcUWi4XTp0/j6emZ5pL7IiIikv8YhsHly5fx9/e/7QKlRS65OX36NAEBAfYOQ0RERLLhxIkTt13mosglN56enkDKyfHy8rJzNCIiIpIZMTExBAQEWH/HM1Lkkpvrl6K8vLyU3IiIiBQwmZlSognFIiIiUqgouREREZFCRcmNiIiIFCpFbs6NiIjkLIvFQkJCgr3DkELA2dn5trd5Z4aSGxERybaEhASOHTuGxWKxdyhSCJjNZoKDg3F2dr6jfpTciIhIthiGQWRkJA4ODgQEBOTIv7il6Lq+yG5kZCQVKlS4o4V2ldyIiEi2JCUlERsbi7+/P+7u7vYORwqB0qVLc/r0aZKSknBycsp2P0qzRUQkW5KTkwHu+BKCyHXXv0vXv1vZZffkZubMmQQHB+Pq6kqjRo3YuHFjum379++PyWRK9apVq1YeRiwiIjfTc/okp+TUd8muyc2SJUsYNmwYo0aNYufOnbRq1YrOnTsTERGRZvv333+fyMhI6+vEiROUKFGCRx55JI8jFxERkfzKrsnNtGnTGDBgAAMHDqRGjRrMmDGDgIAAZs2alWZ7b29v/Pz8rK9t27Zx8eJFnnzyyTyOXERE5IY2bdowbNiwTLcPDw/HZDKxa9euXIsJYN26dZhMJi5dupSrx8lv7DahOCEhge3btzNixAib8pCQEMLCwjLVx+eff0779u0JDAxMt018fDzx8fHW7ZiYmOwFLCIiBd7tLnv069eP+fPnZ7nf77//PksTYAMCAoiMjKRUqVJZPpbcnt2Sm3PnzpGcnIyvr69Nua+vL1FRUbfdPzIykpUrV7Jw4cIM202aNIk333zzjmLNrBMXYrkSn0SNsnogp4hIfhQZGWl9v2TJEsaMGcPhw4etZW5ubjbtExMTM5W0lChRIktxODg44Ofnl6V9JPPsPqH41izaMIxMTSiaP38+Pj4+PPDAAxm2GzlyJNHR0dbXiRMn7iTcdO08foHVHzzH6rljuRSrlTpFRPKjm6c2eHt7YzKZrNtxcXH4+PjwzTff0KZNG1xdXfn66685f/48vXr1onz58ri7u1OnTh0WLVpk0++tl6WCgoKYOHEiTz31FJ6enlSoUIE5c+ZY62+9LHX98tGaNWto3Lgx7u7uNG/e3CbxAnjrrbcoU6YMnp6eDBw4kBEjRlC/fv0snYOlS5dSq1YtXFxcCAoKYurUqTb1M2fOpEqVKri6uuLr68vDDz9srfvuu++oU6cObm5ulCxZkvbt23P16tUsHT8v2C25KVWqFA4ODqlGac6cOZNqNOdWhmEwd+5c+vTpc9tbEF1cXPDy8rJ55YaqV7YygB94MXEua2Y8xdpV33PkrwPExV7JleOJiOQ3hmEQm5Bkl5dhGDn2OV577TWGDh3KwYMH6dixI3FxcTRq1IiffvqJffv28cwzz9CnTx/+/PPPDPuZOnUqjRs3ZufOnTz//PM899xzHDp0KMN9Ro0axdSpU9m2bRuOjo489dRT1roFCxbw9ttvM2XKFLZv306FChXSnaOanu3bt/Poo4/y2GOPsXfvXsaNG8fo0aOtl+K2bdvG0KFDGT9+PIcPH2bVqlXcc889QMqoV69evXjqqac4ePAg69ato0ePHjl67nOK3S5LOTs706hRI0JDQ3nwwQet5aGhodx///0Z7rt+/Xr+/vtvBgwYkNthZlqxmiGcq/8CpXZ9zEMJP8LmH2FzSt01XLhs9ibWqQSJriWxFCuDg7c/LqWD8PStiLdfRUw+AeCQ/QWLRETs7VpiMjXH/GKXYx8Y3xF355z5SRs2bBg9evSwKXvllVes74cMGcKqVav49ttvadq0abr9dOnSheeffx5ISZimT5/OunXrqF69err7vP3227Ru3RqAESNG0LVrV+Li4nB1deXDDz9kwIAB1ptoxowZw+rVq7lyJfP/iJ42bRrt2rVj9OjRAFStWpUDBw7w7rvv0r9/fyIiIihWrBjdunXD09OTwMBAGjRoAKQkN0lJSfTo0cM617VOnTqZPnZesusKxS+//DJ9+vShcePGNGvWjDlz5hAREcGgQYOAlEtKp06d4ssvv7TZ7/PPP6dp06bUrl3bHmGnzWSi1AMTia7YgrPrZuMR/Rclk8/gRDJuxONmOQPxZyAeiAZOAwdv7J6MmTNO5Yn2qYmjf21KVb4LnyrNwVXzd0RE8lLjxo1ttpOTk5k8eTJLlizh1KlT1htVihUrlmE/devWtb6/fvnrzJkzmd6nbNmyQMoVjQoVKnD48GFrsnRdkyZN+O233zL1uQAOHjyYagChRYsWzJgxg+TkZDp06EBgYCAVK1akU6dOdOrUiQcffBB3d3fq1atHu3btqFOnDh07diQkJISHH36Y4sWLZ/r4ecWuyU3Pnj05f/4848ePJzIyktq1a7NixQprRhgZGZlqzZvo6GiWLl3K+++/b4+Qb8u7ble863YFwLBYuHjpIv9GneTi2UiuXIgkIToKy+UzuFw9jVd8JKWTz1DOdA5XUyJlEyMoezYCzq6C3ZCEA6c862Gu0YVyTR/GXDLYzp9ORCR9bk4OHBjf0W7Hzim3Ji1Tp05l+vTpzJgxgzp16lCsWDGGDRt22yeh3zoR2WQy3fYBozfvc33+6c37pDVPNSvSmtd6cx+enp7s2LGDdevWsXr1asaMGcO4cePYunUrPj4+hIaGEhYWxurVq/nwww8ZNWoUf/75J8HB+ev3ye7Plnr++edTZaLXpXU7nre3N7GxsbkcVc4wmc0UL1GS4iVKAvXSbJOQZOHf6FjOnArn/NGdJJ3ahdvFw1RKPEQF01kCL++ALTtgy1tEFquOy139KdG8HzjrOS4ikr+YTKYcuzSUn2zcuJH777+fJ554AkhJNo4cOUKNGjXyNI5q1aqxZcsW+vTpYy3btm1blvqoWbMmv//+u01ZWFgYVatWxcEhJUF0dHSkffv2tG/fnrFjx+Lj48Nvv/1Gjx49MJlMtGjRghYtWjBmzBgCAwNZtmwZL7/88p1/wBxU+L6FBYyzo5mAkh4ElKwNdWsDKV/aK/FJrN+xnfM7l1Pu37U04iBlrx6CdSO4+Ps0zB3fwrvxo6Blz0VEclXlypVZunQpYWFhFC9enGnTphEVFZXnyc2QIUN4+umnady4Mc2bN2fJkiXs2bOHihUrZrqP4cOHc9dddzFhwgR69uzJpk2b+Oijj5g5cyYAP/30E0ePHuWee+6hePHirFixAovFQrVq1fjzzz9Zs2YNISEhlClThj///JOzZ8/m+XnIDCU3+ZSHiyOtmzWFZk2JT0pm/e7DRG78gjYXv6N80hn4+RlO/zGb0j0/wKlsPpp7JCJSyIwePZpjx47RsWNH3N3deeaZZ3jggQeIjo7O0zh69+7N0aNHeeWVV4iLi+PRRx+lf//+bNmyJdN9NGzYkG+++YYxY8YwYcIEypYty/jx4+nfvz8APj4+fP/994wbN464uDiqVKnCokWLqFWrFgcPHmTDhg3MmDGDmJgYAgMDmTp1Kp07d86lT5x9JiM/3sOVi2JiYvD29iY6OjrXbgvPTbuPRXLg2wk8cPVb3EwJxONMbMepFG/W196hiUgRExcXx7Fjx6wPP5a816FDB/z8/Pjqq6/sHUqOyOg7lZXfb7sv4idZUy+4LD1f+Zg17X/md+rjQgLFfxnC2SVDIUmLB4qIFFaxsbFMmzaN/fv3c+jQIcaOHcuvv/5Kv3797B1avqPkpgAym010a9WECoN/ZoFrLwBKH/yCi590gqvn7BydiIjkBpPJxIoVK2jVqhWNGjXixx9/ZOnSpbRv397eoeU7mnNTgFUo5cEDL33E9E9rMODsJIqf207Mx23wemYF+FSwd3giIpKD3Nzc+PXXX+0dRoGgkZsCrpiLI4OfG8KnVeZwwlIar9gTXJ7dWSM4IiJSZCm5KQScHMy83Ls7PzWeS4SlNJ7XTnLp84cg8Zq9QxMREclzSm4KCZPJxKDurfi2+vtcMorhc2EXl77uD5Zke4cmIiKSp5TcFCImk4kXe3ZmVtm3iDcc8Tm+ims/j7R3WCIiInlKyU0h4+hgZsiTfXnX7UUA3LbPxrLjaztHJSIikneU3BRCHi6OPNL/JT6wPAKA5ceX4PROO0clIiKSN5TcFFLV/DwJfHAsvyY3wNFIIP6LhyD6pL3DEhEpFNq0acOwYcOs20FBQcyYMSPDfUwmEz/88MMdHzun+snIuHHjqF+/fq4eIzcpuSnE7m8QwPaGUzhoqYBL/HmufdUTEuPsHZaIiN1079493UXvNm3ahMlkYseOHVnud+vWrTzzzDN3Gp6N9BKMyMjIfPk8p/xEyU0hN/y+u5hT7i3OG564ndtH/DcDIDnJ3mGJiNjFgAED+O233zh+/Hiqurlz51K/fn0aNmyY5X5Lly6Nu7t7ToR4W35+fri4uOTJsQoqJTeFnKODmXF9uvC226vEG464HPmJ5O+fAYvF3qGJiOS5bt26UaZMGebPn29THhsby5IlSxgwYADnz5+nV69elC9fHnd3d+rUqcOiRYsy7PfWy1JHjhzhnnvuwdXVlZo1axIaGppqn9dee42qVavi7u5OxYoVGT16NImJiQDMnz+fN998k927d2MymTCZTNaYb70stXfvXu69917c3NwoWbIkzzzzDFeuXLHW9+/fnwceeID33nuPsmXLUrJkSV544QXrsTLDYrEwfvx4ypcvj4uLC/Xr12fVqlXW+oSEBAYPHkzZsmVxdXUlKCiISZMmWevHjRtHhQoVcHFxwd/fn6FDh2b62Nmhxy8UAd7uTjz/1FO8OjOa94zpOO1fiuFdHlPIeHuHJiKFiWFAYqx9ju3kDibTbZs5OjrSt29f5s+fz5gxYzD9t8+3335LQkICvXv3JjY2lkaNGvHaa6/h5eXFzz//TJ8+fahYsSJNmza97TEsFgs9evSgVKlSbN68mZiYGJv5Odd5enoyf/58/P392bt3L08//TSenp68+uqr9OzZk3379rFq1SrrIxe8vb1T9REbG0unTp24++672bp1K2fOnGHgwIEMHjzYJoFbu3YtZcuWZe3atfz999/07NmT+vXr8/TTT9/28wC8//77TJ06ldmzZ9OgQQPmzp3Lfffdx/79+6lSpQoffPABy5cv55tvvqFChQqcOHGCEydOAPDdd98xffp0Fi9eTK1atYiKimL37t2ZOm52KbkpIiqX8eDBXs8y4ssrTHX6BFPY+1C6GjTobe/QRKSwSIyFif72Ofbrp8G5WKaaPvXUU7z77rusW7eOtm3bAimXpHr06EHx4sUpXrw4r7zyirX9kCFDWLVqFd9++22mkptff/2VgwcPEh4eTvny5QGYOHFiqnkyb7zxhvV9UFAQw4cPZ8mSJbz66qu4ubnh4eGBo6Mjfn5+6R5rwYIFXLt2jS+//JJixVI+/0cffUT37t2ZMmUKvr6+ABQvXpyPPvoIBwcHqlevTteuXVmzZk2mk5v33nuP1157jcceewyAKVOmsHbtWmbMmMHHH39MREQEVapUoWXLlphMJgIDA637RkRE4OfnR/v27XFycqJChQo0adIkU8fNLl2WKkLaVCtDjU7PMjupKwDG/16ArZ/ZOSoRkbxVvXp1mjdvzty5cwH4559/2LhxI0899RQAycnJvP3229StW5eSJUvi4eHB6tWriYiIyFT/Bw8epEKFCtbEBqBZs2ap2n333Xe0bNkSPz8/PDw8GD16dKaPcfOx6tWrZ01sAFq0aIHFYuHw4cPWslq1auHg4GDdLlu2LGfOnMnUMWJiYjh9+jQtWrSwKW/RogUHDx4EUi597dq1i2rVqjF06FBWr15tbffII49w7do1KlasyNNPP82yZctISsrduZ8auSliBrQM5rXI/2PBnjh6O66Bn4fDmYPQaQo46OsgInfAyT1lBMVex86CAQMGMHjwYD7++GPmzZtHYGAg7dq1A2Dq1KlMnz6dGTNmUKdOHYoVK8awYcNISEjIVN+GYaQqM91yyWzz5s089thjvPnmm3Ts2BFvb28WL17M1KlTs/Q5DMNI1Xdax3RyckpVZ8ni3Mtbj3PzsRs2bMixY8dYuXIlv/76K48++ijt27fnu+++IyAggMOHDxMaGsqvv/7K888/z7vvvsv69etTxZVTNHJTxJhMJib0qMvycsOZldQ9pXDrZ7DgYbh2ya6xiUgBZzKlXBqyxysT821u9uijj+Lg4MDChQv54osvePLJJ60/1Bs3buT+++/niSeeoF69elSsWJEjR45kuu+aNWsSERHB6dM3Er1NmzbZtPnjjz8IDAxk1KhRNG7cmCpVqqS6g8vZ2Znk5IyfD1izZk127drF1atXbfo2m81UrVo10zFnxMvLC39/f37//Xeb8rCwMGrUqGHTrmfPnnz66acsWbKEpUuXcuHCBQDc3Ny47777+OCDD1i3bh2bNm1i7969ORJfWpTcFEEujg7MG9CUTRWH8kzCS8QaLnB0LXzeAS4ctXd4IiK5zsPDg549e/L6669z+vRp+vfvb62rXLkyoaGhhIWFcfDgQZ599lmioqIy3Xf79u2pVq0affv2Zffu3WzcuJFRo0bZtKlcuTIREREsXryYf/75hw8++IBly5bZtAkKCuLYsWPs2rWLc+fOER8fn+pYvXv3xtXVlX79+rFv3z7Wrl3LkCFD6NOnj3W+TU74v//7P6ZMmcKSJUs4fPgwI0aMYNeuXbz4Ysqjfq5PGD506BB//fUX3377LX5+fvj4+DB//nw+//xz9u3bx9GjR/nqq69wc3OzmZeT05TcFFHuzo581rcxbnXv55GEsZw2SsC5v+DTe+HQz/YOT0Qk1w0YMICLFy/Svn17KlSoYC0fPXo0DRs2pGPHjrRp0wY/Pz8eeOCBTPdrNptZtmwZ8fHxNGnShIEDB/L222/btLn//vt56aWXGDx4MPXr1ycsLIzRo0fbtHnooYfo1KkTbdu2pXTp0mneju7u7s4vv/zChQsXuOuuu3j44Ydp164dH330UdZOxm0MHTqU4cOHM3z4cOrUqcOqVatYvnw5VapUAVKSxSlTptC4cWPuuusuwsPDWbFiBWazGR8fHz799FNatGhB3bp1WbNmDT/++CMlS5bM0RhvZjLSujhYiMXExODt7U10dDReXl72DsfuLBaDKasO8f2G7XzqPJX65v9Gbhr1h3tHQ7FSdo1PRPKvuLg4jh07RnBwMK6urvYORwqBjL5TWfn91shNEWc2mxjZpQZ9OjTl0YSxzE7qigUTbJ8PHzSEP2drwT8RESlQlNwIAEPbVeHdx+5iKn3onfA6hwiC+GhY+Sp8UB9+n67nUomISIGg5Eas7q9fjoUDm3K2VFO6xL3FmMR+xOMMl47Dr+NgThv4a7VGckREJF9TciM2GgeVYMXQVrzetRZLHbpwV9zHTE7qxTWzB5w9CAsfgSlBKbeP6wGcIiKSDym5kVScHc0MbFWRNcPb0KpuZT5J6k7L2Hf5xtwppUF8dMrifx82gHVTIPaCfQMWEbsqYvelSC7Kqe+SkhtJl5+3Kx8/3pCFTzeleJlyvBrblxpxc5ljeoREBze4FAHrJsL79WHDu0pyRIqY68v5Z3blXpHbuf5duvlREdmhW8ElU+ISk1nwZwRzfz/GqUvX8CCWx7z3Mdh5BT6X/0pp5OwB9R+Hxk9BmRoZdygiBZ5hGERERJCYmIi/vz9ms/69LNlnsVg4ffq09eGatz7uISu/30puJEsSky18s+0E00P/4tyVBExY6Oe1g2HOy/G58rdt47tfgLavg4uHfYIVkVyXkJDAsWPHsvycIpG0mM1mgoODcXZ2TlWn5CYDSm5yxtX4JBb8eZw5G45y7koCYPCo535GunxD8ZuTHGcPaNgXQt4G/atOpFCyWCy6NCU5wtnZOd0RQCU3GVByk7OuJSSzcEsEn6z/h7OXU5570t3zCKOLLaPMpV03Grp4wbProURF+wQqIiIFmpKbDCi5yR1xicl8uSmciSsOWct83ByZVO4POp98/0bD/j9DUEs7RCgiIgWZkpsMKLnJXVfjk/h22wk+3Zgy8RigocM/fO/03wPhTGboNh0a9oNbJouJiIikR8lNBpTc5I3EZAsbj5xlysrDHP73MsW4xjd+X1Hr0rqUBuWbQO9vwc3HnmGKiEgBoQdnit05OZi5t7ovy15oTvsavlzFjW5RA1nq3Q/D0Q1OboG5HeHf/fYOVUREChklN5Kr3J0d+axfY0Z3q4mLkyPD/+3IINfJJLn4wNlDsOARuBhu7zBFRKQQUXIjeWJAy2C+fbY5ZTxd+OVcaTpeHU+yozvEnIL53eHicXuHKCIihYSSG8kzdcp789PQljSvVJJ/kkoREvs2V4sFQHQEzO+mERwREckRSm4kT5XxdGVu/7toX6MM/1h8Cbk4gqseQSkJztcPQfwVe4coIiIFnN2Tm5kzZxIcHIyrqyuNGjVi48aNGbaPj49n1KhRBAYG4uLiQqVKlZg7d24eRSs5wdXJgdl9GvNgg3KcshSnw4X/I961DJz/GxY+qgRHRETuiF2TmyVLljBs2DBGjRrFzp07adWqFZ07dyYiIiLdfR599FHWrFnD559/zuHDh1m0aBHVq1fPw6glJziYTbz3SD3uq+fPaUtxel8ZSrKTJxz/AxY9BslJ9g5RREQKKLuuc9O0aVMaNmzIrFmzrGU1atTggQceYNKkSanar1q1iscee4yjR49SokSJbB1T69zkL0nJFp5fsIPVB/6lnWcEnzIec2IstB4BbUfaOzwREcknCsQ6NwkJCWzfvp2QkBCb8pCQEMLCwtLcZ/ny5TRu3Jh33nmHcuXKUbVqVV555RWuXbuW7nHi4+OJiYmxeUn+4ehgZlrP+lQsXYw1lyvwjvMLKRUb3oHwP+wbnIiIFEh2S27OnTtHcnIyvr6+NuW+vr5ERUWluc/Ro0f5/fff2bdvH8uWLWPGjBl89913vPDCC+keZ9KkSXh7e1tfAQEBOfo55M55uDgyr/9dlPJw4ZPzDfjdoyMYFvj+aYi9YO/wRESkgLH7hGLTLc8XMgwjVdl1FosFk8nEggULaNKkCV26dGHatGnMnz8/3dGbkSNHEh0dbX2dOHEixz+D3LnAksX4rF9jXBzNPHOuJ+ddAlLWwFk+BIrWE0JEROQO2S25KVWqFA4ODqlGac6cOZNqNOe6smXLUq5cOby9va1lNWrUwDAMTp48meY+Li4ueHl52bwkf6of4MP0nvWJxZV+lwdhMTvBoZ9g62f2Dk1ERAoQuyU3zs7ONGrUiNDQUJvy0NBQmjdvnuY+LVq04PTp01y5cuNW4b/++guz2Uz58uVzNV7JG13qlKVHw3LsswQzy6lvSmHoGLikETcREckcu16Wevnll/nss8+YO3cuBw8e5KWXXiIiIoJBgwYBKZeU+vbta23/+OOPU7JkSZ588kkOHDjAhg0b+L//+z+eeuop3Nzc7PUxJIeN6VaTMp4uvBt9Lyc860FiLKz4P3uHJSIiBYRdk5uePXsyY8YMxo8fT/369dmwYQMrVqwgMDAQgMjISJs1bzw8PAgNDeXSpUs0btyY3r170717dz744AN7fQTJBT7uzkx4oDZgYuD53hgmM/y1Eo6nfRediIjIzey6zo09aJ2bguPV73bzzbaTfFBsLvcl/wqla8CzG8DR2d6hiYhIHisQ69yI3M6b99WmrLcrY64+QqxjcTh7EH6fbu+wREQkn1NyI/mWm7MDY7vX5BKejE7ok1K48T2ITvvOOBEREVByI/lcx1p+VC7jwdKEphz3bADJCbD6DXuHJSIi+ZiSG8nXTCYTr3WqDph47vyjKYX7l0HUPrvGJSIi+ZeSG8n3OtT0pVvdshywBLLZrXVKYegY+wYlIiL5lpIbKRBe7VgdZwcz/3fpASwmR/hnDRzbYO+wREQkH1JyIwVChZLu9GoSwAnDl19cO6cU/jpOz50SEZFUlNxIgfF828q4OJoZfbELyY7ucGo7HPzR3mGJiEg+o+RGCgxfL1f6NgvkHN4sMndLKfxtAiQn2TcwERHJV5TcSIHyQtvKeLs5MSUmhHgnHzj3F+xeaO+wREQkH1FyIwWKj7szz9xTkcu4M9fcI6Vw3WRIvGbfwEREJN9QciMFTt9mgXi5OjIj+h6uuflBzCnY8qm9wxIRkXxCyY0UOJ6uTgxoWZF4nJnJfwv7bXwPYi/YNzAREckXlNxIgdS/RRCeLo58fLEJMV5VIS4atsyxd1giIpIPKLmRAsnbzYn+LYKwYGZ6/P0phWEfwdVz9g1MRETsTsmNFFjP3FORksWcmR9djwteNSHhMmycau+wRETEzpTcSIHl6erEoNaVMDAzPu6RlMKtn8GlCPsGJiIidqXkRgq0J+4OpJSHCz/EVONs6bshOQHWTrR3WCIiYkdKbqRAc3N2oF+zQADGx/43erN7Mfy7345RiYiIPSm5kQKvb/OUO6d+PF+WqPIdAQN+HKaHaoqIFFFKbqTA83Zzom/zlNGb0TE9MEwOcHILHFlt58hERMQelNxIoTCgZUXcnBwIPePJqeD/Lk/9Og6SE+0al4iI5D0lN1IolCjmTI+G5QB48PC9GO4l4cwB2PSRnSMTEZG8puRGCo0X2lYG4GyyBxuChqYU/j4drp63Y1QiIpLXlNxIoeHv40bzSiUBGBteB6NMrZTHMvw0TJOLRUSKECU3UqjM7tOIEsWcCb8Qx8pKb4DZEQ4uh+3z7B2aiIjkESU3Uqh4ujox9N6Uy1NjtzmT2HpUSkXoWIg5bcfIREQkryi5kULn8aaBlPV25ezleD6K6wTlGkF8DPz4oi5PiYgUAUpupNBxdjQzonN1AD4PO8H59lPB7JSy7s2PL9o5OhERyW1KbqRQ6l7XnzrlvLkSn8TTK2OxNH0upWLHl/CXFvcTESnMlNxIoWQ2m5jUow4mE+yIuMQ3PgMh4G7AgIWPwImt9g5RRERyiZIbKbRql/PmmXsqAjD5l8Oc77EEfFIe08Dn7SEm0o7RiYhIblFyI4XaKyHVqFHWi0uxiUz45Rg8sfRG5ZzWYEm2X3AiIpIrlNxIoebkYGZyjzoA/LDrNENCr0Df5SmVV/6Fb/tBUrwdIxQRkZym5EYKvXoBPnSq5QfAj7tP8/OVqtDza3BwhoM/whfd9YBNEZFCRMmNFAnv96pvff/Cwh0cK30v9FqcUnDiT/jiPrBY7BOciIjkKCU3UiS4ODqweWQ763bb99ZhVLoX7nk1pSAiDOZ3heQkO0UoIiI5RcmNFBl+3q5MfaSedbvVO2vh3lHw4BwwmVMSnC/vg4SrdoxSRETulJIbKVIealTe+v7kxWss3hIB9XrCfR+lFB7/A+a0gX/32ydAERG5Y0pupMgJn9yVpsElABjx/V6e+XIbNOgND88FF2849xfM65KymrGIiBQ4Sm6kSFr8zN00r1QSgNUH/mXc8v1Q+yF4YTOUqQVxl2D5EPh9OiRes2+wIiL5UUIs7F8GcTH2jiQVJTdSJJlMJr54qol1e35YOHN/PwZe/vD0GqjQPKXi13Hwth+cPWyfQEVE8qufXoJv+8M3fe0dSSpKbqTIcnIwc2B8R+v2+J8O8L9dp8DJDZ5cAd3fv9H44ybw4zDdTSUict2e/5bTOLrWvnGkwe7JzcyZMwkODsbV1ZVGjRqxcePGdNuuW7cOk8mU6nXo0KE8jFgKE3dnRw6/1cm6/eLiXXyw5ggGQKP+8OJu8EhZAJDt82BCSfioie6oEhHJx+ya3CxZsoRhw4YxatQodu7cSatWrejcuTMREREZ7nf48GEiIyOtrypVquRRxFIYuTg6sOX1G2vgTAv9i87v/5dkFw+Clw9A3cdu7HDuMEwqD9Gn8jZQERHJFLsmN9OmTWPAgAEMHDiQGjVqMGPGDAICApg1a1aG+5UpUwY/Pz/ry8HBIY8ilsKqjJcrB8d3wtvNCYBDUZd5cOYfxCYkgdkBesyGwdtu7GBYYHpN+O4puPyvnaIWEZG02C25SUhIYPv27YSEhNiUh4SEEBYWluG+DRo0oGzZsrRr1461azO+1hcfH09MTIzNSyQtbs4O7BrTgYf/WwtnZ8Qlao75hUkrD2IYBpSqAuOi4aHPb+y0bylMrQqbZkJinJ0iFxGRm9ktuTl37hzJycn4+vralPv6+hIVFZXmPmXLlmXOnDksXbqU77//nmrVqtGuXTs2bNiQ7nEmTZqEt7e39RUQEJCjn0MKF5PJxHuP1OOTJxphMqWUzV5/lBFL93ItITmloM7D8MZZaPLMjR1/GQlv+8LEchB/Je8DFxERK5NhGIY9Dnz69GnKlStHWFgYzZo1s5a//fbbfPXVV5meJNy9e3dMJhPLly9Psz4+Pp74+HjrdkxMDAEBAURHR+Pl5XVnH0IKtZMXY2k5xXZkcFKPOvRqUuFGQfwV+G0C/PnJjTIPP7jvA6jaERGRQmuc903vo3P9cDExMXh7e2fq99tuIzelSpXCwcEh1SjNmTNnUo3mZOTuu+/myJEj6da7uLjg5eVl8xLJjPLF3Tk0oRMujjf+moz8fi9BI35m7eEzKQUuHtB5Cow4AaVrpJRdiYKFj6aschz+hx0iFxEp2uyW3Dg7O9OoUSNCQ0NtykNDQ2nevHmm+9m5cydly5bN6fBEAHB1cuDwW51Z9PTdNuVPztvKuOX7Sbb8N/Dp6pWyuvErf0OzwWB2THlO1fwu8NWDEP67HaIXESma7Hq31Msvv8xnn33G3LlzOXjwIC+99BIREREMGjQIgJEjR9K3742VD2fMmMEPP/zAkSNH2L9/PyNHjmTp0qUMHjzYXh9BiohmlUpybFIXhra7sezA/LBwKr2+ImXhv+s8SkPHt1PWx6neLaXsn99gfjdY0gdObM3jyEVEih5Hex68Z8+enD9/nvHjxxMZGUnt2rVZsWIFgYGBAERGRtqseZOQkMArr7zCqVOncHNzo1atWvz888906dLFXh9BihCTycTLHarSvkYZ7vvoxuWmFxfv4sXFu5j35F20rVYmpdC7PDy2AE5th696pDyr6uDylJdbCbh2Afr8AEEtwcHJLp9HRKSwstuEYnvJyoQkkfQYhsGnG48ycYXtxHdHs4lvBjWjYYXitjv8ewA2fQR7v4XkBNu6oFYpTyT3KJPLUYuI5KB8PKFYyY3IHVq1L4pBX29PVf7XW51xdrzlyu/V87B6FOxelHZnldtD7++w3ocuIpJf5ePkxu7PlhIp6DrV9uPoxC683qW6TXnVN1by9ebjto2LlYQHP4Gxl6Db9NSd/f0rvOkDv4xKSYRERCTLNHIjkoNiE5LoMTOMQ1GXrWWtqpSiddXSDGxVMe2dEq/BHx/Auom25SYzBDSFiE0pk5Mfma/5OSKSf+TjkRslNyK54PyVeNq+t46YuCRrmbuzA+Pvr219vEOaTm2HpU+DJREuZfAA2T4/QKW2ORewiEhWKbnJP5TcSF7aGXGR15ft42Ck7TPNrk88rl/eB7M5nfk1F8Nh/zL4dVzGB6nYBpo+l7IisubqiEheUXKTfyi5EXsIP3eVp+Zv5ei5q6nqnm1dkaH3VqGYSwYrMyRchQPL4YdBtz9Yu7HQ6uU7iFZEJBOU3OQfSm7Enlbti2Tc8gNExaT9BPHFz9zN3RVL3r6jy//Ckt5wMp1FAf3qwqNfQongO4hWRCQDSm7yDyU3kh8kJFloP209ERdiU9V5uDjy2/DWlPFyzVxnlmSI3A0bp8Khn2zrnv4NyjXKgYhFRG6h5Cb/UHIj+c324xd5aFZYqvKqvh4MbFWRbnXL4u6chcXET2yFxb3g6lnwKgcv7ddcHBHJeUpu8g8lN5Jfnbp0jZZTfiOtv5F1y3tzV1AJXmxfBS/XTNwOfnIbfNYu5X3NB+DRL3I0VhERJTf5iJIbye8sFoOdJy4ydvl+DkddJjE59V/Rcd1r8mCD8ni7Z5DorH8X1r6V8t6/ATy1GhydcylqESlylNzkH0pupCBJthh8tSmc99cc4WJsYqr6Uh7OdK5dln7Ng6hcxsO20jBSVju+WZNnoMu7uRewiBQdSm7yDyU3UlBdT3Q+Wvs3564kpNmmSXAJvh7Q9MYzrSwW+KZP6onGo8+DQxbm8YiI3ErJTf6h5EYKg+hriXy1KZwVe6M4cMsCgdcdGN/xxkTkPd/C9wNTNxq6S7eLi0j2KLnJP5TcSGG0al8kg77ekap877gQPK9PQE5OhMmBkHjLQoIv7oHigXkQpYgUKvk4udFTwUUKgU61yxI+uSt7x4XYlDef9NuNDQcnGHUanllnu/P7deFDrYUjIoWHkhuRQsTT1YnwyV1pW600AJfjk/hyU7htI/8GMPaSbdn5v+Gz9nkSo4hIblNyI1IIzXuyCcWcHQAY87/9fLbxqG0DkyllGPmhz2+UndwKK1/LwyhFRHKHkhuRQmrVsHus79/6+SBBI37m220nbBvVedh2FOfPT+DYxrwJUEQklyi5ESmkAkq48/trbW3K/u+7PTw6e5NtQ5MJ3jgDPhVStr/oBn//mkdRiojkPCU3IoVY+eLu/DOxi03ZlmMXqPT6Cu776Heiov97OrmjS8oKxtd9/RBpPgdCRKQAUHIjUsg5mE2ET+7KvP53WcuSLQZ7TkZz96Q1bD9+IaXQqyw8sfTGjptn5nGkIiI5Q8mNSBHRtnoZwid3ZVKPOjblD83axKvf7U7ZqNweXP5bP+KX18GSnMdRiojcOSU3IkVMryYV2PdmR5uyb7adJGjEzxiGAc+F3aj4uEkeRycicueU3IgUQR4ujimXqp68y6Y8eOQK8Am4UXD+7zyOTETkzim5ESnC2lYrk2oUZ/DCHVhe2H6j4PK/eRyViMidUXIjUsR5uDjy99udrds/7Ynk+VU3PSfmz1l2iEpEJPuU3IgIjg5m1v9fG+v2qv1RWEpWSdm4HGWfoEREsknJjYgAEFiyGEufa2bd/tzxsZQ3p3fZJyARkWxSciMiVo0CS1jfzzleNuXN2UOQGGeniEREsk7JjYjY2PJ6OwDO4k2M4QYY8O8++wYlIpIFSm5ExEYZL9f/3pk4aZRJeRu5227xiIhklZIbEUll+xvtAdhtqZhScPGYHaMREckaJTcikkpJDxcADhr/PSn8gpIbESk4lNyISJp6NQnguOGXsnH+H/sGIyKSBUpuRCRN99cvx7Hryc3FY2Cx2DcgEZFMUnIjImmqU86bSEqRaDhAUhxcPm3vkEREMkXJjYikqZiLIxXL+HDCKJ1ScOGofQMSEckkJTcikq665b05Zvy3mN+ZQ/YNRkQkk5TciEi6gkoVY58RnLJxanvGjUVE8gklNyKSrsCS7hyxlEvZ2LPYvsGIiGSSkhsRSVe98j6YMW4UGEb6jUVE8gm7JzczZ84kODgYV1dXGjVqxMaNGzO13x9//IGjoyP169fP3QBFirByPm6sNTW+UXBqh/2CERHJJLsmN0uWLGHYsGGMGjWKnTt30qpVKzp37kxERESG+0VHR9O3b1/atWuXR5GKFE1mswlvL+8bBZ/da79gREQyKVvJzYkTJzh58qR1e8uWLQwbNow5c+ZkqZ9p06YxYMAABg4cSI0aNZgxYwYBAQHMmjUrw/2effZZHn/8cZo1a5ad8EUkCy5eTbB3CCIiWZKt5Obxxx9n7dq1AERFRdGhQwe2bNnC66+/zvjx4zPVR0JCAtu3byckJMSmPCQkhLCwsHT3mzdvHv/88w9jx47NTugikkW1y3nzZVKHGwVaqVhE8rlsJTf79u2jSZMmAHzzzTfUrl2bsLAwFi5cyPz58zPVx7lz50hOTsbX19em3NfXl6ioqDT3OXLkCCNGjGDBggU4Ojpm6jjx8fHExMTYvEQk817pWI3PkzvfKNj7jf2CERHJhGwlN4mJibi4pDw1+Ndff+W+++4DoHr16kRGRmapL5PJZLNtGEaqMoDk5GQef/xx3nzzTapWrZrp/idNmoS3t7f1FRAQkKX4RIq64FLFbjxAE2DZszC/G2yfb7eYREQykq3kplatWnzyySds3LiR0NBQOnXqBMDp06cpWbJkpvooVaoUDg4OqUZpzpw5k2o0B+Dy5cts27aNwYMH4+joiKOjI+PHj2f37t04Ojry22+/pXmckSNHEh0dbX2dOHEii59WpGgrWcwZgDGJ/W4Uhm+EH1+0U0QiIhnLVnIzZcoUZs+eTZs2bejVqxf16tUDYPny5dbLVbfj7OxMo0aNCA0NtSkPDQ2lefPmqdp7eXmxd+9edu3aZX0NGjSIatWqsWvXLpo2bZrmcVxcXPDy8rJ5iUjmXR9J/SlZE/hFpGDI3MSVW7Rp04Zz584RExND8eLFreXPPPMM7u7ume7n5Zdfpk+fPjRu3JhmzZoxZ84cIiIiGDRoEJAy6nLq1Cm+/PJLzGYztWvXttm/TJkyuLq6pioXkZz17D0Vmb3hKP8aPviaLtk7HBGRDGVr5ObatWvEx8dbE5vjx48zY8YMDh8+TJkyZTLdT8+ePZkxYwbjx4+nfv36bNiwgRUrVhAYGAhAZGTkbde8EZHcN6BlyvOlusVPtK24dtEO0YiIZMxkGFlfTz0kJIQePXowaNAgLl26RPXq1XFycuLcuXNMmzaN5557LjdizRExMTF4e3sTHR2tS1QiWRA04mcAVjqPoIb5v390NB4A3abZMSoRsZtxNy3wOS461w+Xld/vbI3c7Nixg1atWgHw3Xff4evry/Hjx/nyyy/54IMPstOliORzPw1pCUDnhEk3Crd9nvI/OI3giBQ5FiP1nc35RbaSm9jYWDw9PQFYvXo1PXr0wGw2c/fdd3P8+PEcDVBE8ofa5a7/K83Eq4lP21ZOCQJLcl6HJCKSpmwlN5UrV+aHH37gxIkT/PLLL9ZVhs+cOaNLPSKF2K8vtwbgm+S2qSvHl8jjaERE0pat5GbMmDG88sorBAUF0aRJE+sznlavXk2DBg1yNEARyT8ql/Gwvg+O+zp1g3/SXm9KRCQvZSu5efjhh4mIiGDbtm388ssv1vJ27doxffr0HAtORPKfv99OeRSDgZkqcV/aVn71IJz/B5KT7BCZiEiKbCU3AH5+fjRo0IDTp09z6tQpAJo0aUL16tVzLDgRyX8cHczM6FkfgEQcaRD3iW2DDxvChJKw/4c8j01EBLKZ3FgsFsaPH4+3tzeBgYFUqFABHx8fJkyYgEVPDBYp9B5oUM76/iJeVIubn7rRt/1g2zzI+moTIiJ3JFvJzahRo/joo4+YPHkyO3fuZMeOHUycOJEPP/yQ0aNH53SMIpIPHZvUxfo+Hue05+D8NAze9MmzmEREIJuL+Pn7+/PJJ59YnwZ+3f/+9z+ef/5562Wq/EiL+InknIQkC1XfWGnddiKJ7b0c8FrWO3XjTlOg6bNgyr9rY4hI5lnG+mA2/ZdCFIZF/C5cuJDm3Jrq1atz4cKF7HQpIgWQs6OZQxM6WbcTcaTuIhOfNVyWuvGq1+C9qnkYnYgUVdlKburVq8dHH32Uqvyjjz6ibt26dxyUiBQcrk4O7B0XYlP2Vti1tOfhXD2TsqLxroWQeC1vAhSRXJGfZ9Nl67LU+vXr6dq1KxUqVKBZs2aYTCbCwsI4ceIEK1assD6aIT/SZSmR3GGxGFR8fUWq8k/aJNNpc5+0dxpzETAgYjP41wfnYrkao4jknOSxPjgUpstSrVu35q+//uLBBx/k0qVLXLhwgR49erB//37mzZuXraBFpGAzm02ET+5Klzp+NuWD1jnQw/XTtHcaXzxlZeP5XeCbvnkQpYgUBdkauUnP7t27adiwIcnJ+fcZMxq5Ecl9/9t1ihcX77IpM2PhoO8YXKKPpr/jzf/6i70A7nqkg0h+VehGbkREMnJ//XL8PLSlTZkFM9X+fYthJT9JZy9gzzcpc3LGecM7wbD+3VyOVEQKIyU3IpIravl7Ez65K51q2V6m+uGUF0FxC2ljzEm90/e3PG187Vu5GKGIFFZKbkQkV33SpxG/DLsnVXl4vAetXJey7K6FGXegVc9FJIuyNOemR48eGdZfunSJ9evXa86NiKQSl5hM9dGr0qzz5gq7XZ/JuINnN0JZLTUhkl8Umjk33t7eGb4CAwPp21d3PIhIaq5ODoRP7kroS6lHcaLxIChuISeaTUi/gzmtU544fv3fYxeOwYktuRStiBRkOXq3VEGgkRsR+zMMg81HL9Dr081p1n/lNJFWDvvS3rl+b3hgZsqkY4A+P0CltrkTqIikq9CM3IiI5ASTyUSzSiU5OrELb3Stkaq+T+LrNIhL566qXQtg2XM3tr96IHeCFJEMGeTf58QpuRERuzGbTQxsVZEjb3emrLerTd1FUu6qCopbkHrH3bdMQo6/kotRikhBo+RGROzOycHMppHt+PP1dmnUmgiKu80dVZPKw/FNcGo7bPoY/t2fK3GKSMHgaO8ARESu8/VyJXxyV5ItBm/9fIB5f4Rb64LiFuJAMnOd3qW1w55b9jRgXifbojyYAyAi+ZNGbkQk33EwmxjbvRZ/v92ZBhV8rOXJONAvcQQjEgfaLzgRyfeU3IhIvuXoYGbZ8y3YcsvlqsXJ9xIUt5BxiRksPVG0bgQVkZsouRGRfK/Mf5erfn/N9pbv+cmdGJvYL+2d3vRJuV38844Q8WfuByki+YaSGxEpMMoXdyd8clfGda9pLfsiuSPt499Jf6cTm2FuCCQlpGwbBly7mMuRiog9KbkRkQKnf4tgwid3ZcHApgD8bZQnKG4hzeM+SH+ndyrCpQhY2BOmBMHpnXD2sJ5dJVIIKbkRkQKrReVS/P12Z+v2aUoRFLeQKYmPpW6ccBlm1IEjv6Rsz2kDHzeBVa/lTbAikmeU3IhIgeboYCZ8cld+HNzSWjYr+T6qxc1nUmKv23ewZU4uRieSAYsF9v8Al07YO5Js0QrFIiK5rE55b8Ind+XJFkEAxOPM7OTuaY/iiOQHexbDt/1gRm17R1LoKLkRkUJlbPda7B0XQv0AHwA+Te7CvKSOGe+059uU+TgieenYBntHUGgpuRGRQsfT1YkfXmjB8sEtSMKRN5P6ERS3kJcSnkt7h+8Hwvv18zRGEck9Sm5EpNCqW96HIzdNOF5maUmX+IlpNzaS8ygqEcltSm5EpFBz+m/C8e4xIYCJA0ZQxreMi0iBp+RGRIoEb3cn/pnYhZc7VOU0pagY93XqRmsn5X1gUmRFX0u0dwiFlpIbESkyHMwmhrarwtpX2mDBTMf4ybYN1k+GBY/aJzgpcv7697K9Qyi0lNyISJETXKoYhyZ04rBRgTcSn7StPPKLnkUlUsApuRGRIsnVyYHdY0P4OrkDAxOG21bODQFLMqwckXKbuIgUKI72DkBExF683Zw4ML4jNcdAw7hP2OE66Ebl+BI33ldpD27F8z5AkXzMsHcAGdDIjYgUae7Ojhwc34kLeNEnYUTajWa3ztugROSOKLkRkSLPzdmBY5O6sNFSlxlJPVI3uHQ874OSIiA/j30UbHZPbmbOnElwcDCurq40atSIjRs3ptv2999/p0WLFpQsWRI3NzeqV6/O9OnT8zBaESmsTCYTu8eGMCPp4bQbfPdU3gYkItlm1+RmyZIlDBs2jFGjRrFz505atWpF586diYhI+xkvxYoVY/DgwWzYsIGDBw/yxhtv8MYbbzBnjp7qKyJ3ztvNiYPjO1E/bnbqyn1LIfz3vA9KCrH8+1Ttgs6uyc20adMYMGAAAwcOpEaNGsyYMYOAgABmzZqVZvsGDRrQq1cvatWqRVBQEE888QQdO3bMcLRHRCQr3JwdmNqvLUFxCwlNbmRbOb+r1sERKQDsltwkJCSwfft2QkJCbMpDQkIICwvLVB87d+4kLCyM1q3Tn+wXHx9PTEyMzUtEJCPtavjy3aBmPJ04nDXJDWwrj/wC47zh6Hr7BCcit2W35ObcuXMkJyfj6+trU+7r60tUVFSG+5YvXx4XFxcaN27MCy+8wMCBA9NtO2nSJLy9va2vgICAHIlfRAq3xkEl+ObZZgxI/D+axX2YusGX90HC1bwPTERuy+4Tik0m22uOhmGkKrvVxo0b2bZtG5988gkzZsxg0aJF6bYdOXIk0dHR1teJEydyJG4RKfyaBJdg6XPNiaQkS5Nbpm4wrzPEXgDDgG1z4XjmRp1FJHfZbRG/UqVK4eDgkGqU5syZM6lGc24VHBwMQJ06dfj3338ZN24cvXr1SrOti4sLLi4uORO0iBQ5jQKLs/aVNrR9z8AE9HC4aVJx5G54JxicPSDhSkrZuGi7xCkiN9ht5MbZ2ZlGjRoRGhpqUx4aGkrz5s0z3Y9hGMTHx+d0eCIiVsGlivFKSDVeTnyelvEzUje4ntiIFCn5924vuz5+4eWXX6ZPnz40btyYZs2aMWfOHCIiIhg0KGUJ9JEjR3Lq1Cm+/PJLAD7++GMqVKhA9erVgZR1b9577z2GDBlit88gIkXD4HurYDFgWijUj5vNLtdn7R2SiKTDrslNz549OX/+POPHjycyMpLatWuzYsUKAgMDAYiMjLRZ88ZisTBy5EiOHTuGo6MjlSpVYvLkyTz7rP4nIyK5b2i7KjQJLsFjczbTOG4W21yfS93o2kWI3AMYULFNXocoIoDJMIwitf5zTEwM3t7eREdH4+XlZe9wRKQA2n3iEvd//AdmLBx1fSL9hq8eA/cS6ddLkbZ1+qPcFf1LykYBnKuVMLYkzqaklI08iD8rv992v1tKRKSgqRfgw/AOVbFgJihuQfoNl6a/TIWI5B4lNyIi2TCkXRXGdq8JmAiKW0iM4Za60T9rUhb8+3VcXocnUqQpuRERyaYnWwSzcGBTAOrGf86TCf+XdsPfp8PmT/IwMpGiTcmNiMgdaF65FJtHtgNgraUB0xMfSrvhqtf04E2RPKLkRkTkDvl5u/L7a20BeD/5ISrGfZ12w/ldUxb+E5FcpeRGRCQHlC/uTvjkrgBYMFM/bnbaDWffAyv+D66ey8PoJH8qUjcr5yklNyIiOeifiV14tnVFLuGZ/p1UW+bAci0+KgWbkY9XKFZyIyKSgxzMJkZ2rsGAlsGAid4JI9NueHgFXDmbp7FJfpN/k4OCTsmNiEguGN2tJqO71eQPSx0ejR+ddqNtc/M2KJEiQsmNiEguGdAyGH9vV7YYNaga90XqBusmQuiYvA9MpJBTciMikov+GHEv7Wv4koATbeOnsim55i0N3odDP9snOJFCSsmNiEguMplMfNavMe8/Vp9jRll6JY5K3Wjx42BJzvvgRO5Afr7XS8mNiEgeuL9+OR6o7w+YqBc3J3WD96rCzOawf1mexyaSHfl5OrSSGxGRPDLjsQaEjbiXaDwYm9jPtjL2HJzZD9/2t0tsIoWJkhsRkTzk7+PGE3dX4IvkjryV2Nve4YgUSkpuRETy2FsP1MHVycxnyV2pFjc/dYNx3rB5FiTF53lsIoWBkhsRETs4OL4TAPE4M+bWS1QAq0ak3Eklkk9pQrGIiNgwmUwcm9QFgC+TO/JTctPUjTbPyuOoRAoHJTciInZiMpmsD9scnPhi6gbXLsDR9bpNXCSLlNyIiNjZ9RGcJ9J6DtWX98HK1/I4IpGCTcmNiIidXR/B+d1SJ+0Jxls/BSM/z3AQyV+U3IiI5BOf9W1MPM40jPskdeXB5XkfkEgGjHy8jJ+SGxGRfKJ9TV8Ov9WJC3gxJGGwbeU3fWHdFPj7V/sEJ7mgYI/GmfJx/EpuRETyERdHB359uTU/WprzTmJP28p1E+Hrh+wTmEgBouRGRCSfqVzGg/oBPsxMvs/eoUiuyr+XdQo6JTciIvnQDy+0AEwExS1MXTmjrm4PF8mAkhsRkXzqyNudAfgkqbttxaXjcOaAHSISuUETikVEJMucHMzsHN2ByUm9mJfU0bbyk5ZwdJ1d4hLJ75TciIjkY8WLOTOic3XeTErj+VNf3p/3AUkOyqO7jbbNg7UT8+ZY+YSSGxGRfG5Q60qULOZMi7g0HqR57VLKSyQ9Pw2D9VPg3/32jiTPKLkRESkAto/uwClKc9BSwbZiSmDK6+T2lEnGh1fC1XP2CVKyKG/nrESdOZunx7MnJTciIgVE2Ih76Z7wVtqVn92bculh0WMwp02exiUFw6XYhBztTxOKRUTkjvn7uPFyp1oEx32ddoON76X8N/pE3gUlRZZWKBYRkRzxfJvKGJipHfeZvUMRybeU3IiIFDDhk7tyBXd7hyGSbym5EREpgLa90V6jNyLpUHIjIlIAlfJwoX39ygTFLSTecLJ3OFIEaUKxiIjkuBmPNQCgdfy01JW/jktdtm0uxvTacO7v3A1MxM6U3IiIFGDHJnUhipKpK36fDvGXITnpRtlPL2GKPkHM9y/mXYAidqDkRkSkADOZTMzu04iPktJ4FMNXPWBCSdi5wKb4xLnoPIpOMpZ/b6Uu6JTciIgUcB1r+fFe0qOpK05uSfnv/57P24CkUDIsFjat/ZlTp/L/OkpKbkRECoFdY0IIjvuaH5PvTrvBwZ+sbwMTj4GhUQP7y78TctPyZ+gSmq1/HM85dwH5e9zJ7snNzJkzCQ4OxtXVlUaNGrFx48Z0237//fd06NCB0qVL4+XlRbNmzfjll1/yMFoRkfzJx92ZyQ/VY0jiUP6xlE3dYElv61sP4wrsW5qH0UlhYPprFQBepmsp2/YM5jbsmtwsWbKEYcOGMWrUKHbu3EmrVq3o3LkzERERabbfsGEDHTp0YMWKFWzfvp22bdvSvXt3du7cmceRi4jkPz3vqsCB8R1pn/Du7Rtvn5/r8YjYi12Tm2nTpjFgwAAGDhxIjRo1mDFjBgEBAcyaNSvN9jNmzODVV1/lrrvuokqVKkycOJEqVarw448/5nHkIiL5k7uzI1V8vWgZPyPDdrGJlrwJSMQO7JbcJCQksH37dkJCQmzKQ0JCCAsLy1QfFouFy5cvU6JEidwIUUSkQFoxtBUnjTIExS1Mt82xc1fzMCJJW36etVKw2S25OXfuHMnJyfj6+tqU+/r6EhUVlak+pk6dytWrV3n00TTuEvhPfHw8MTExNi8RkcLM0cHM0YldAOiVMCrtRppQLHcoP3+D7D6h2GSynZJkGEaqsrQsWrSIcePGsWTJEsqUKZNuu0mTJuHt7W19BQQE3HHMIiL5ndls4uehLdlkqZVmfa2E3bYL/Ikd5OcpuWkw2T1lyDS7RVqqVCkcHBxSjdKcOXMm1WjOrZYsWcKAAQP45ptvaN++fYZtR44cSXR0tPV14kT+vz9fRCQn1PL3Zsi9lakbNyftBp+00AhOIWSxGPyw8xTHz+fupcf8nJrZLblxdnamUaNGhIaG2pSHhobSvHnzdPdbtGgR/fv3Z+HChXTt2vW2x3FxccHLy8vmJSJSVAwPqYanT2kejh+TuvLsIbgYnucxSe5auuMkw5bsovW76+wdit3YdYzp5Zdf5rPPPmPu3LkcPHiQl156iYiICAYNGgSkjLr07dvX2n7RokX07duXqVOncvfddxMVFUVUVBTR0VpKXEQkPRtfbcs2ozpnDJ9UdbF7f0x5PINGcAqNreEX7B2C3dk1uenZsyczZsxg/Pjx1K9fnw0bNrBixQoCAwMBiIyMtFnzZvbs2SQlJfHCCy9QtmxZ6+vFF/UQOBGR9JjNJvaMC6FJ/MdMSXzMps597eiUxzMcXmGn6CSnOVoSGeG4iKamg7l6HCMfX5hytHcAzz//PM8/n/ZzT+bPn2+zvW7dutwPSESkEPJydWLtK21p+x685rQ4VX3SyR04Vr/9pX7J/1qe/5Yujj8yyPFH4JVcO44pH98vVXCmPouIyB0JLlWM0d1q0Tgu9UKp5t+nQfxlO0QlOa10fG7dOJN/R2pupeRGRKQIGdAymHN4pyo3Y4FJ5TX3pjAoODlIrlFyIyJSxByd2IW74z5Ms84I/z2PoxHJeUpuRESKGLPZRNsmDdKsO7fp6zyOphAyjEwukFjARsluXXQ3Hw8RKbkRESmCRnSqTsW41IlM6b8Ww6ft4HLmHoMjqcV93oXEqTUhMc4uxzcyscp/piVchZjInOsvjyi5EREpgrzdnVg5rA1d4iemrjy1DRY/rvk32eR6Mgyn2H+5cPh2l/iyl4QYhsFXm8LZdeJStvbPiuR3q8K06hB9MtePlZOU3IiIFFHV/Dx54oHuvJOYxsOHT22HN33g7zV5HldhcTr6Wq70+8u+SMJ+nMvwmd+k0yLnRm4cEq8AcGLXr/n6MtStlNyIiBRhjzetQGjJJ1iVfFfaDb7ukbcByW3FHwpllvP7rHH5v9s3zqHRt3+j7XOJLbuU3IiIFHGhL7dmUOIwe4chmVTmygF7hwBoQrGIiORzW15vT4SldNqV8Vdst6+cgSO/ak7OHcut83cj6TBy9M/IdMtW/v3zV3IjIiKU8XLlnaoL0qwL/7yfbcFHd8GCh2BPenM+xJ5s75bKwQQk/w7UpKLkRkREAPjoiaZp3j0VdOZXWDXyxq3NcZcASDjwM2ycBu/X063j2VKAsoUCRsmNiIhYLX1zEP0T0piounkml34eY1N05N8YWPMmXAzHWDc5jyKU27EZt8m/V45ylZIbERGxcnN2YOa4ETwY/2aqOp9ds222ExJvrMJ78uzFXI9NsiEX59xoQrGIiBQY7s6OLJs0LM262H/CrO9NWKzvz0ZfSau52EF+TjryipIbERFJ05WR51OVuX/V+cbGTaMCgbH78iKkQqZwXTM6cDqGv8/kjyRXyY2IiKTJw8WRs8XTfsAmgJvlqvW9U3IWFnmLiYSk+DsJzX52fAXLh4Il2d6RZEqOpk8ZPLMq+loiXT7YSPtp63P49vPsUXIjIiLpKj10bbp11eJ2W98blsw8BRs4ezjlWUUzm91paPaxfDDs+ALj4I850FleXD7Km0TjbMw1vnSaxIdOH+TJ8W5HyY2IiKTPZIJXjty2mTeZuxyRvP9/KW8u/HMnUdnd4fAT9g4hfabs/bTHRf3FycUvkXDxdKba35w2OV06yj0Oe+nusBnDYkl3n7yi5EZERDLmUQajz/9u385iue3dOftOxeRQUPYVcy3R3iFkSlYuESXNuZfyh+YS+flj6bS4dYXimw9k/4TmZkpuRETktkyV2nCmzbsZtkn6sDFMCYT9P6QUJFyFj5rAileBlB/aXw78m8uR5o0m+96EmIxHOEy3veyUhUtGtz4CI7OykNx4WC4DUO7y3uwd6/oh72jvnKHkRkREMqVMm2c4XTL9uTKOF/+BuGj4th9cu0jS7iVw7jBsmY1hGJy5HI+R3s/OoRXw7/6cCfTwKoyvH4HLuZxIrXwtd/u/bvMnMKkclp0L2L9/D5ZsXvZZs+nPHA4sHflgQrGjvQMQEZGCw3/IKiz/rMP81f0ZN5wShMXJy7p5fnwwK8sMYrhjGs+jOrUDFvcCwBh7CVMGd+VkyqKemIDoZS/h3XfhnfWVkWt3unBhJj/nqpQkyvy/56l1B0d74dJ7wOjbtktvnZzMpiy6W0pERAocc6U28HokSY7uGbZzTrwxv6aUcZH+/07C0ZTGqMOZg9a300L/yqkwOXUyIsf6SkticsYjKIbdLtDc9FTwXOn1dn0ruRERkYLI2R3HNyL5q/XH2e/jUsodR8k3/RbuWbf0DgPLO8fPx9o7hEzI+0TD/qmNkhsREbkDVdv0zva+sV8+An/9wr5Tl6xlXzhPyXZ/F64msPTPv63bNRP2khiXeyvmxicVjIX8ssqUTnpiZPZyoS5LiYhIgWYywdhLrOuwIsu7ul84CAsfpd7211NXbpsLWz/PUn/fffwGD61sZFO2d2n2k6XbSS8JyLxcSgJuSkJuzTM+/PUQ4eeukh23v/sr7WPag5IbERG5MyYTbVq0IOblcM7jc+f97f8BfnoJfn455e6rTHomdnaqsoToqDuPJyvywS/7zU9rvzWeZza24KsP0kgmc5T9z4GSGxERyRFeXsUpOe44X1f98M46+rbfjffX13dJiIXELDy/6roMkg2LxWD4gjBm/nYo6/2me7ibj3e7kY6cf/zC6iUf0erSD+nWu5iSGG2en62+bz2T6d5VlQ8W9FNyIyIiOerxx/rwa/uVOdPZ9JqwZjxMLAvvVMzyyEhGl442HzzK1COd6bCuR0ri9Pt0mzu3sufG8TJ7GScnhRwclWt93/ppTCb7j9CkR8mNiIjkKLPZRPuWzYl9+o+c6XDj1JT/Jl4FSxIxcVl49EEGowhupzYBUMV8Cn6fBr+Og5l3ZyGw1D/u+eCqlA2DvB9F0To3IiJSaLmXqw3DD+don6tW/sCliTVYseonAOLjrhLxdgN++3Zmlvsy3fSAyfjwbKzem9ZveD74Yc8tmb5bKh9QciMiIrnH0w/GRfN73ck50l2nbQOpYD5Ll80pt6BfndmeColHuXf/yLR3yGDk5uaVkI+ezfot42ld8spaalPAE6H0ws8HCZ6SGxERyXUtezzHv4OPst5/YM51uuw5SsQcyLBJhrdr35TcJGfzeU2p2f+H/WaZyjMO/ghz2qYqPnXpWsZ922FOUWYpuRERkTzhW6okrZ+Zyu7Hd+ZMh7sz8dyojO7cuem32ZSN0YY0R26y1E8eJAeZiWfJE3B6R6rifQdufZCpKcPNG4e0f4Kn5EZERPJUvaoVYVw08a+eyPVjNbnwI8bfv3EtPilVnXPczQ++vOkH+cLRTPWd5k94PvhhzxGGQXD4rQ85zb8jNbdSciMiInbh4u7FpeGnGJ70Ag/Ej8+145i+fpCLE6tw6pRtMlVjywjr+4DEYzcqPmiQtQMkJUDUXjBsH5XpfukvyLHLXXnLsuVTqv6VelHEzNA6NyIiUqT5eHow9a2JfDX2eQYlDMu14/ibLhCx6n1IvAaxF1LVe1kyvxLyddfHMWK+ehw+acmV32dx83hO8NZxsPLVDHrIi1Ge7B3j6m9T8/yYOUnJjYiI2J2nqxOfTHyTmBHneDrh5Vw5hgkLsVPrwTvBJF85l3HjK2cy0WPKj7jX8VAArq3/IPVVqa2fZj3QfOBqfBoPBU11VSq9FYpzPJwsU3IjIiL5hperE3PeHsNrQd/meN8mwD3uXwD2b7rNgz7fqwLXLsG1i+m3ueVHPCk5KYu/7Dkwh+WrB+HCsdu3y4LMPxA0nXb5ILtRciMiIvmKyWRiSv8Qvuy4m4pxXxMUl4m7ojKh+tlV1vfXrmXiOVVTAmFKECTFp1ntgm0fZiwYeX1J5p/fiF3UL91qe+QZ9k9tlNyIiEg+1bdZEEcndyd8cleGBv3vjvvzjjtlfW8xOWR+x62fp/w3+qRNcXDSMdjxpXXbwbBgj5/2+LMZjNzkaHaT2ZEm+6c3jvYOQERE5HY+6N+GlXsPMWXhzwSZojhmlGWC4zzucdibrf5q7c3Cism/jITiQZzds5rSt9YtH2J9a8aS/Vzi2iVw88nWrsk5PE7hYDLw42y2988HV6XsP3Izc+ZMgoODcXV1pVGjRmzcuDHdtpGRkTz++ONUq1YNs9nMsGHD8i5QERGxq851yrJu0kCmjHiF715/gr6JI/gu+Z5s9eWVkJkJwzdZ3IvSB+Zl2KQE0VxYNSl1RVICJKdeZ8dmhOOLbml3molMIdsrBcfFwJ/Zu907Rbqr+N1BnznDrsnNkiVLGDZsGKNGjWLnzp20atWKzp07ExERkWb7+Ph4SpcuzahRo6hXr14eRysiIvmBr5crpT1d+GNEO2b5DCckfoq9Q7Ly3/1h6sK3SsOEkvDb2+nvGPXfCFRCrG150u3nBlky+CnP8KngP710m1vVb3VTMrPgUby4mmYr503TU265tyO7JjfTpk1jwIABDBw4kBo1ajBjxgwCAgKYNWtWmu2DgoJ4//336du3L97e3nkcrYiI5CflfNxYM7wNfxkBBMUtJChuIVMSH7N3WOnb8M4tBbeMfETuhollSVr+krUo0XL7URBLdkduDmRxHtPNhznyS7rNXP78kOT172Yvphxit+QmISGB7du3ExISYlMeEhJCWFhYjh0nPj6emJgYm5eIiBQe4ZO7cmB8R34e2pJ2T0/K/0lOemanXGJz3DHXWpScnMZ6M7cwTNn4KT8SCpbETDf3vPx3lrp3+P1OFgG8c3ZLbs6dO0dycjK+vr425b6+vkRFReXYcSZNmoS3t7f1FRAQkGN9i4hI/uDu7Egtf28aB5Xgn4ldmGt6gLpxn3LNcLZ3aLY2f2J9W+HawXSbJSUlceJCLMu2pz1Nw5YJtnyaMvJzCyO9kZ+lAzLR7w3VjnxKQXq2lN3vljKZbE+WYRipyu7EyJEjefnlG6tdxsTEKMERESnEHMwmDr/VmbjEZKaF1uHLDQdpbd7DbOfp9g4NVr0GTZ8FwDch/cRl/eKpbD/4N6863frwytT8jX9hxStp1pkSLqdZnpAM+Szty1F2S25KlSqFg4NDqlGaM2fOpBrNuRMuLi64uLjkWH8iIlIwuDo58HqXGrzasRpJlvup+3YzSscfZ43L/9k3sDd9btsk+K+5tHO686sY5lTzfFJcSbRQ4o57z7/sdlnK2dmZRo0aERoaalMeGhpK8+bN7RSViIgUNo4OZlydHNg9NoT+93ekX8mvuSvuY4LiFrLXEmTv8NJU0Zwz0zNOHk97royRrZ9/XZbKlJdffpk+ffrQuHFjmjVrxpw5c4iIiGDQoEFAyiWlU6dO8eWXN1aA3LVrFwBXrlzh7Nmz7Nq1C2dnZ2rWrGmPjyAiIgWEyWSiz92B9Lk7EMMwOHHhGuN+/Ixth47iQhIdHbbyllPGa9kUNC4X/865YYyCk9vYN7np2bMn58+fZ/z48URGRlK7dm1WrFhBYGAgkLJo361r3jRo0MD6fvv27SxcuJDAwEDCw8PzMnQRESnATCYTFUq6M7f/XcBdAKw73IFZkUNYv/p7Fju/Zd8Ac0iAOe2VhksSnceR5C2TYeSDpQTzUExMDN7e3kRHR+Pl5WXvcEREJJ+xWAxW7Ytk/E8HSYg5w1OOK6ljOkZrhz32Ds2utvj3ocnpr9KsO/7YWgIXt7UtHJezCVRWfr/tfreUiIhIfmI2m+hS158udf1Zvvs0hyIb0G/dPzgmJlHOdI6nHFbym6UhXzjnn5WR80J6iU1+pJEbERGR20hMtrB6/7+8sHBHmvVvOH7FQMeVeRxVPmfHkRslNyIiIllwOS4RT1cnLl5NYOW+KFbui2TjkXMUJ4apTp9wr8Mue4eYPyi5yTtKbkREJKddik2g/vhQzFgobzqLGQvnDW8qmk7T3HyARubDtHfYae8w85bm3IiIiBRcPu7OhE/uSlKyBQezibNX4omKjiPZYvDgzDBIBq/EK1QzneQfw58LeFLNdIJruLDB5aXbH6AgsljAbJ/l9DRyIyIikstOXIil1Ttr0613JZ44nOlh3sh9DptoYd6HkynloZkDE4bzmbN9H0SZLRq5ERERKbwCSrgTPrmrTVlcYjIujma+236SCT8d4PMnGtH7MxPfW+6xtjFhwcDM2MR+xOLCZcOdT5xn2PRzzvBih6UKIQ7b8+KjZMo2S1Ua2/H4GrkRERHJJ5L/e4p32D/n2BZ+kQ1HznLiQiznriQA0KpKKTYeOZfmviYsVDOdpLzpLB87vU+PhPHsN4JoZDrMCaMMBibed/qI5g4HrPuEW3wJMv+b45/jw6QHGPLWFznapyYUZ0DJjYiIFGRnYuJYtOUELSqX5I+/z7NibySjutbgf7tOs3THydvuX5bzdHDYxnfJrYnFFUeSmOI0h92WSpw3vFlrqU8srtQ1/UMT8yGWJreiu8Mmhjt+i7cpNlMx9koYxaKJr97pR7Wh5CYDSm5ERKQouZaQjLOjmS3HLjBk0Q7rKFDWGdQyhdPTYR19HUN5PmEoHR228WlSF04apZnuNJMEnPgxuRl+zR/njW45+8xHJTcZUHIjIiJFncVikJBs4fj5WKr6egAQn2ThwtUEzCYTft6uJCVbiL6WSDEXRxzMJvacvMT/fbuHl0OqMnPtPxyIjEm3/91jQvB2d8rRmJXcZEDJjYiISMGTld9v+9yALiIiIpJLlNyIiIhIoaLkRkRERAoVJTciIiJSqCi5ERERkUJFyY2IiIgUKkpuREREpFBRciMiIiKFipIbERERKVSU3IiIiEihouRGREREChUlNyIiIlKoKLkRERGRQkXJjYiIiBQqjvYOIK8ZhgGkPDpdRERECobrv9vXf8czUuSSm8uXLwMQEBBg50hEREQkqy5fvoy3t3eGbUxGZlKgQsRisXD69Gk8PT0xmUw52ndMTAwBAQGcOHECLy+vHO1bbtB5zhs6z3lH5zpv6Dznjdw6z4ZhcPnyZfz9/TGbM55VU+RGbsxmM+XLl8/VY3h5eekvTh7Qec4bOs95R+c6b+g8543cOM+3G7G5ThOKRUREpFBRciMiIiKFipKbHOTi4sLYsWNxcXGxdyiFms5z3tB5zjs613lD5zlv5IfzXOQmFIuIiEjhppEbERERKVSU3IiIiEihouRGREREChUlNyIiIlKoKLnJITNnziQ4OBhXV1caNWrExo0b7R1SvrZhwwa6d++Ov78/JpOJH374wabeMAzGjRuHv78/bm5utGnThv3799u0iY+PZ8iQIZQqVYpixYpx3333cfLkSZs2Fy9epE+fPnh7e+Pt7U2fPn24dOlSLn+6/GPSpEncddddeHp6UqZMGR544AEOHz5s00bn+s7NmjWLunXrWhcta9asGStXrrTW6xznjkmTJmEymRg2bJi1TOf6zo0bNw6TyWTz8vPzs9YXiHNsyB1bvHix4eTkZHz66afGgQMHjBdffNEoVqyYcfz4cXuHlm+tWLHCGDVqlLF06VIDMJYtW2ZTP3nyZMPT09NYunSpsXfvXqNnz55G2bJljZiYGGubQYMGGeXKlTNCQ0ONHTt2GG3btjXq1atnJCUlWdt06tTJqF27thEWFmaEhYUZtWvXNrp165ZXH9PuOnbsaMybN8/Yt2+fsWvXLqNr165GhQoVjCtXrljb6FzfueXLlxs///yzcfjwYePw4cPG66+/bjg5ORn79u0zDEPnODds2bLFCAoKMurWrWu8+OKL1nKd6zs3duxYo1atWkZkZKT1debMGWt9QTjHSm5yQJMmTYxBgwbZlFWvXt0YMWKEnSIqWG5NbiwWi+Hn52dMnjzZWhYXF2d4e3sbn3zyiWEYhnHp0iXDycnJWLx4sbXNqVOnDLPZbKxatcowDMM4cOCAARibN2+2ttm0aZMBGIcOHcrlT5U/nTlzxgCM9evXG4ahc52bihcvbnz22Wc6x7ng8uXLRpUqVYzQ0FCjdevW1uRG5zpnjB071qhXr16adQXlHOuy1B1KSEhg+/bthISE2JSHhIQQFhZmp6gKtmPHjhEVFWVzTl1cXGjdurX1nG7fvp3ExESbNv7+/tSuXdvaZtOmTXh7e9O0aVNrm7vvvhtvb+8i+2cTHR0NQIkSJQCd69yQnJzM4sWLuXr1Ks2aNdM5zgUvvPACXbt2pX379jblOtc558iRI/j7+xMcHMxjjz3G0aNHgYJzjovcgzNz2rlz50hOTsbX19em3NfXl6ioKDtFVbBdP29pndPjx49b2zg7O1O8ePFUba7vHxUVRZkyZVL1X6ZMmSL5Z2MYBi+//DItW7akdu3agM51Ttq7dy/NmjUjLi4ODw8Pli1bRs2aNa3/o9Y5zhmLFy9mx44dbN26NVWdvs85o2nTpnz55ZdUrVqVf//9l7feeovmzZuzf//+AnOOldzkEJPJZLNtGEaqMsma7JzTW9uk1b6o/tkMHjyYPXv28Pvvv6eq07m+c9WqVWPXrl1cunSJpUuX0q9fP9avX2+t1zm+cydOnODFF19k9erVuLq6pttO5/rOdO7c2fq+Tp06NGvWjEqVKvHFF19w9913A/n/HOuy1B0qVaoUDg4OqTLNM2fOpMpsJXOuz8rP6Jz6+fmRkJDAxYsXM2zz77//pur/7NmzRe7PZsiQISxfvpy1a9dSvnx5a7nOdc5xdnamcuXKNG7cmEmTJlGvXj3ef/99neMctH37ds6cOUOjRo1wdHTE0dGR9evX88EHH+Do6Gg9DzrXOatYsWLUqVOHI0eOFJjvs5KbO+Ts7EyjRo0IDQ21KQ8NDaV58+Z2iqpgCw4Oxs/Pz+acJiQksH79eus5bdSoEU5OTjZtIiMj2bdvn7VNs2bNiI6OZsuWLdY2f/75J9HR0UXmz8YwDAYPHsz333/Pb7/9RnBwsE29znXuMQyD+Ph4neMc1K5dO/bu3cuuXbusr8aNG9O7d2927dpFxYoVda5zQXx8PAcPHqRs2bIF5/t8x1OSxXor+Oeff24cOHDAGDZsmFGsWDEjPDzc3qHlW5cvXzZ27txp7Ny50wCMadOmGTt37rTePj958mTD29vb+P777429e/cavXr1SvNWw/Llyxu//vqrsWPHDuPee+9N81bDunXrGps2bTI2bdpk1KlTp8jczmkYhvHcc88Z3t7exrp162xu64yNjbW20bm+cyNHjjQ2bNhgHDt2zNizZ4/x+uuvG2az2Vi9erVhGDrHuenmu6UMQ+c6JwwfPtxYt26dcfToUWPz5s1Gt27dDE9PT+tvWkE4x0pucsjHH39sBAYGGs7OzkbDhg2tt9pK2tauXWsAqV79+vUzDCPldsOxY8cafn5+houLi3HPPfcYe/futenj2rVrxuDBg40SJUoYbm5uRrdu3YyIiAibNufPnzd69+5teHp6Gp6enkbv3r2Nixcv5tGntL+0zjFgzJs3z9pG5/rOPfXUU9a//6VLlzbatWtnTWwMQ+c4N92a3Ohc37nr69Y4OTkZ/v7+Ro8ePYz9+/db6wvCOTYZhmHc+fiPiIiISP6gOTciIiJSqCi5ERERkUJFyY2IiIgUKkpuREREpFBRciMiIiKFipIbERERKVSU3IiIiEihouRGRAq9hIQEKleuzB9//JGnxz1z5gylS5fm1KlTeXpckaJOyY2IZNmZM2d49tlnqVChAi4uLvj5+dGxY0c2bdpkbWMymfjhhx/sF+RN5syZQ2BgIC1atMj0Pt9//z0dO3akVKlSmEwmdu3alapNfHw8Q4YMoVSpUhQrVoz77ruPkydPWuvLlClDnz59GDt2bE58DBHJJCU3IpJlDz30ELt37+aLL77gr7/+Yvny5bRp04YLFy7YO7Q0ffjhhwwcODBL+1y9epUWLVowefLkdNsMGzaMZcuWsXjxYn7//XeuXLlCt27dSE5OtrZ58sknWbBgQaonJItILsqRhziISJFx8eJFAzDWrVuXbpvAwECbZ1kFBgZa65YvX240bNjQcHFxMYKDg41x48YZiYmJ1nrAmDlzptGpUyfD1dXVCAoKMr755htrfXx8vPHCCy9Yn2sTGBhoTJw4Md1Ytm/fbpjNZiM6Otpa9sUXXxjFihUz/vrrL2vZ4MGDjSpVqhhXrlyx2f/YsWMGYOzcudOm/NKlS4aTk5OxePFia9mpU6cMs9lsrFq1yqZtUFCQ8fnnn6cbo4jkLI3ciEiWeHh44OHhwQ8//EB8fHyabbZu3QrAvHnziIyMtG7/8ssvPPHEEwwdOpQDBw4we/Zs5s+fz9tvv22z/+jRo62jQ0888QS9evXi4MGDAHzwwQcsX76cb775hsOHD/P1118TFBSUbrwbNmygatWqeHl5Wcv69u1Lly5d6N27N0lJSaxatYrZs2ezYMECihUrlqnzsH37dhITEwkJCbGW+fv7U7t2bcLCwmzaNmnShI0bN2aqXxG5c0puRCRLHB0dmT9/Pl988QU+Pj60aNGC119/nT179ljblC5dGgAfHx/8/Pys22+//TYjRoygX79+VKxYkQ4dOjBhwgRmz55tc4xHHnmEgQMHUrVqVSZMmEDjxo358MMPAYiIiKBKlSq0bNmSwMBAWrZsSa9evdKNNzw8HH9//1Tls2fPJjIykqFDh9K/f3/Gjh3LXXfdlenzEBUVhbOzM8WLF7cp9/X1JSoqyqasXLlyhIeHZ7pvEbkzSm5EJMseeughTp8+zfLly+nYsSPr1q2jYcOGzJ8/P8P9tm/fzvjx462jPx4eHjz99NNERkYSGxtrbdesWTOb/Zo1a2Yduenfvz+7du2iWrVqDB06lNWrV2d4zGvXruHq6pqqvHjx4nz++efMmjWLSpUqMWLEiEx++owZhoHJZLIpc3Nzs/l8IpK7lNyISLa4urrSoUMHxowZQ1hYmHX0IyMWi4U333yTXbt2WV979+7lyJEjaSYgN7ueMDRs2JBjx44xYcIErl27xqOPPsrDDz+c7n6lSpVKdzLvhg0bcHBw4PTp01y9evU2n9iWn58fCQkJqfo+c+YMvr6+NmUXLlywjl6JSO5TciMiOaJmzZo2CYKTk5PNXUOQkpgcPnyYypUrp3qZzTf+d7R582ab/TZv3kz16tWt215eXvTs2ZNPP/2UJUuWsHTp0nTv1GrQoAGHDh3CMAyb8rCwMN555x1+/PFHvLy8GDJkSJY+b6NGjXByciI0NNRaFhkZyb59+2jevLlN23379tGgQYMs9S8i2edo7wBEpGA5f/48jzzyCE899RR169bF09OTbdu28c4773D//fdb2wUFBbFmzRpatGiBi4sLxYsXZ8yYMXTr1o2AgAAeeeQRzGYze/bsYe/evbz11lvWfb/99lsaN25My5YtWbBgAVu2bOHzzz8HYPr06ZQtW5b69etjNpv59ttv8fPzw8fHJ81427Zty9WrV9m/fz+1a9cG4PLly/Tp04chQ4bQuXNnKlSoQOPGjenWrRuPPPIIkDLaEhERwenTpwE4fPgwkDJi4+fnh7e3NwMGDGD48OGULFmSEiVK8Morr1CnTh3at29vPX5sbCzbt29n4sSJOfeHICIZs/ftWiJSsMTFxRkjRowwGjZsaHh7exvu7u5GtWrVjDfeeMOIjY21tlu+fLlRuXJlw9HR0eZW8FWrVhnNmzc33NzcDC8vL6NJkybGnDlzrPWA8fHHHxsdOnSw3uq9aNEia/2cOXOM+vXrG8WKFTO8vLyMdu3aGTt27Mgw5scee8wYMWKEdfvJJ5806tSpY8TFxVnL3n//faNEiRLGyZMnDcMwjHnz5tnczn79NXbsWOs+165dMwYPHmyUKFHCcHNzM7p162ZERETYHHvhwoVGtWrVMndyRSRHmAzjlrFaERE7MplMLFu2jAceeCDH+ty7dy/t27fn77//xtPTM8f6zYwmTZowbNgwHn/88Tw9rkhRpjk3IlLo1alTh3feeSfPb8c+c+YMDz/8cIa3qotIztPIjYjkK7kxciMiRYsmFItIvqJ/b4nIndJlKRERESlUlNyIiIhIoaLkRkRERAoVJTciIiJSqCi5ERERkUJFyY2IiIgUKkpuREREpFBRciMiIiKFipIbERERKVT+H68ua7+Sh9uNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Steps (x10)')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e6617",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_fn(output, train_labels)\n\u001b[0;32m     71\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m val_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 't_loss' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "\n",
    "g.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super().__init__()\n",
    "\n",
    "    self.seq_model = nn.Sequential(\n",
    "      nn.Linear(input_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(hidden_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(hidden_size, output_size)\n",
    "    )\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    return self.seq_model(x)\n",
    "  \n",
    "\n",
    "net = Net(2, 16, 1)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Early stopping 변수\n",
    "min_val_loss = float('inf')\n",
    "patience = 100\n",
    "steps_no_improvement = 0\n",
    "min_step = 0\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for steps in range(50000):\n",
    "  net.train()\n",
    "  data_batch, label_batch = get_batch(train_data, train_labels, 256)\n",
    "  output = net(data_batch)\n",
    "  \n",
    "  loss = loss_fn(output, label_batch)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "  \n",
    "\n",
    "  if steps % 10 == 0:\n",
    "    net.eval()\n",
    "    output = net(val_data)\n",
    "    val_loss = loss_fn(output, val_labels)\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "    # Early stopping 적용(val_loss가 개선되지 않으면 patience만큼 기다린 후 학습 중지)\n",
    "    if val_loss < min_val_loss:\n",
    "      min_val_loss = val_loss\n",
    "      steps_no_improvement = 0\n",
    "      min_step = steps\n",
    "    else:\n",
    "      steps_no_improvement += 1\n",
    "      if steps_no_improvement == patience:\n",
    "        print(f\"Early stopping at step {steps} with min_val_loss: {min_val_loss.item()}\")\n",
    "        break\n",
    "\n",
    "    output = net(train_data)\n",
    "    train_loss = loss_fn(output, train_labels)\n",
    "    train_losses.append(train_loss.item())\n",
    "    print(f\"{steps} val_loss: {val_loss.item()}, train_loss: {t_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Steps (x10)')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
